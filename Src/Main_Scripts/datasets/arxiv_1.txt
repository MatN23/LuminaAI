Dynamic Backtracking
Because of their occasional need to return to shallow points in a search
tree, existing backtracking methods can sometimes erase meaningful progress
toward solving a search problem. In this paper, we present a method by which
backtrack points can be moved deeper in the search space, thereby avoiding this
difficulty. The technique developed is a variant of dependency-directed
backtracking that uses only polynomial space while still providing useful
control information and retaining the completeness guarantees provided by
earlier approaches.

A Market-Oriented Programming Environment and its Application to
  Distributed Multicommodity Flow Problems
Market price systems constitute a well-understood class of mechanisms that
under certain conditions provide effective decentralization of decision making
with minimal communication overhead. In a market-oriented programming approach
to distributed problem solving, we derive the activities and resource
allocations for a set of computational agents by computing the competitive
equilibrium of an artificial economy. WALRAS provides basic constructs for
defining computational market structures, and protocols for deriving their
corresponding price equilibria. In a particular realization of this approach
for a form of multicommodity flow problem, we see that careful construction of
the decision process according to economic principles can lead to efficient
distributed resource allocation, and that the behavior of the system can be
meaningfully analyzed in economic terms.

An Empirical Analysis of Search in GSAT
We describe an extensive study of search in GSAT, an approximation procedure
for propositional satisfiability. GSAT performs greedy hill-climbing on the
number of satisfied clauses in a truth assignment. Our experiments provide a
more complete picture of GSAT's search than previous accounts. We describe in
detail the two phases of search: rapid hill-climbing followed by a long plateau
search. We demonstrate that when applied to randomly generated 3SAT problems,
there is a very simple scaling with problem size for both the mean number of
satisfied clauses and the mean branching rate. Our results allow us to make
detailed numerical conjectures about the length of the hill-climbing phase, the
average gradient of this phase, and to conjecture that both the average score
and average branching rate decay exponentially during plateau search. We end by
showing how these results can be used to direct future theoretical analysis.
This work provides a case study of how computer experiments can be used to
improve understanding of the theoretical properties of algorithms.

The Difficulties of Learning Logic Programs with Cut
As real logic programmers normally use cut (!), an effective learning
procedure for logic programs should be able to deal with it. Because the cut
predicate has only a procedural meaning, clauses containing cut cannot be
learned using an extensional evaluation method, as is done in most learning
systems. On the other hand, searching a space of possible programs (instead of
a space of independent clauses) is unfeasible. An alternative solution is to
generate first a candidate base program which covers the positive examples, and
then make it consistent by inserting cut where appropriate. The problem of
learning programs with cut has not been investigated before and this seems to
be a natural and reasonable approach. We generalize this scheme and investigate
the difficulties that arise. Some of the major shortcomings are actually
caused, in general, by the need for intensional evaluation. As a conclusion,
the analysis of this paper suggests, on precise and technical grounds, that
learning cut is difficult, and current induction techniques should probably be
restricted to purely declarative logic languages.

Software Agents: Completing Patterns and Constructing User Interfaces
To support the goal of allowing users to record and retrieve information,
this paper describes an interactive note-taking system for pen-based computers
with two distinctive features. First, it actively predicts what the user is
going to write. Second, it automatically constructs a custom, button-box user
interface on request. The system is an example of a learning-apprentice
software- agent. A machine learning component characterizes the syntax and
semantics of the user's information. A performance system uses this learned
information to generate completion strings and construct a user interface.
Description of Online Appendix: People like to record information. Doing this
on paper is initially efficient, but lacks flexibility. Recording information
on a computer is less efficient but more powerful. In our new note taking
softwre, the user records information directly on a computer. Behind the
interface, an agent acts for the user. To help, it provides defaults and
constructs a custom user interface. The demonstration is a QuickTime movie of
the note taking agent in action. The file is a binhexed self-extracting
archive. Macintosh utilities for binhex are available from
mac.archive.umich.edu. QuickTime is available from ftp.apple.com in the
dts/mac/sys.soft/quicktime.

Hierarchical Reinforcement Learning with the MAXQ Value Function
  Decomposition
This paper presents the MAXQ approach to hierarchical reinforcement learning
based on decomposing the target Markov decision process (MDP) into a hierarchy
of smaller MDPs and decomposing the value function of the target MDP into an
additive combination of the value functions of the smaller MDPs. The paper
defines the MAXQ hierarchy, proves formal results on its representational
power, and establishes five conditions for the safe use of state abstractions.
The paper presents an online model-free learning algorithm, MAXQ-Q, and proves
that it converges wih probability 1 to a kind of locally-optimal policy known
as a recursively optimal policy, even in the presence of the five kinds of
state abstraction. The paper evaluates the MAXQ representation and MAXQ-Q
through a series of experiments in three domains and shows experimentally that
MAXQ-Q (with state abstractions) converges to a recursively optimal policy much
faster than flat Q learning. The fact that MAXQ learns a representation of the
value function has an important benefit: it makes it possible to compute and
execute an improved, non-hierarchical policy via a procedure similar to the
policy improvement step of policy iteration. The paper demonstrates the
effectiveness of this non-hierarchical execution experimentally. Finally, the
paper concludes with a comparison to related work and a discussion of the
design tradeoffs in hierarchical reinforcement learning.

State Abstraction in MAXQ Hierarchical Reinforcement Learning
Many researchers have explored methods for hierarchical reinforcement
learning (RL) with temporal abstractions, in which abstract actions are defined
that can perform many primitive actions before terminating. However, little is
known about learning with state abstractions, in which aspects of the state
space are ignored. In previous work, we developed the MAXQ method for
hierarchical RL. In this paper, we define five conditions under which state
abstraction can be combined with the MAXQ value function decomposition. We
prove that the MAXQ-Q learning algorithm converges under these conditions and
show experimentally that state abstraction is important for the successful
application of MAXQ-Q learning.

Multiplicative Algorithm for Orthgonal Groups and Independent Component
  Analysis
The multiplicative Newton-like method developed by the author et al. is
extended to the situation where the dynamics is restricted to the orthogonal
group. A general framework is constructed without specifying the cost function.
Though the restriction to the orthogonal groups makes the problem somewhat
complicated, an explicit expression for the amount of individual jumps is
obtained. This algorithm is exactly second-order-convergent. The global
instability inherent in the Newton method is remedied by a
Levenberg-Marquardt-type variation. The method thus constructed can readily be
applied to the independent component analysis. Its remarkable performance is
illustrated by a numerical simulation.

Multiplicative Nonholonomic/Newton -like Algorithm
We construct new algorithms from scratch, which use the fourth order cumulant
of stochastic variables for the cost function. The multiplicative updating rule
here constructed is natural from the homogeneous nature of the Lie group and
has numerous merits for the rigorous treatment of the dynamics. As one
consequence, the second order convergence is shown. For the cost function,
functions invariant under the componentwise scaling are choosen. By identifying
points which can be transformed to each other by the scaling, we assume that
the dynamics is in a coset space. In our method, a point can move toward any
direction in this coset. Thus, no prewhitening is required.

Complexity analysis for algorithmically simple strings
Given a reference computer, Kolmogorov complexity is a well defined function
on all binary strings. In the standard approach, however, only the asymptotic
properties of such functions are considered because they do not depend on the
reference computer. We argue that this approach can be more useful if it is
refined to include an important practical case of simple binary strings.
Kolmogorov complexity calculus may be developed for this case if we restrict
the class of available reference computers. The interesting problem is to
define a class of computers which is restricted in a {\it natural} way modeling
the real-life situation where only a limited class of computers is physically
available to us. We give an example of what such a natural restriction might
look like mathematically, and show that under such restrictions some error
terms, even logarithmic in complexity, can disappear from the standard
complexity calculus.
  Keywords: Kolmogorov complexity; Algorithmic information theory.

Robust Classification for Imprecise Environments
In real-world environments it usually is difficult to specify target
operating conditions precisely, for example, target misclassification costs.
This uncertainty makes building robust classification systems problematic. We
show that it is possible to build a hybrid classifier that will perform at
least as well as the best available classifier for any target conditions. In
some cases, the performance of the hybrid actually can surpass that of the best
known classifier. This robust performance extends across a wide variety of
comparison frameworks, including the optimization of metrics such as accuracy,
expected cost, lift, precision, recall, and workforce utilization. The hybrid
also is efficient to build, to store, and to update. The hybrid is based on a
method for the comparison of classifier performance that is robust to imprecise
class distributions and misclassification costs. The ROC convex hull (ROCCH)
method combines techniques from ROC analysis, decision analysis and
computational geometry, and adapts them to the particulars of analyzing learned
classifiers. The method is efficient and incremental, minimizes the management
of classifier performance data, and allows for clear visual comparisons and
sensitivity analyses. Finally, we point to empirical evidence that a robust
hybrid classifier indeed is needed for many real-world problems.

Top-down induction of clustering trees
An approach to clustering is presented that adapts the basic top-down
induction of decision trees method towards clustering. To this aim, it employs
the principles of instance based learning. The resulting methodology is
implemented in the TIC (Top down Induction of Clustering trees) system for
first order clustering. The TIC system employs the first order logical decision
tree representation of the inductive logic programming system Tilde. Various
experiments with TIC are presented, in both propositional and relational
domains.

Scaling Up Inductive Logic Programming by Learning from Interpretations
When comparing inductive logic programming (ILP) and attribute-value learning
techniques, there is a trade-off between expressive power and efficiency.
Inductive logic programming techniques are typically more expressive but also
less efficient. Therefore, the data sets handled by current inductive logic
programming systems are small according to general standards within the data
mining community. The main source of inefficiency lies in the assumption that
several examples may be related to each other, so they cannot be handled
independently.
  Within the learning from interpretations framework for inductive logic
programming this assumption is unnecessary, which allows to scale up existing
ILP algorithms. In this paper we explain this learning setting in the context
of relational databases. We relate the setting to propositional data mining and
to the classical ILP setting, and show that learning from interpretations
corresponds to learning from multiple relations and thus extends the
expressiveness of propositional learning, while maintaining its efficiency to a
large extent (which is not the case in the classical ILP setting).
  As a case study, we present two alternative implementations of the ILP system
Tilde (Top-down Induction of Logical DEcision trees): Tilde-classic, which
loads all data in main memory, and Tilde-LDS, which loads the examples one by
one. We experimentally compare the implementations, showing Tilde-LDS can
handle large data sets (in the order of 100,000 examples or 100 MB) and indeed
scales up linearly in the number of examples.

Learning Policies with External Memory
In order for an agent to perform well in partially observable domains, it is
usually necessary for actions to depend on the history of observations. In this
paper, we explore a {\it stigmergic} approach, in which the agent's actions
include the ability to set and clear bits in an external memory, and the
external memory is included as part of the input to the agent. In this case, we
need to learn a reactive policy in a highly non-Markovian domain. We explore
two algorithms: SARSA(\lambda), which has had empirical success in partially
observable domains, and VAPS, a new algorithm due to Baird and Moore, with
convergence guarantees in partially observable domains. We compare the
performance of these two algorithms on benchmark problems.

Efficient algorithms for decision tree cross-validation
Cross-validation is a useful and generally applicable technique often
employed in machine learning, including decision tree induction. An important
disadvantage of straightforward implementation of the technique is its
computational overhead. In this paper we show that, for decision trees, the
computational overhead of cross-validation can be reduced significantly by
integrating the cross-validation with the normal decision tree induction
process. We discuss how existing decision tree algorithms can be adapted to
this aim, and provide an analysis of the speedups these adaptations may yield.
The analysis is supported by experimental results.

Evaluation of the Performance of the Markov Blanket Bayesian Classifier
  Algorithm
The Markov Blanket Bayesian Classifier is a recently-proposed algorithm for
construction of probabilistic classifiers. This paper presents an empirical
comparison of the MBBC algorithm with three other Bayesian classifiers: Naive
Bayes, Tree-Augmented Naive Bayes and a general Bayesian network. All of these
are implemented using the K2 framework of Cooper and Herskovits. The
classifiers are compared in terms of their performance (using simple accuracy
measures and ROC curves) and speed, on a range of standard benchmark data sets.
It is concluded that MBBC is competitive in terms of speed and accuracy with
the other algorithms considered.

Approximating Incomplete Kernel Matrices by the em Algorithm
In biological data, it is often the case that observed data are available
only for a subset of samples. When a kernel matrix is derived from such data,
we have to leave the entries for unavailable samples as missing. In this paper,
we make use of a parametric model of kernel matrices, and estimate missing
entries by fitting the model to existing entries. The parametric model is
created as a set of spectral variants of a complete kernel matrix derived from
another information source. For model fitting, we adopt the em algorithm based
on the information geometry of positive definite matrices. We will report
promising results on bacteria clustering experiments using two marker
sequences: 16S and gyrB.

Reliable and Efficient Inference of Bayesian Networks from Sparse Data
  by Statistical Learning Theory
To learn (statistical) dependencies among random variables requires
exponentially large sample size in the number of observed random variables if
any arbitrary joint probability distribution can occur.
  We consider the case that sparse data strongly suggest that the probabilities
can be described by a simple Bayesian network, i.e., by a graph with small
in-degree \Delta. Then this simple law will also explain further data with high
confidence. This is shown by calculating bounds on the VC dimension of the set
of those probability measures that correspond to simple graphs. This allows to
select networks by structural risk minimization and gives reliability bounds on
the error of the estimated joint measure without (in contrast to a previous
paper) any prior assumptions on the set of possible joint measures.
  The complexity for searching the optimal Bayesian networks of in-degree
\Delta increases only polynomially in the number of random varibales for
constant \Delta and the optimal joint measure associated with a given graph can
be found by convex optimization.

Toward Attribute Efficient Learning Algorithms
We make progress on two important problems regarding attribute efficient
learnability.
  First, we give an algorithm for learning decision lists of length $k$ over
$n$ variables using $2^{\tilde{O}(k^{1/3})} \log n$ examples and time
$n^{\tilde{O}(k^{1/3})}$. This is the first algorithm for learning decision
lists that has both subexponential sample complexity and subexponential running
time in the relevant parameters. Our approach establishes a relationship
between attribute efficient learning and polynomial threshold functions and is
based on a new construction of low degree, low weight polynomial threshold
functions for decision lists. For a wide range of parameters our construction
matches a 1994 lower bound due to Beigel for the ODDMAXBIT predicate and gives
an essentially optimal tradeoff between polynomial threshold function degree
and weight.
  Second, we give an algorithm for learning an unknown parity function on $k$
out of $n$ variables using $O(n^{1-1/k})$ examples in time polynomial in $n$.
For $k=o(\log n)$ this yields a polynomial time algorithm with sample
complexity $o(n)$. This is the first polynomial time algorithm for learning
parity on a superconstant number of variables with sublinear sample complexity.

Improving spam filtering by combining Naive Bayes with simple k-nearest
  neighbor searches
Using naive Bayes for email classification has become very popular within the
last few months. They are quite easy to implement and very efficient. In this
paper we want to present empirical results of email classification using a
combination of naive Bayes and k-nearest neighbor searches. Using this
technique we show that the accuracy of a Bayes filter can be improved slightly
for a high number of features and significantly for a small number of features.

About Unitary Rating Score Constructing
It is offered to pool test points of different subjects and different aspects
of the same subject together in order to get the unitary rating score, by the
way of nonlinear transformation of indicator points in accordance with Zipf's
distribution. It is proposed to use the well-studied distribution of
Intellectuality Quotient IQ as the reference distribution for latent variable
"progress in studies".

Mining Heterogeneous Multivariate Time-Series for Learning Meaningful
  Patterns: Application to Home Health Telecare
For the last years, time-series mining has become a challenging issue for
researchers. An important application lies in most monitoring purposes, which
require analyzing large sets of time-series for learning usual patterns. Any
deviation from this learned profile is then considered as an unexpected
situation. Moreover, complex applications may involve the temporal study of
several heterogeneous parameters. In that paper, we propose a method for mining
heterogeneous multivariate time-series for learning meaningful patterns. The
proposed approach allows for mixed time-series -- containing both pattern and
non-pattern data -- such as for imprecise matches, outliers, stretching and
global translating of patterns instances in time. We present the early results
of our approach in the context of monitoring the health status of a person at
home. The purpose is to build a behavioral profile of a person by analyzing the
time variations of several quantitative or qualitative parameters recorded
through a provision of sensors installed in the home.

Stability Analysis for Regularized Least Squares Regression
We discuss stability for a class of learning algorithms with respect to noisy
labels. The algorithms we consider are for regression, and they involve the
minimization of regularized risk functionals, such as L(f) := 1/N sum_i
(f(x_i)-y_i)^2+ lambda ||f||_H^2. We shall call the algorithm `stable' if, when
y_i is a noisy version of f*(x_i) for some function f* in H, the output of the
algorithm converges to f* as the regularization term and noise simultaneously
vanish. We consider two flavors of this problem, one where a data set of N
points remains fixed, and the other where N -> infinity. For the case where N
-> infinity, we give conditions for convergence to f_E (the function which is
the expectation of y(x) for each x), as lambda -> 0. For the fixed N case, we
describe the limiting 'non-noisy', 'non-regularized' function f*, and give
conditions for convergence. In the process, we develop a set of tools for
dealing with functionals such as L(f), which are applicable to many other
problems in learning theory.

Probabilistic and Team PFIN-type Learning: General Properties
We consider the probability hierarchy for Popperian FINite learning and study
the general properties of this hierarchy. We prove that the probability
hierarchy is decidable, i.e. there exists an algorithm that receives p_1 and
p_2 and answers whether PFIN-type learning with the probability of success p_1
is equivalent to PFIN-type learning with the probability of success p_2.
  To prove our result, we analyze the topological structure of the probability
hierarchy. We prove that it is well-ordered in descending ordering and
order-equivalent to ordinal epsilon_0. This shows that the structure of the
hierarchy is very complicated.
  Using similar methods, we also prove that, for PFIN-type learning, team
learning and probabilistic learning are of the same power.

Non-asymptotic calibration and resolution
We analyze a new algorithm for probability forecasting of binary observations
on the basis of the available data, without making any assumptions about the
way the observations are generated. The algorithm is shown to be well
calibrated and to have good resolution for long enough sequences of
observations and for a suitable choice of its parameter, a kernel on the
Cartesian product of the forecast space $[0,1]$ and the data space. Our main
results are non-asymptotic: we establish explicit inequalities, shown to be
tight, for the performance of the algorithm.

Defensive forecasting for linear protocols
We consider a general class of forecasting protocols, called "linear
protocols", and discuss several important special cases, including multi-class
forecasting. Forecasting is formalized as a game between three players:
Reality, whose role is to generate observations; Forecaster, whose goal is to
predict the observations; and Skeptic, who tries to make money on any lack of
agreement between Forecaster's predictions and the actual observations. Our
main mathematical result is that for any continuous strategy for Skeptic in a
linear protocol there exists a strategy for Forecaster that does not allow
Skeptic's capital to grow. This result is a meta-theorem that allows one to
transform any continuous law of probability in a linear protocol into a
forecasting strategy whose predictions are guaranteed to satisfy this law. We
apply this meta-theorem to a weak law of large numbers in Hilbert spaces to
obtain a version of the K29 prediction algorithm for linear protocols and show
that this version also satisfies the attractive properties of proper
calibration and resolution under a suitable choice of its kernel parameter,
with no assumptions about the way the data is generated.

About one 3-parameter Model of Testing
This article offers a 3-parameter model of testing, with 1) the difference
between the ability level of the examinee and item difficulty; 2) the examinee
discrimination and 3) the item discrimination as model parameters.

On the Job Training
We propose a new framework for building and evaluating machine learning
algorithms. We argue that many real-world problems require an agent which must
quickly learn to respond to demands, yet can continue to perform and respond to
new training throughout its useful life. We give a framework for how such
agents can be built, describe several metrics for evaluating them, and show
that subtle changes in system construction can significantly affect agent
performance.

Multiresolution Kernels
We present in this work a new methodology to design kernels on data which is
structured with smaller components, such as text, images or sequences. This
methodology is a template procedure which can be applied on most kernels on
measures and takes advantage of a more detailed "bag of components"
representation of the objects. To obtain such a detailed description, we
consider possible decompositions of the original bag into a collection of
nested bags, following a prior knowledge on the objects' structure. We then
consider these smaller bags to compare two objects both in a detailed
perspective, stressing local matches between the smaller bags, and in a global
or coarse perspective, by considering the entire bag. This multiresolution
approach is likely to be best suited for tasks where the coarse approach is not
precise enough, and where a more subtle mixture of both local and global
similarities is necessary to compare objects. The approach presented here would
not be computationally tractable without a factorization trick that we
introduce before presenting promising results on an image retrieval task.

Defensive Universal Learning with Experts
This paper shows how universal learning can be achieved with expert advice.
To this aim, we specify an experts algorithm with the following
characteristics: (a) it uses only feedback from the actions actually chosen
(bandit setup), (b) it can be applied with countably infinite expert classes,
and (c) it copes with losses that may grow in time appropriately slowly. We
prove loss bounds against an adaptive adversary. From this, we obtain a master
algorithm for "reactive" experts problems, which means that the master's
actions may influence the behavior of the adversary. Our algorithm can
significantly outperform standard experts algorithms on such problems. Finally,
we combine it with a universal expert class. The resulting universal learner
performs -- in a certain sense -- almost as well as any computable strategy,
for any online decision problem. We also specify the (worst-case) convergence
speed, which is very slow.

FPL Analysis for Adaptive Bandits
A main problem of "Follow the Perturbed Leader" strategies for online
decision problems is that regret bounds are typically proven against oblivious
adversary. In partial observation cases, it was not clear how to obtain
performance guarantees against adaptive adversary, without worsening the
bounds. We propose a conceptually simple argument to resolve this problem.
Using this, a regret bound of O(t^(2/3)) for FPL in the adversarial multi-armed
bandit problem is shown. This bound holds for the common FPL variant using only
the observations from designated exploration rounds. Using all observations
allows for the stronger bound of O(t^(1/2)), matching the best bound known so
far (and essentially the known lower bound) for adversarial bandits.
Surprisingly, this variant does not even need explicit exploration, it is
self-stabilizing. However the sampling probabilities have to be either
externally provided or approximated to sufficient accuracy, using O(t^2 log t)
samples in each step.

Learning Optimal Augmented Bayes Networks
Naive Bayes is a simple Bayesian classifier with strong independence
assumptions among the attributes. This classifier, desipte its strong
independence assumptions, often performs well in practice. It is believed that
relaxing the independence assumptions of a naive Bayes classifier may improve
the classification accuracy of the resulting structure. While finding an
optimal unconstrained Bayesian Network (for most any reasonable scoring
measure) is an NP-hard problem, it is possible to learn in polynomial time
optimal networks obeying various structural restrictions. Several authors have
examined the possibilities of adding augmenting arcs between attributes of a
Naive Bayes classifier. Friedman, Geiger and Goldszmidt define the TAN
structure in which the augmenting arcs form a tree on the attributes, and
present a polynomial time algorithm that learns an optimal TAN with respect to
MDL score. Keogh and Pazzani define Augmented Bayes Networks in which the
augmenting arcs form a forest on the attributes (a collection of trees, hence a
relaxation of the stuctural restriction of TAN), and present heuristic search
methods for learning good, though not optimal, augmenting arc sets. The
authors, however, evaluate the learned structure only in terms of observed
misclassification error and not against a scoring metric, such as MDL. In this
paper, we present a simple, polynomial time greedy algorithm for learning an
optimal Augmented Bayes Network with respect to MDL score.

Learning Unions of $Ï‰(1)$-Dimensional Rectangles
We consider the problem of learning unions of rectangles over the domain
$[b]^n$, in the uniform distribution membership query learning setting, where
both b and n are "large". We obtain poly$(n, \log b)$-time algorithms for the
following classes:
  - poly$(n \log b)$-way Majority of $O(\frac{\log(n \log b)} {\log \log(n \log
b)})$-dimensional rectangles.
  - Union of poly$(\log(n \log b))$ many $O(\frac{\log^2 (n \log b)} {(\log
\log(n \log b) \log \log \log (n \log b))^2})$-dimensional rectangles.
  - poly$(n \log b)$-way Majority of poly$(n \log b)$-Or of disjoint
$O(\frac{\log(n \log b)} {\log \log(n \log b)})$-dimensional rectangles.
  Our main algorithmic tool is an extension of Jackson's boosting- and
Fourier-based Harmonic Sieve algorithm [Jackson 1997] to the domain $[b]^n$,
building on work of [Akavia, Goldwasser, Safra 2003]. Other ingredients used to
obtain the results stated above are techniques from exact learning [Beimel,
Kushilevitz 1998] and ideas from recent work on learning augmented $AC^{0}$
circuits [Jackson, Klivans, Servedio 2002] and on representing Boolean
functions as thresholds of parities [Klivans, Servedio 2001].

On-line regression competitive with reproducing kernel Hilbert spaces
We consider the problem of on-line prediction of real-valued labels, assumed
bounded in absolute value by a known constant, of new objects from known
labeled objects. The prediction algorithm's performance is measured by the
squared deviation of the predictions from the actual labels. No stochastic
assumptions are made about the way the labels and objects are generated.
Instead, we are given a benchmark class of prediction rules some of which are
hoped to produce good predictions. We show that for a wide range of
infinite-dimensional benchmark classes one can construct a prediction algorithm
whose cumulative loss over the first N examples does not exceed the cumulative
loss of any prediction rule in the class plus O(sqrt(N)); the main differences
from the known results are that we do not impose any upper bound on the norm of
the considered prediction rules and that we achieve an optimal leading term in
the excess loss of our algorithm. If the benchmark class is "universal" (dense
in the class of continuous functions on each compact set), this provides an
on-line non-stochastic analogue of universally consistent prediction in
non-parametric statistics. We use two proof techniques: one is based on the
Aggregating Algorithm and the other on the recently developed method of
defensive forecasting.

Bounds on Query Convergence
The problem of finding an optimum using noisy evaluations of a smooth cost
function arises in many contexts, including economics, business, medicine,
experiment design, and foraging theory. We derive an asymptotic bound E[ (x_t -
x*)^2 ] >= O(1/sqrt(t)) on the rate of convergence of a sequence (x_0, x_1,
>...) generated by an unbiased feedback process observing noisy evaluations of
an unknown quadratic function maximised at x*. The bound is tight, as the proof
leads to a simple algorithm which meets it. We further establish a bound on the
total regret, E[ sum_{i=1..t} (x_i - x*)^2 ] >= O(sqrt(t)) These bounds may
impose practical limitations on an agent's performance, as O(eps^-4) queries
are made before the queries converge to x* with eps accuracy.

Preference Learning in Terminology Extraction: A ROC-based approach
A key data preparation step in Text Mining, Term Extraction selects the
terms, or collocation of words, attached to specific concepts. In this paper,
the task of extracting relevant collocations is achieved through a supervised
learning algorithm, exploiting a few collocations manually labelled as
relevant/irrelevant. The candidate terms are described along 13 standard
statistical criteria measures. From these examples, an evolutionary learning
algorithm termed Roger, based on the optimization of the Area under the ROC
curve criterion, extracts an order on the candidate terms. The robustness of
the approach is demonstrated on two real-world domain applications, considering
different domains (biology and human resources) and different languages
(English and French).

Competing with wild prediction rules
We consider the problem of on-line prediction competitive with a benchmark
class of continuous but highly irregular prediction rules. It is known that if
the benchmark class is a reproducing kernel Hilbert space, there exists a
prediction algorithm whose average loss over the first N examples does not
exceed the average loss of any prediction rule in the class plus a "regret
term" of O(N^(-1/2)). The elements of some natural benchmark classes, however,
are so irregular that these classes are not Hilbert spaces. In this paper we
develop Banach-space methods to construct a prediction algorithm with a regret
term of O(N^(-1/p)), where p is in [2,infty) and p-2 reflects the degree to
which the benchmark class fails to be a Hilbert space.

Genetic Programming, Validation Sets, and Parsimony Pressure
Fitness functions based on test cases are very common in Genetic Programming
(GP). This process can be assimilated to a learning task, with the inference of
models from a limited number of samples. This paper is an investigation on two
methods to improve generalization in GP-based learning: 1) the selection of the
best-of-run individuals using a three data sets methodology, and 2) the
application of parsimony pressure in order to reduce the complexity of the
solutions. Results using GP in a binary classification setup show that while
the accuracy on the test sets is preserved, with less variances compared to
baseline results, the mean tree size obtained with the tested methods is
significantly reduced.

Processing of Test Matrices with Guessing Correction
It is suggested to insert into test matrix 1s for correct responses, 0s for
response refusals, and negative corrective elements for incorrect responses.
With the classical test theory approach test scores of examinees and items are
calculated traditionally as sums of matrix elements, organized in rows and
columns. Correlation coefficients are estimated using correction coefficients.
In item response theory approach examinee and item logits are estimated using
maximum likelihood method and probabilities of all matrix elements.

Learning rational stochastic languages
Given a finite set of words w1,...,wn independently drawn according to a
fixed unknown distribution law P called a stochastic language, an usual goal in
Grammatical Inference is to infer an estimate of P in some class of
probabilistic models, such as Probabilistic Automata (PA). Here, we study the
class of rational stochastic languages, which consists in stochastic languages
that can be generated by Multiplicity Automata (MA) and which strictly includes
the class of stochastic languages generated by PA. Rational stochastic
languages have minimal normal representation which may be very concise, and
whose parameters can be efficiently estimated from stochastic samples. We
design an efficient inference algorithm DEES which aims at building a minimal
normal representation of the target. Despite the fact that no recursively
enumerable class of MA computes exactly the set of rational stochastic
languages over Q, we show that DEES strongly identifies tis set in the limit.
We study the intermediary MA output by DEES and show that they compute rational
series which converge absolutely to one and which can be used to provide
stochastic languages which closely estimate the target.

General Discounting versus Average Reward
Consider an agent interacting with an environment in cycles. In every
interaction cycle the agent is rewarded for its performance. We compare the
average reward U from cycle 1 to m (average value) with the future discounted
reward V from cycle k to infinity (discounted value). We consider essentially
arbitrary (non-geometric) discount sequences and arbitrary reward sequences
(non-MDP environments). We show that asymptotically U for m->infinity and V for
k->infinity are equal, provided both limits exist. Further, if the effective
horizon grows linearly with k or faster, then existence of the limit of U
implies that the limit of V exists. Conversely, if the effective horizon grows
linearly with k or slower, then existence of the limit of V implies that the
limit of U exists.

On Sequence Prediction for Arbitrary Measures
Suppose we are given two probability measures on the set of one-way infinite
finite-alphabet sequences and consider the question when one of the measures
predicts the other, that is, when conditional probabilities converge (in a
certain sense) when one of the measures is chosen to generate the sequence.
This question may be considered a refinement of the problem of sequence
prediction in its most general formulation: for a given class of probability
measures, does there exist a measure which predicts all of the measures in the
class? To address this problem, we find some conditions on local absolute
continuity which are sufficient for prediction and which generalize several
different notions which are known to be sufficient for prediction. We also
formulate some open questions to outline a direction for finding the conditions
on classes of measures for which prediction is possible.

Predictions as statements and decisions
Prediction is a complex notion, and different predictors (such as people,
computer programs, and probabilistic theories) can pursue very different goals.
In this paper I will review some popular kinds of prediction and argue that the
theory of competitive on-line learning can benefit from the kinds of prediction
that are now foreign to it.

PAC Classification based on PAC Estimates of Label Class Distributions
A standard approach in pattern classification is to estimate the
distributions of the label classes, and then to apply the Bayes classifier to
the estimates of the distributions in order to classify unlabeled examples. As
one might expect, the better our estimates of the label class distributions,
the better the resulting classifier will be. In this paper we make this
observation precise by identifying risk bounds of a classifier in terms of the
quality of the estimates of the label class distributions. We show how PAC
learnability relates to estimates of the distributions that have a PAC
guarantee on their $L_1$ distance from the true distribution, and we bound the
increase in negative log likelihood risk in terms of PAC bounds on the
KL-divergence. We give an inefficient but general-purpose smoothing method for
converting an estimated distribution that is good under the $L_1$ metric into a
distribution that is good under the KL-divergence.

Competing with stationary prediction strategies
In this paper we introduce the class of stationary prediction strategies and
construct a prediction algorithm that asymptotically performs as well as the
best continuous stationary strategy. We make mild compactness assumptions but
no stochastic assumptions about the environment. In particular, no assumption
of stationarity is made about the environment, and the stationarity of the
considered strategies only means that they do not depend explicitly on time; we
argue that it is natural to consider only stationary strategies even for highly
non-stationary environments.

Using Pseudo-Stochastic Rational Languages in Probabilistic Grammatical
  Inference
In probabilistic grammatical inference, a usual goal is to infer a good
approximation of an unknown distribution P called a stochastic language. The
estimate of P stands in some class of probabilistic models such as
probabilistic automata (PA). In this paper, we focus on probabilistic models
based on multiplicity automata (MA). The stochastic languages generated by MA
are called rational stochastic languages; they strictly include stochastic
languages generated by PA; they also admit a very concise canonical
representation. Despite the fact that this class is not recursively enumerable,
it is efficiently identifiable in the limit by using the algorithm DEES,
introduced by the authors in a previous paper. However, the identification is
not proper and before the convergence of the algorithm, DEES can produce MA
that do not define stochastic languages. Nevertheless, it is possible to use
these MA to define stochastic languages. We show that they belong to a broader
class of rational series, that we call pseudo-stochastic rational languages.
The aim of this paper is twofold. First we provide a theoretical study of
pseudo-stochastic rational languages, the languages output by DEES, showing for
example that this class is decidable within polynomial time. Second, we have
carried out a lot of experiments in order to compare DEES to classical
inference algorithms such as ALERGIA and MDI. They show that DEES outperforms
them in most cases.

Logical settings for concept learning from incomplete examples in First
  Order Logic
We investigate here concept learning from incomplete examples. Our first
purpose is to discuss to what extent logical learning settings have to be
modified in order to cope with data incompleteness. More precisely we are
interested in extending the learning from interpretations setting introduced by
L. De Raedt that extends to relational representations the classical
propositional (or attribute-value) concept learning from examples framework. We
are inspired here by ideas presented by H. Hirsh in a work extending the
Version space inductive paradigm to incomplete data. H. Hirsh proposes to
slightly modify the notion of solution when dealing with incomplete examples: a
solution has to be a hypothesis compatible with all pieces of information
concerning the examples. We identify two main classes of incompleteness. First,
uncertainty deals with our state of knowledge concerning an example. Second,
generalization (or abstraction) deals with what part of the description of the
example is sufficient for the learning purpose. These two main sources of
incompleteness can be mixed up when only part of the useful information is
known. We discuss a general learning setting, referred to as "learning from
possibilities" that formalizes these ideas, then we present a more specific
learning setting, referred to as "assumption-based learning" that cope with
examples which uncertainty can be reduced when considering contextual
information outside of the proper description of the examples. Assumption-based
learning is illustrated on a recent work concerning the prediction of a
consensus secondary structure common to a set of RNA sequences.

A Theory of Probabilistic Boosting, Decision Trees and Matryoshki
We present a theory of boosting probabilistic classifiers. We place ourselves
in the situation of a user who only provides a stopping parameter and a
probabilistic weak learner/classifier and compare three types of boosting
algorithms: probabilistic Adaboost, decision tree, and tree of trees of ... of
trees, which we call matryoshka. "Nested tree," "embedded tree" and "recursive
tree" are also appropriate names for this algorithm, which is one of our
contributions. Our other contribution is the theoretical analysis of the
algorithms, in which we give training error bounds. This analysis suggests that
the matryoshka leverages probabilistic weak classifiers more efficiently than
simple decision trees.

Leading strategies in competitive on-line prediction
We start from a simple asymptotic result for the problem of on-line
regression with the quadratic loss function: the class of continuous
limited-memory prediction strategies admits a "leading prediction strategy",
which not only asymptotically performs at least as well as any continuous
limited-memory strategy but also satisfies the property that the excess loss of
any continuous limited-memory strategy is determined by how closely it imitates
the leading strategy. More specifically, for any class of prediction strategies
constituting a reproducing kernel Hilbert space we construct a leading
strategy, in the sense that the loss of any prediction strategy whose norm is
not too large is determined by how closely it imitates the leading strategy.
This result is extended to the loss functions given by Bregman divergences and
by strictly proper scoring rules.

Competing with Markov prediction strategies
Assuming that the loss function is convex in the prediction, we construct a
prediction strategy universal for the class of Markov prediction strategies,
not necessarily continuous. Allowing randomization, we remove the requirement
of convexity.

A Study on Learnability for Rigid Lambek Grammars
We present basic notions of Gold's "learnability in the limit" paradigm,
first presented in 1967, a formalization of the cognitive process by which a
native speaker gets to grasp the underlying grammar of his/her own native
language by being exposed to well formed sentences generated by that grammar.
Then we present Lambek grammars, a formalism issued from categorial grammars
which, although not as expressive as needed for a full formalization of natural
languages, is particularly suited to easily implement a natural interface
between syntax and semantics. In the last part of this work, we present a
learnability result for Rigid Lambek grammars from structured examples.

A Massive Local Rules Search Approach to the Classification Problem
An approach to the classification problem of machine learning, based on
building local classification rules, is developed. The local rules are
considered as projections of the global classification rules to the event we
want to classify. A massive global optimization algorithm is used for
optimization of quality criterion. The algorithm, which has polynomial
complexity in typical case, is used to find all high--quality local rules. The
other distinctive feature of the algorithm is the integration of attributes
levels selection (for ordered attributes) with rules searching and original
conflicting rules resolution strategy. The algorithm is practical; it was
tested on a number of data sets from UCI repository, and a comparison with the
other predicting techniques is presented.

Metric entropy in competitive on-line prediction
Competitive on-line prediction (also known as universal prediction of
individual sequences) is a strand of learning theory avoiding making any
stochastic assumptions about the way the observations are generated. The
predictor's goal is to compete with a benchmark class of prediction rules,
which is often a proper Banach function space. Metric entropy provides a
unifying framework for competitive on-line prediction: the numerous known upper
bounds on the metric entropy of various compact sets in function spaces readily
imply bounds on the performance of on-line prediction strategies. This paper
discusses strengths and limitations of the direct approach to competitive
on-line prediction via metric entropy, including comparisons to other
approaches.

PAC Learning Mixtures of Axis-Aligned Gaussians with No Separation
  Assumption
We propose and analyze a new vantage point for the learning of mixtures of
Gaussians: namely, the PAC-style model of learning probability distributions
introduced by Kearns et al. Here the task is to construct a hypothesis mixture
of Gaussians that is statistically indistinguishable from the actual mixture
generating the data; specifically, the KL-divergence should be at most epsilon.
  In this scenario, we give a poly(n/epsilon)-time algorithm that learns the
class of mixtures of any constant number of axis-aligned Gaussians in
n-dimensional Euclidean space. Our algorithm makes no assumptions about the
separation between the means of the Gaussians, nor does it have any dependence
on the minimum mixing weight. This is in contrast to learning results known in
the ``clustering'' model, where such assumptions are unavoidable.
  Our algorithm relies on the method of moments, and a subalgorithm developed
in previous work by the authors (FOCS 2005) for a discrete mixture-learning
problem.

Hedging predictions in machine learning
Recent advances in machine learning make it possible to design efficient
prediction algorithms for data sets with huge numbers of parameters. This paper
describes a new technique for "hedging" the predictions output by many such
algorithms, including support vector machines, kernel ridge regression, kernel
nearest neighbours, and by many other state-of-the-art methods. The hedged
predictions for the labels of new objects include quantitative measures of
their own accuracy and reliability. These measures are provably valid under the
assumption of randomness, traditional in machine learning: the objects and
their labels are assumed to be generated independently from the same
probability distribution. In particular, it becomes possible to control (up to
statistical fluctuations) the number of erroneous predictions by selecting a
suitable confidence level. Validity being achieved automatically, the remaining
goal of hedged prediction is efficiency: taking full account of the new
objects' features and other available information to produce as accurate
predictions as possible. This can be done successfully using the powerful
machinery of modern machine learning.

A Unified View of TD Algorithms; Introducing Full-Gradient TD and
  Equi-Gradient Descent TD
This paper addresses the issue of policy evaluation in Markov Decision
Processes, using linear function approximation. It provides a unified view of
algorithms such as TD(lambda), LSTD(lambda), iLSTD, residual-gradient TD. It is
asserted that they all consist in minimizing a gradient function and differ by
the form of this function and their means of minimizing it. Two new schemes are
introduced in that framework: Full-gradient TD which uses a generalization of
the principle introduced in iLSTD, and EGD TD, which reduces the gradient by
successive equi-gradient descents. These three algorithms form a new
intermediate family with the interesting property of making much better use of
the samples than TD while keeping a gradient descent scheme, which is useful
for complexity issues and optimistic policy iteration.

Bandit Algorithms for Tree Search
Bandit based methods for tree search have recently gained popularity when
applied to huge trees, e.g. in the game of go (Gelly et al., 2006). The UCT
algorithm (Kocsis and Szepesvari, 2006), a tree search method based on Upper
Confidence Bounds (UCB) (Auer et al., 2002), is believed to adapt locally to
the effective smoothness of the tree. However, we show that UCT is too
``optimistic'' in some cases, leading to a regret O(exp(exp(D))) where D is the
depth of the tree. We propose alternative bandit algorithms for tree search.
First, a modification of UCT using a confidence sequence that scales
exponentially with the horizon depth is proven to have a regret O(2^D
\sqrt{n}), but does not adapt to possible smoothness in the tree. We then
analyze Flat-UCB performed on the leaves and provide a finite regret bound with
high probability. Then, we introduce a UCB-based Bandit Algorithm for Smooth
Trees which takes into account actual smoothness of the rewards for performing
efficient ``cuts'' of sub-optimal branches with high confidence. Finally, we
present an incremental tree search version which applies when the full tree is
too big (possibly infinite) to be entirely represented and show that with high
probability, essentially only the optimal branches is indefinitely developed.
We illustrate these methods on a global optimization problem of a Lipschitz
function, given noisy data.

Intrinsic dimension of a dataset: what properties does one expect?
We propose an axiomatic approach to the concept of an intrinsic dimension of
a dataset, based on a viewpoint of geometry of high-dimensional structures. Our
first axiom postulates that high values of dimension be indicative of the
presence of the curse of dimensionality (in a certain precise mathematical
sense). The second axiom requires the dimension to depend smoothly on a
distance between datasets (so that the dimension of a dataset and that of an
approximating principal manifold would be close to each other). The third axiom
is a normalization condition: the dimension of the Euclidean $n$-sphere $\s^n$
is $\Theta(n)$. We give an example of a dimension function satisfying our
axioms, even though it is in general computationally unfeasible, and discuss a
computationally cheap function satisfying most but not all of our axioms (the
``intrinsic dimensionality'' of Ch\'avez et al.)

Parametric Learning and Monte Carlo Optimization
This paper uncovers and explores the close relationship between Monte Carlo
Optimization of a parametrized integral (MCO), Parametric machine-Learning
(PL), and `blackbox' or `oracle'-based optimization (BO). We make four
contributions. First, we prove that MCO is mathematically identical to a broad
class of PL problems. This identity potentially provides a new application
domain for all broadly applicable PL techniques: MCO. Second, we introduce
immediate sampling, a new version of the Probability Collectives (PC) algorithm
for blackbox optimization. Immediate sampling transforms the original BO
problem into an MCO problem. Accordingly, by combining these first two
contributions, we can apply all PL techniques to BO. In our third contribution
we validate this way of improving BO by demonstrating that cross-validation and
bagging improve immediate sampling. Finally, conventional MC and MCO procedures
ignore the relationship between the sample point locations and the associated
values of the integrand; only the values of the integrand at those locations
are considered. We demonstrate that one can exploit the sample location
information using PL techniques, for example by forming a fit of the sample
locations to the associated values of the integrand. This provides an
additional way to apply PL techniques to improve MCO.

Supervised Feature Selection via Dependence Estimation
We introduce a framework for filtering features that employs the
Hilbert-Schmidt Independence Criterion (HSIC) as a measure of dependence
between the features and the labels. The key idea is that good features should
maximise such dependence. Feature selection for various supervised learning
problems (including classification and regression) is unified under this
framework, and the solutions can be approximated using a backward-elimination
algorithm. We demonstrate the usefulness of our method on both artificial and
real world datasets.

Consistency of the group Lasso and multiple kernel learning
We consider the least-square regression problem with regularization by a
block 1-norm, i.e., a sum of Euclidean norms over spaces of dimensions larger
than one. This problem, referred to as the group Lasso, extends the usual
regularization by the 1-norm where all spaces have dimension one, where it is
commonly referred to as the Lasso. In this paper, we study the asymptotic model
consistency of the group Lasso. We derive necessary and sufficient conditions
for the consistency of group Lasso under practical assumptions, such as model
misspecification. When the linear predictors and Euclidean norms are replaced
by functions and reproducing kernel Hilbert norms, the problem is usually
referred to as multiple kernel learning and is commonly used for learning from
heterogeneous data sources and for non linear variable selection. Using tools
from functional analysis, and in particular covariance operators, we extend the
consistency results to this infinite dimensional case and also propose an
adaptive scheme to obtain a consistent model estimate, even when the necessary
condition required for the non adaptive scheme is not satisfied.

Cost-minimising strategies for data labelling : optimal stopping and
  active learning
Supervised learning deals with the inference of a distribution over an output
or label space $\CY$ conditioned on points in an observation space $\CX$, given
a training dataset $D$ of pairs in $\CX \times \CY$. However, in a lot of
applications of interest, acquisition of large amounts of observations is easy,
while the process of generating labels is time-consuming or costly. One way to
deal with this problem is {\em active} learning, where points to be labelled
are selected with the aim of creating a model with better performance than that
of an model trained on an equal number of randomly sampled points. In this
paper, we instead propose to deal with the labelling cost directly: The
learning goal is defined as the minimisation of a cost which is a function of
the expected model performance and the total cost of the labels used. This
allows the development of general strategies and specific algorithms for (a)
optimal stopping, where the expected cost dictates whether label acquisition
should continue (b) empirical evaluation, where the cost is used as a
performance metric for a given combination of inference, stopping and sampling
methods. Though the main focus of the paper is optimal stopping, we also aim to
provide the background for further developments and discussion in the related
field of active learning.

Defensive forecasting for optimal prediction with expert advice
The method of defensive forecasting is applied to the problem of prediction
with expert advice for binary outcomes. It turns out that defensive forecasting
is not only competitive with the Aggregating Algorithm but also handles the
case of "second-guessing" experts, whose advice depends on the learner's
prediction; this paper assumes that the dependence on the learner's prediction
is continuous.

Continuous and randomized defensive forecasting: unified view
Defensive forecasting is a method of transforming laws of probability (stated
in game-theoretic terms as strategies for Sceptic) into forecasting algorithms.
There are two known varieties of defensive forecasting: "continuous", in which
Sceptic's moves are assumed to depend on the forecasts in a (semi)continuous
manner and which produces deterministic forecasts, and "randomized", in which
the dependence of Sceptic's moves on the forecasts is arbitrary and
Forecaster's moves are allowed to be randomized. This note shows that the
randomized variety can be obtained from the continuous variety by smearing
Sceptic's moves to make them continuous.

Filtering Additive Measurement Noise with Maximum Entropy in the Mean
The purpose of this note is to show how the method of maximum entropy in the
mean (MEM) may be used to improve parametric estimation when the measurements
are corrupted by large level of noise. The method is developed in the context
on a concrete example: that of estimation of the parameter in an exponential
distribution. We compare the performance of our method with the bayesian and
maximum likelihood approaches.

Prediction with expert advice for the Brier game
We show that the Brier game of prediction is mixable and find the optimal
learning rate and substitution function for it. The resulting prediction
algorithm is applied to predict results of football and tennis matches. The
theoretical performance guarantee turns out to be rather tight on these data
sets, especially in the case of the more extensive tennis data.

Consistency of trace norm minimization
Regularization by the sum of singular values, also referred to as the trace
norm, is a popular technique for estimating low rank rectangular matrices. In
this paper, we extend some of the consistency results of the Lasso to provide
necessary and sufficient conditions for rank consistency of trace norm
minimization with the square loss. We also provide an adaptive version that is
rank consistent even when the necessary condition for the non adaptive version
is not fulfilled.

Clustering with Transitive Distance and K-Means Duality
Recent spectral clustering methods are a propular and powerful technique for
data clustering. These methods need to solve the eigenproblem whose
computational complexity is $O(n^3)$, where $n$ is the number of data samples.
In this paper, a non-eigenproblem based clustering method is proposed to deal
with the clustering problem. Its performance is comparable to the spectral
clustering algorithms but it is more efficient with computational complexity
$O(n^2)$. We show that with a transitive distance and an observed property,
called K-means duality, our algorithm can be used to handle data sets with
complex cluster shapes, multi-scale clusters, and noise. Moreover, no
parameters except the number of clusters need to be set in our algorithm.

Covariance and PCA for Categorical Variables
Covariances from categorical variables are defined using a regular simplex
expression for categories. The method follows the variance definition by Gini,
and it gives the covariance as a solution of simultaneous equations. The
calculated results give reasonable values for test data. A method of principal
component analysis (RS-PCA) is also proposed using regular simplex expressions,
which allows easy interpretation of the principal components. The proposed
methods apply to variable selection problem of categorical data USCensus1990
data. The proposed methods give appropriate criterion for the variable
selection problem of categorical

On the Relationship between the Posterior and Optimal Similarity
For a classification problem described by the joint density $P(\omega,x)$,
models of $P(\omega\eq\omega'|x,x')$ (the ``Bayesian similarity measure'') have
been shown to be an optimal similarity measure for nearest neighbor
classification. This paper analyzes demonstrates several additional properties
of that conditional distribution. The paper first shows that we can
reconstruct, up to class labels, the class posterior distribution $P(\omega|x)$
given $P(\omega\eq\omega'|x,x')$, gives a procedure for recovering the class
labels, and gives an asymptotically Bayes-optimal classification procedure. It
also shows, given such an optimal similarity measure, how to construct a
classifier that outperforms the nearest neighbor classifier and achieves
Bayes-optimal classification rates. The paper then analyzes Bayesian similarity
in a framework where a classifier faces a number of related classification
tasks (multitask learning) and illustrates that reconstruction of the class
posterior distribution is not possible in general. Finally, the paper
identifies a distinct class of classification problems using
$P(\omega\eq\omega'|x,x')$ and shows that using $P(\omega\eq\omega'|x,x')$ to
solve those problems is the Bayes optimal solution.

Equations of States in Singular Statistical Estimation
Learning machines which have hierarchical structures or hidden variables are
singular statistical models because they are nonidentifiable and their Fisher
information matrices are singular. In singular statistical models, neither the
Bayes a posteriori distribution converges to the normal distribution nor the
maximum likelihood estimator satisfies asymptotic normality. This is the main
reason why it has been difficult to predict their generalization performances
from trained states. In this paper, we study four errors, (1) Bayes
generalization error, (2) Bayes training error, (3) Gibbs generalization error,
and (4) Gibbs training error, and prove that there are mathematical relations
among these errors. The formulas proved in this paper are equations of states
in statistical estimation because they hold for any true distribution, any
parametric model, and any a priori distribution. Also we show that Bayes and
Gibbs generalization errors are estimated by Bayes and Gibbs training errors,
and propose widely applicable information criteria which can be applied to both
regular and singular statistical models.

Density estimation in linear time
We consider the problem of choosing a density estimate from a set of
distributions F, minimizing the L1-distance to an unknown distribution
(Devroye, Lugosi 2001). Devroye and Lugosi analyze two algorithms for the
problem: Scheffe tournament winner and minimum distance estimate. The Scheffe
tournament estimate requires fewer computations than the minimum distance
estimate, but has strictly weaker guarantees than the latter.
  We focus on the computational aspect of density estimation. We present two
algorithms, both with the same guarantee as the minimum distance estimate. The
first one, a modification of the minimum distance estimate, uses the same
number (quadratic in |F|) of computations as the Scheffe tournament. The second
one, called ``efficient minimum loss-weight estimate,'' uses only a linear
number of computations, assuming that F is preprocessed.
  We also give examples showing that the guarantees of the algorithms cannot be
improved and explore randomized algorithms for density estimation.

Graph kernels between point clouds
Point clouds are sets of points in two or three dimensions. Most kernel
methods for learning on sets of points have not yet dealt with the specific
geometrical invariances and practical constraints associated with point clouds
in computer vision and graphics. In this paper, we present extensions of graph
kernels for point clouds, which allow to use kernel methods for such ob jects
as shapes, line drawings, or any three-dimensional point clouds. In order to
design rich and numerically efficient kernels with as few free parameters as
possible, we use kernels between covariance matrices and their factorizations
on graphical models. We derive polynomial time dynamic programming recursions
and present applications to recognition of handwritten digits and Chinese
characters from few training examples.

Online variants of the cross-entropy method
The cross-entropy method is a simple but efficient method for global
optimization. In this paper we provide two online variants of the basic CEM,
together with a proof of convergence.

The optimal assignment kernel is not positive definite
We prove that the optimal assignment kernel, proposed recently as an attempt
to embed labeled graphs and more generally tuples of basic data to a Hilbert
space, is in fact not always positive definite.

New Estimation Procedures for PLS Path Modelling
Given R groups of numerical variables X1, ... XR, we assume that each group
is the result of one underlying latent variable, and that all latent variables
are bound together through a linear equation system. Moreover, we assume that
some explanatory latent variables may interact pairwise in one or more
equations. We basically consider PLS Path Modelling's algorithm to estimate
both latent variables and the model's coefficients. New "external" estimation
schemes are proposed that draw latent variables towards strong group structures
in a more flexible way. New "internal" estimation schemes are proposed to
enable PLSPM to make good use of variable group complementarity and to deal
with interactions. Application examples are given.

A New Approach to Collaborative Filtering: Operator Estimation with
  Spectral Regularization
We present a general approach for collaborative filtering (CF) using spectral
regularization to learn linear operators from "users" to the "objects" they
rate. Recent low-rank type matrix completion approaches to CF are shown to be
special cases. However, unlike existing regularization based CF methods, our
approach can be used to also incorporate information such as attributes of the
users or the objects -- a limitation of existing regularization based CF
methods. We then provide novel representer theorems that we use to develop new
estimation methods. We provide learning algorithms based on low-rank
decompositions, and test them on a standard CF dataset. The experiments
indicate the advantages of generalizing the existing regularization based CF
methods to incorporate related information about users and objects. Finally, we
show that certain multi-task learning methods can be also seen as special cases
of our proposed approach.

Multiple Random Oracles Are Better Than One
We study the problem of learning k-juntas given access to examples drawn from
a number of different product distributions. Thus we wish to learn a function f
: {-1,1}^n -> {-1,1} that depends on k (unknown) coordinates. While the best
known algorithms for the general problem of learning a k-junta require running
time of n^k * poly(n,2^k), we show that given access to k different product
distributions with biases separated by \gamma>0, the functions may be learned
in time poly(n,2^k,\gamma^{-k}). More generally, given access to t <= k
different product distributions, the functions may be learned in time n^{k/t} *
poly(n,2^k,\gamma^{-k}). Our techniques involve novel results in Fourier
analysis relating Fourier expansions with respect to different biases and a
generalization of Russo's formula.

Introduction to Relational Networks for Classification
The use of computational intelligence techniques for classification has been
used in numerous applications. This paper compares the use of a Multi Layer
Perceptron Neural Network and a new Relational Network on classifying the HIV
status of women at ante-natal clinics. The paper discusses the architecture of
the relational network and its merits compared to a neural network and most
other computational intelligence classifiers. Results gathered from the study
indicate comparable classification accuracies as well as revealed relationships
between data features in the classification data. Much higher classification
accuracies are recommended for future research in the area of HIV
classification as well as missing data estimation.

The Effect of Structural Diversity of an Ensemble of Classifiers on
  Classification Accuracy
This paper aims to showcase the measure of structural diversity of an
ensemble of 9 classifiers and then map a relationship between this structural
diversity and accuracy. The structural diversity was induced by having
different architectures or structures of the classifiers The Genetical
Algorithms (GA) were used to derive the relationship between diversity and the
classification accuracy by evolving the classifiers and then picking 9
classifiers out on an ensemble of 60 classifiers. It was found that as the
ensemble became diverse the accuracy improved. However at a certain diversity
measure the accuracy began to drop. The Kohavi-Wolpert variance method is used
to measure the diversity of the ensemble. A method of voting is used to
aggregate the results from each classifier. The lowest error was observed at a
diversity measure of 0.16 with a mean square error of 0.274, when taking 0.2024
as maximum diversity measured. The parameters that were varied were: the number
of hidden nodes, learning rate and the activation function.

A Quadratic Loss Multi-Class SVM
Using a support vector machine requires to set two types of hyperparameters:
the soft margin parameter C and the parameters of the kernel. To perform this
model selection task, the method of choice is cross-validation. Its
leave-one-out variant is known to produce an estimator of the generalization
error which is almost unbiased. Its major drawback rests in its time
requirement. To overcome this difficulty, several upper bounds on the
leave-one-out error of the pattern recognition SVM have been derived. Among
those bounds, the most popular one is probably the radius-margin bound. It
applies to the hard margin pattern recognition SVM, and by extension to the
2-norm SVM. In this report, we introduce a quadratic loss M-SVM, the M-SVM^2,
as a direct extension of the 2-norm SVM to the multi-class case. For this
machine, a generalized radius-margin bound is then established.

On Recovery of Sparse Signals via $\ell_1$ Minimization
This article considers constrained $\ell_1$ minimization methods for the
recovery of high dimensional sparse signals in three settings: noiseless,
bounded error and Gaussian noise. A unified and elementary treatment is given
in these noise settings for two $\ell_1$ minimization methods: the Dantzig
selector and $\ell_1$ minimization with an $\ell_2$ constraint. The results of
this paper improve the existing results in the literature by weakening the
conditions and tightening the error bounds. The improvement on the conditions
shows that signals with larger support can be recovered accurately. This paper
also establishes connections between restricted isometry property and the
mutual incoherence property. Some results of Candes, Romberg and Tao (2006) and
Donoho, Elad, and Temlyakov (2006) are extended.

The Margitron: A Generalised Perceptron with Margin
We identify the classical Perceptron algorithm with margin as a member of a
broader family of large margin classifiers which we collectively call the
Margitron. The Margitron, (despite its) sharing the same update rule with the
Perceptron, is shown in an incremental setting to converge in a finite number
of updates to solutions possessing any desirable fraction of the maximum
margin. Experiments comparing the Margitron with decomposition SVMs on tasks
involving linear kernels and 2-norm soft margin are also reported.

Sample Selection Bias Correction Theory
This paper presents a theoretical analysis of sample selection bias
correction. The sample bias correction technique commonly used in machine
learning consists of reweighting the cost of an error on each training point of
a biased sample to more closely reflect the unbiased distribution. This relies
on weights derived by various estimation techniques based on finite samples. We
analyze the effect of an error in that estimation on the accuracy of the
hypothesis returned by the learning algorithm for two estimation techniques: a
cluster-based estimation technique and kernel mean matching. We also report the
results of sample bias correction experiments with several data sets using
these techniques. Our analysis is based on the novel concept of distributional
stability which generalizes the existing concept of point-based stability. Much
of our work and proof techniques can be used to analyze other importance
weighting techniques and their effect on accuracy when using a distributionally
stable algorithm.

From Data Topology to a Modular Classifier
This article describes an approach to designing a distributed and modular
neural classifier. This approach introduces a new hierarchical clustering that
enables one to determine reliable regions in the representation space by
exploiting supervised information. A multilayer perceptron is then associated
with each of these detected clusters and charged with recognizing elements of
the associated cluster while rejecting all others. The obtained global
classifier is comprised of a set of cooperating neural networks and completed
by a K-nearest neighbor classifier charged with treating elements rejected by
all the neural networks. Experimental results for the handwritten digit
recognition problem and comparison with neural and statistical nonmodular
classifiers are given.

Utilisation des grammaires probabilistes dans les tÃ¢ches de
  segmentation et d'annotation prosodique
Nous pr\'esentons dans cette contribution une approche \`a la fois symbolique
et probabiliste permettant d'extraire l'information sur la segmentation du
signal de parole \`a partir d'information prosodique. Nous utilisons pour ce
faire des grammaires probabilistes poss\'edant une structure hi\'erarchique
minimale. La phase de construction des grammaires ainsi que leur pouvoir de
pr\'ediction sont \'evalu\'es qualitativement ainsi que quantitativement.
  -----
  Methodologically oriented, the present work sketches an approach for prosodic
information retrieval and speech segmentation, based on both symbolic and
probabilistic information. We have recourse to probabilistic grammars, within
which we implement a minimal hierarchical structure. Both the stages of
probabilistic grammar building and its testing in prediction are explored and
quantitatively and qualitatively evaluated.

Statistical Learning of Arbitrary Computable Classifiers
Statistical learning theory chiefly studies restricted hypothesis classes,
particularly those with finite Vapnik-Chervonenkis (VC) dimension. The
fundamental quantity of interest is the sample complexity: the number of
samples required to learn to a specified level of accuracy. Here we consider
learning over the set of all computable labeling functions. Since the
VC-dimension is infinite and a priori (uniform) bounds on the number of samples
are impossible, we let the learning algorithm decide when it has seen
sufficient samples to have learned. We first show that learning in this setting
is indeed possible, and develop a learning algorithm. We then show, however,
that bounding sample complexity independently of the distribution is
impossible. Notably, this impossibility is entirely due to the requirement that
the learning algorithm be computable, and not due to the statistical nature of
the problem.

Agnostically Learning Juntas from Random Walks
We prove that the class of functions g:{-1,+1}^n -> {-1,+1} that only depend
on an unknown subset of k<<n variables (so-called k-juntas) is agnostically
learnable from a random walk in time polynomial in n, 2^{k^2}, epsilon^{-k},
and log(1/delta). In other words, there is an algorithm with the claimed
running time that, given epsilon, delta > 0 and access to a random walk on
{-1,+1}^n labeled by an arbitrary function f:{-1,+1}^n -> {-1,+1}, finds with
probability at least 1-delta a k-junta that is (opt(f)+epsilon)-close to f,
where opt(f) denotes the distance of a closest k-junta to f.

Computationally Efficient Estimators for Dimension Reductions Using
  Stable Random Projections
The method of stable random projections is a tool for efficiently computing
the $l_\alpha$ distances using low memory, where $0<\alpha \leq 2$ is a tuning
parameter. The method boils down to a statistical estimation task and various
estimators have been proposed, based on the geometric mean, the harmonic mean,
and the fractional power etc.
  This study proposes the optimal quantile estimator, whose main operation is
selecting, which is considerably less expensive than taking fractional power,
the main operation in previous estimators. Our experiments report that the
optimal quantile estimator is nearly one order of magnitude more
computationally efficient than previous estimators. For large-scale learning
tasks in which storing and computing pairwise distances is a serious
bottleneck, this estimator should be desirable.
  In addition to its computational advantages, the optimal quantile estimator
exhibits nice theoretical properties. It is more accurate than previous
estimators when $\alpha>1$. We derive its theoretical error bounds and
establish the explicit (i.e., no hidden constants) sample complexity bound.

On Approximating the Lp Distances for p>2
Applications in machine learning and data mining require computing pairwise
Lp distances in a data matrix A. For massive high-dimensional data, computing
all pairwise distances of A can be infeasible. In fact, even storing A or all
pairwise distances of A in the memory may be also infeasible. This paper
proposes a simple method for p = 2, 4, 6, ... We first decompose the l_p (where
p is even) distances into a sum of 2 marginal norms and p-1 ``inner products''
at different orders. Then we apply normal or sub-Gaussian random projections to
approximate the resultant ``inner products,'' assuming that the marginal norms
can be computed exactly by a linear scan. We propose two strategies for
applying random projections. The basic projection strategy requires only one
projection matrix but it is more difficult to analyze, while the alternative
projection strategy requires p-1 projection matrices but its theoretical
analysis is much easier. In terms of the accuracy, at least for p=4, the basic
strategy is always more accurate than the alternative strategy if the data are
non-negative, which is common in reality.

Graph Kernels
We present a unified framework to study graph kernels, special cases of which
include the random walk graph kernel \citep{GaeFlaWro03,BorOngSchVisetal05},
marginalized graph kernel \citep{KasTsuIno03,KasTsuIno04,MahUedAkuPeretal04},
and geometric kernel on graphs \citep{Gaertner02}. Through extensions of linear
algebra to Reproducing Kernel Hilbert Spaces (RKHS) and reduction to a
Sylvester equation, we construct an algorithm that improves the time complexity
of kernel computation from $O(n^6)$ to $O(n^3)$. When the graphs are sparse,
conjugate gradient solvers or fixed-point iterations bring our algorithm into
the sub-cubic domain. Experiments on graphs from bioinformatics and other
application domains show that it is often more than a thousand times faster
than previous approaches. We then explore connections between diffusion kernels
\citep{KonLaf02}, regularization on graphs \citep{SmoKon03}, and graph kernels,
and use these connections to propose new graph kernels. Finally, we show that
rational kernels \citep{CorHafMoh02,CorHafMoh03,CorHafMoh04} when specialized
to graphs reduce to the random walk graph kernel.

On Probability Distributions for Trees: Representations, Inference and
  Learning
We study probability distributions over free algebras of trees. Probability
distributions can be seen as particular (formal power) tree series [Berstel et
al 82, Esik et al 03], i.e. mappings from trees to a semiring K . A widely
studied class of tree series is the class of rational (or recognizable) tree
series which can be defined either in an algebraic way or by means of
multiplicity tree automata. We argue that the algebraic representation is very
convenient to model probability distributions over a free algebra of trees.
First, as in the string case, the algebraic representation allows to design
learning algorithms for the whole class of probability distributions defined by
rational tree series. Note that learning algorithms for rational tree series
correspond to learning algorithms for weighted tree automata where both the
structure and the weights are learned. Second, the algebraic representation can
be easily extended to deal with unranked trees (like XML trees where a symbol
may have an unbounded number of children). Both properties are particularly
relevant for applications: nondeterministic automata are required for the
inference problem to be relevant (recall that Hidden Markov Models are
equivalent to nondeterministic string automata); nowadays applications for Web
Information Extraction, Web Services and document processing consider unranked
trees.

Positive factor networks: A graphical framework for modeling
  non-negative sequential data
We present a novel graphical framework for modeling non-negative sequential
data with hierarchical structure. Our model corresponds to a network of coupled
non-negative matrix factorization (NMF) modules, which we refer to as a
positive factor network (PFN). The data model is linear, subject to
non-negativity constraints, so that observation data consisting of an additive
combination of individually representable observations is also representable by
the network. This is a desirable property for modeling problems in
computational auditory scene analysis, since distinct sound sources in the
environment are often well-modeled as combining additively in the corresponding
magnitude spectrogram. We propose inference and learning algorithms that
leverage existing NMF algorithms and that are straightforward to implement. We
present a target tracking example and provide results for synthetic observation
data which serve to illustrate the interesting properties of PFNs and motivate
their potential usefulness in applications such as music transcription, source
separation, and speech recognition. We show how a target process characterized
by a hierarchical state transition model can be represented as a PFN. Our
results illustrate that a PFN which is defined in terms of a single target
observation can then be used to effectively track the states of multiple
simultaneous targets. Our results show that the quality of the inferred target
states degrades gradually as the observation noise is increased. We also
present results for an example in which meaningful hierarchical features are
extracted from a spectrogram. Such a hierarchical representation could be
useful for music transcription and source separation applications. We also
propose a network for language modeling.

When is there a representer theorem? Vector versus matrix regularizers
We consider a general class of regularization methods which learn a vector of
parameters on the basis of linear measurements. It is well known that if the
regularizer is a nondecreasing function of the inner product then the learned
vector is a linear combination of the input data. This result, known as the
{\em representer theorem}, is at the basis of kernel-based methods in machine
learning. In this paper, we prove the necessity of the above condition, thereby
completing the characterization of kernel methods based on regularization. We
further extend our analysis to regularization methods which learn a matrix, a
problem which is motivated by the application to multi-task learning. In this
context, we study a more general representer theorem, which holds for a larger
class of regularizers. We provide a necessary and sufficient condition for
these class of matrix regularizers and highlight them with some concrete
examples of practical importance. Our analysis uses basic principles from
matrix theory, especially the useful notion of matrix nondecreasing function.

Clustered Multi-Task Learning: A Convex Formulation
In multi-task learning several related tasks are considered simultaneously,
with the hope that by an appropriate sharing of information across tasks, each
task may benefit from the others. In the context of learning linear functions
for supervised classification or regression, this can be achieved by including
a priori information about the weight vectors associated with the tasks, and
how they are expected to be related to each other. In this paper, we assume
that tasks are clustered into groups, which are unknown beforehand, and that
tasks within a group have similar weight vectors. We design a new spectral norm
that encodes this a priori assumption, without the prior knowledge of the
partition of tasks into groups, resulting in a new convex optimization
formulation for multi-task learning. We show in simulations on synthetic
examples and on the IEDB MHC-I binding dataset, that our approach outperforms
well-known convex methods for multi-task learning, as well as related non
convex methods dedicated to the same problem.

Surrogate Learning - An Approach for Semi-Supervised Classification
We consider the task of learning a classifier from the feature space
$\mathcal{X}$ to the set of classes $\mathcal{Y} = \{0, 1\}$, when the features
can be partitioned into class-conditionally independent feature sets
$\mathcal{X}_1$ and $\mathcal{X}_2$. We show the surprising fact that the
class-conditional independence can be used to represent the original learning
task in terms of 1) learning a classifier from $\mathcal{X}_2$ to
$\mathcal{X}_1$ and 2) learning the class-conditional distribution of the
feature set $\mathcal{X}_1$. This fact can be exploited for semi-supervised
learning because the former task can be accomplished purely from unlabeled
samples. We present experimental evaluation of the idea in two real world
applications.

Learning Isometric Separation Maps
Maximum Variance Unfolding (MVU) and its variants have been very successful
in embedding data-manifolds in lower dimensional spaces, often revealing the
true intrinsic dimension. In this paper we show how to also incorporate
supervised class information into an MVU-like method without breaking its
convexity. We call this method the Isometric Separation Map and we show that
the resulting kernel matrix can be used as a binary/multiclass Support Vector
Machine-like method in a semi-supervised (transductive) framework. We also show
that the method always finds a kernel matrix that linearly separates the
training data exactly without projecting them in infinite dimensional spaces.
In traditional SVMs we choose a kernel and hope that the data become linearly
separable in the kernel space. In this paper we show how the hyperplane can be
chosen ad-hoc and the kernel is trained so that data are always linearly
separable. Comparisons with Large Margin SVMs show comparable performance.

Entropy, Perception, and Relativity
In this paper, I expand Shannon's definition of entropy into a new form of
entropy that allows integration of information from different random events.
Shannon's notion of entropy is a special case of my more general definition of
entropy. I define probability using a so-called performance function, which is
de facto an exponential distribution. Assuming that my general notion of
entropy reflects the true uncertainty about a probabilistic event, I understand
that our perceived uncertainty differs. I claim that our perception is the
result of two opposing forces similar to the two famous antagonists in Chinese
philosophy: Yin and Yang. Based on this idea, I show that our perceived
uncertainty matches the true uncertainty in points determined by the golden
ratio. I demonstrate that the well-known sigmoid function, which we typically
employ in artificial neural networks as a non-linear threshold function,
describes the actual performance. Furthermore, I provide a motivation for the
time dilation in Einstein's Special Relativity, basically claiming that
although time dilation conforms with our perception, it does not correspond to
reality. At the end of the paper, I show how to apply this theoretical
framework to practical applications. I present recognition rates for a pattern
recognition problem, and also propose a network architecture that can take
advantage of general entropy to solve complex decision problems.

Stability Bound for Stationary Phi-mixing and Beta-mixing Processes
Most generalization bounds in learning theory are based on some measure of
the complexity of the hypothesis class used, independently of any algorithm. In
contrast, the notion of algorithmic stability can be used to derive tight
generalization bounds that are tailored to specific learning algorithms by
exploiting their particular properties. However, as in much of learning theory,
existing stability analyses and bounds apply only in the scenario where the
samples are independently and identically distributed. In many machine learning
applications, however, this assumption does not hold. The observations received
by the learning algorithm often have some inherent temporal dependence.
  This paper studies the scenario where the observations are drawn from a
stationary phi-mixing or beta-mixing sequence, a widely adopted assumption in
the study of non-i.i.d. processes that implies a dependence between
observations weakening over time. We prove novel and distinct stability-based
generalization bounds for stationary phi-mixing and beta-mixing sequences.
These bounds strictly generalize the bounds given in the i.i.d. case and apply
to all stable learning algorithms, thereby extending the use of
stability-bounds to non-i.i.d. scenarios.
  We also illustrate the application of our phi-mixing generalization bounds to
general classes of learning algorithms, including Support Vector Regression,
Kernel Ridge Regression, and Support Vector Machines, and many other kernel
regularization-based and relative entropy-based regularization algorithms.
These novel bounds can thus be viewed as the first theoretical basis for the
use of these algorithms in non-i.i.d. scenarios.

Land Cover Mapping Using Ensemble Feature Selection Methods
Ensemble classification is an emerging approach to land cover mapping whereby
the final classification output is a result of a consensus of classifiers.
Intuitively, an ensemble system should consist of base classifiers which are
diverse i.e. classifiers whose decision boundaries err differently. In this
paper ensemble feature selection is used to impose diversity in ensembles. The
features of the constituent base classifiers for each ensemble were created
through an exhaustive search algorithm using different separability indices.
For each ensemble, the classification accuracy was derived as well as a
diversity measure purported to give a measure of the inensemble diversity. The
correlation between ensemble classification accuracy and diversity measure was
determined to establish the interplay between the two variables. From the
findings of this paper, diversity measures as currently formulated do not
provide an adequate means upon which to constitute ensembles for land cover
mapping.

A Novel Clustering Algorithm Based on Quantum Random Walk
The enormous successes have been made by quantum algorithms during the last
decade. In this paper, we combine the quantum random walk (QRW) with the
problem of data clustering, and develop two clustering algorithms based on the
one dimensional QRW. Then, the probability distributions on the positions
induced by QRW in these algorithms are investigated, which also indicates the
possibility of obtaining better results. Consequently, the experimental results
have demonstrated that data points in datasets are clustered reasonably and
efficiently, and the clustering algorithms are of fast rates of convergence.
Moreover, the comparison with other algorithms also provides an indication of
the effectiveness of the proposed approach.

Convex Sparse Matrix Factorizations
We present a convex formulation of dictionary learning for sparse signal
decomposition. Convexity is obtained by replacing the usual explicit upper
bound on the dictionary size by a convex rank-reducing term similar to the
trace norm. In particular, our formulation introduces an explicit trade-off
between size and sparsity of the decomposition of rectangular matrices. Using a
large set of synthetic examples, we compare the estimation abilities of the
convex and non-convex approaches, showing that while the convex formulation has
a single local minimum, this may lead in some cases to performance which is
inferior to the local minima of the non-convex formulation.

Binary Classification Based on Potentials
We introduce a simple and computationally trivial method for binary
classification based on the evaluation of potential functions. We demonstrate
that despite the conceptual and computational simplicity of the method its
performance can match or exceed that of standard Support Vector Machine
methods.

Linearly Parameterized Bandits
We consider bandit problems involving a large (possibly infinite) collection
of arms, in which the expected reward of each arm is a linear function of an
$r$-dimensional random vector $\mathbf{Z} \in \mathbb{R}^r$, where $r \geq 2$.
The objective is to minimize the cumulative regret and Bayes risk. When the set
of arms corresponds to the unit sphere, we prove that the regret and Bayes risk
is of order $\Theta(r \sqrt{T})$, by establishing a lower bound for an
arbitrary policy, and showing that a matching upper bound is obtained through a
policy that alternates between exploration and exploitation phases. The
phase-based policy is also shown to be effective if the set of arms satisfies a
strong convexity condition. For the case of a general set of arms, we describe
a near-optimal policy whose regret and Bayes risk admit upper bounds of the
form $O(r \sqrt{T} \log^{3/2} T)$.

Importance Weighted Active Learning
We present a practical and statistically consistent scheme for actively
learning binary classifiers under general loss functions. Our algorithm uses
importance weighting to correct sampling bias, and by controlling the variance,
we are able to give rigorous label complexity bounds for the learning process.
Experiments on passively labeled data show that this approach reduces the label
complexity required to achieve good predictive performance on many learning
problems.

Distributed Preemption Decisions: Probabilistic Graphical Model,
  Algorithm and Near-Optimality
Cooperative decision making is a vision of future network management and
control. Distributed connection preemption is an important example where nodes
can make intelligent decisions on allocating resources and controlling traffic
flows for multi-class service networks. A challenge is that nodal decisions are
spatially dependent as traffic flows trespass multiple nodes in a network.
Hence the performance-complexity trade-off becomes important, i.e., how
accurate decisions are versus how much information is exchanged among nodes.
Connection preemption is known to be NP-complete. Centralized preemption is
optimal but computationally intractable. Decentralized preemption is
computationally efficient but may result in a poor performance. This work
investigates distributed preemption where nodes decide whether and which flows
to preempt using only local information exchange with neighbors. We develop,
based on the probabilistic graphical models, a near-optimal distributed
algorithm. The algorithm is used by each node to make collectively near-optimal
preemption decisions. We study trade-offs between near-optimal performance and
complexity that corresponds to the amount of information-exchange of the
distributed algorithm. The algorithm is validated by both analysis and
simulation.

A Limit Theorem in Singular Regression Problem
In statistical problems, a set of parameterized probability distributions is
used to estimate the true probability distribution. If Fisher information
matrix at the true distribution is singular, then it has been left unknown what
we can estimate about the true distribution from random samples. In this paper,
we study a singular regression problem and prove a limit theorem which shows
the relation between the singular regression problem and two birational
invariants, a real log canonical threshold and a singular fluctuation. The
obtained theorem has an important application to statistics, because it enables
us to estimate the generalization error from the training error without any
knowledge of the true probability distribution.

Cross-situational and supervised learning in the emergence of
  communication
Scenarios for the emergence or bootstrap of a lexicon involve the repeated
interaction between at least two agents who must reach a consensus on how to
name N objects using H words. Here we consider minimal models of two types of
learning algorithms: cross-situational learning, in which the individuals
determine the meaning of a word by looking for something in common across all
observed uses of that word, and supervised operant conditioning learning, in
which there is strong feedback between individuals about the intended meaning
of the words. Despite the stark differences between these learning schemes, we
show that they yield the same communication accuracy in the realistic limits of
large N and H, which coincides with the result of the classical occupancy
problem of randomly assigning N objects to H words.

Extraction de concepts sous contraintes dans des donnÃ©es d'expression
  de gÃ¨nes
In this paper, we propose a technique to extract constrained formal concepts.

Database Transposition for Constrained (Closed) Pattern Mining
Recently, different works proposed a new way to mine patterns in databases
with pathological size. For example, experiments in genome biology usually
provide databases with thousands of attributes (genes) but only tens of objects
(experiments). In this case, mining the "transposed" database runs through a
smaller search space, and the Galois connection allows to infer the closed
patterns of the original database. We focus here on constrained pattern mining
for those unusual databases and give a theoretical framework for database and
constraint transposition. We discuss the properties of constraint transposition
and look into classical constraints. We then address the problem of generating
the closed patterns of the original database satisfying the constraint,
starting from those mined in the "transposed" database. Finally, we show how to
generate all the patterns satisfying the constraint from the closed ones.

Multi-Label Prediction via Compressed Sensing
We consider multi-label prediction problems with large output spaces under
the assumption of output sparsity -- that the target (label) vectors have small
support. We develop a general theory for a variant of the popular error
correcting output code scheme, using ideas from compressed sensing for
exploiting this sparsity. The method can be regarded as a simple reduction from
multi-label regression problems to binary regression problems. We show that the
number of subproblems need only be logarithmic in the total number of possible
labels, making this approach radically more efficient than others. We also
state and prove robustness guarantees for this method in the form of regret
transform bounds (in general), and also provide a more detailed analysis for
the linear prediction setting.

Learning rules from multisource data for cardiac monitoring
This paper formalises the concept of learning symbolic rules from multisource
data in a cardiac monitoring context. Our sources, electrocardiograms and
arterial blood pressure measures, describe cardiac behaviours from different
viewpoints. To learn interpretable rules, we use an Inductive Logic Programming
(ILP) method. We develop an original strategy to cope with the dimensionality
issues caused by using this ILP technique on a rich multisource language. The
results show that our method greatly improves the feasibility and the
efficiency of the process while staying accurate. They also confirm the
benefits of using multiple sources to improve the diagnosis of cardiac
arrhythmias.

Uniqueness of Low-Rank Matrix Completion by Rigidity Theory
The problem of completing a low-rank matrix from a subset of its entries is
often encountered in the analysis of incomplete data sets exhibiting an
underlying factor model with applications in collaborative filtering, computer
vision and control. Most recent work had been focused on constructing efficient
algorithms for exact or approximate recovery of the missing matrix entries and
proving lower bounds for the number of known entries that guarantee a
successful recovery with high probability. A related problem from both the
mathematical and algorithmic point of view is the distance geometry problem of
realizing points in a Euclidean space from a given subset of their pairwise
distances. Rigidity theory answers basic questions regarding the uniqueness of
the realization satisfying a given partial set of distances. We observe that
basic ideas and tools of rigidity theory can be adapted to determine uniqueness
of low-rank matrix completion, where inner products play the role that
distances play in rigidity theory. This observation leads to an efficient
randomized algorithm for testing both local and global unique completion.
Crucial to our analysis is a new matrix, which we call the completion matrix,
that serves as the analogue of the rigidity matrix.

Prediction with expert evaluators' advice
We introduce a new protocol for prediction with expert advice in which each
expert evaluates the learner's and his own performance using a loss function
that may change over time and may be different from the loss functions used by
the other experts. The learner's goal is to perform better or not much worse
than each expert, as evaluated by that expert, for all experts simultaneously.
If the loss functions used by the experts are all proper scoring rules and all
mixable, we show that the defensive forecasting algorithm enjoys the same
performance guarantee as that attainable by the Aggregating Algorithm in the
standard setting and known to be optimal. This result is also applied to the
case of "specialist" (or "sleeping") experts. In this case, the defensive
forecasting algorithm reduces to a simple modification of the Aggregating
Algorithm.

Multiplicative updates For Non-Negative Kernel SVM
We present multiplicative updates for solving hard and soft margin support
vector machines (SVM) with non-negative kernels. They follow as a natural
extension of the updates for non-negative matrix factorization. No additional
param- eter setting, such as choosing learning, rate is required. Ex- periments
demonstrate rapid convergence to good classifiers. We analyze the rates of
asymptotic convergence of the up- dates and establish tight bounds. We test the
performance on several datasets using various non-negative kernels and report
equivalent generalization errors to that of a standard SVM.

Efficient Human Computation
Collecting large labeled data sets is a laborious and expensive task, whose
scaling up requires division of the labeling workload between many teachers.
When the number of classes is large, miscorrespondences between the labels
given by the different teachers are likely to occur, which, in the extreme
case, may reach total inconsistency. In this paper we describe how globally
consistent labels can be obtained, despite the absence of teacher coordination,
and discuss the possible efficiency of this process in terms of human labor. We
define a notion of label efficiency, measuring the ratio between the number of
globally consistent labels obtained and the number of labels provided by
distributed teachers. We show that the efficiency depends critically on the
ratio alpha between the number of data instances seen by a single teacher, and
the number of classes. We suggest several algorithms for the distributed
labeling problem, and analyze their efficiency as a function of alpha. In
addition, we provide an upper bound on label efficiency for the case of
completely uncoordinated teachers, and show that efficiency approaches 0 as the
ratio between the number of labels each teacher provides and the number of
classes drops (i.e. alpha goes to 0).

Differential Contrastive Divergence
This paper has been retracted.

On $p$-adic Classification
A $p$-adic modification of the split-LBG classification method is presented
in which first clusterings and then cluster centers are computed which locally
minimise an energy function. The outcome for a fixed dataset is independent of
the prime number $p$ with finitely many exceptions. The methods are applied to
the construction of $p$-adic classifiers in the context of learning.

Stability Analysis and Learning Bounds for Transductive Regression
  Algorithms
This paper uses the notion of algorithmic stability to derive novel
generalization bounds for several families of transductive regression
algorithms, both by using convexity and closed-form solutions. Our analysis
helps compare the stability of these algorithms. It also shows that a number of
widely used transductive regression algorithms are in fact unstable. Finally,
it reports the results of experiments with local transductive regression
demonstrating the benefit of our stability bounds for model selection, for one
of the algorithms, in particular for determining the radius of the local
neighborhood used by the algorithm.

Inferring Dynamic Bayesian Networks using Frequent Episode Mining
Motivation: Several different threads of research have been proposed for
modeling and mining temporal data. On the one hand, approaches such as dynamic
Bayesian networks (DBNs) provide a formal probabilistic basis to model
relationships between time-indexed random variables but these models are
intractable to learn in the general case. On the other, algorithms such as
frequent episode mining are scalable to large datasets but do not exhibit the
rigorous probabilistic interpretations that are the mainstay of the graphical
models literature.
  Results: We present a unification of these two seemingly diverse threads of
research, by demonstrating how dynamic (discrete) Bayesian networks can be
inferred from the results of frequent episode mining. This helps bridge the
modeling emphasis of the former with the counting emphasis of the latter.
First, we show how, under reasonable assumptions on data characteristics and on
influences of random variables, the optimal DBN structure can be computed using
a greedy, local, algorithm. Next, we connect the optimality of the DBN
structure with the notion of fixed-delay episodes and their counts of distinct
occurrences. Finally, to demonstrate the practical feasibility of our approach,
we focus on a specific (but broadly applicable) class of networks, called
excitatory networks, and show how the search for the optimal DBN structure can
be conducted using just information from frequent episodes. Application on
datasets gathered from mathematical models of spiking neurons as well as real
neuroscience datasets are presented.
  Availability: Algorithmic implementations, simulator codebases, and datasets
are available from our website at http://neural-code.cs.vt.edu/dbn

Introduction to Machine Learning: Class Notes 67577
Introduction to Machine learning covering Statistical Inference (Bayes, EM,
ML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering),
and PAC learning (the Formal model, VC dimension, Double Sampling theorem).

Limits of Learning about a Categorical Latent Variable under Prior
  Near-Ignorance
In this paper, we consider the coherent theory of (epistemic) uncertainty of
Walley, in which beliefs are represented through sets of probability
distributions, and we focus on the problem of modeling prior ignorance about a
categorical random variable. In this setting, it is a known result that a state
of prior ignorance is not compatible with learning. To overcome this problem,
another state of beliefs, called \emph{near-ignorance}, has been proposed.
Near-ignorance resembles ignorance very closely, by satisfying some principles
that can arguably be regarded as necessary in a state of ignorance, and allows
learning to take place. What this paper does, is to provide new and substantial
evidence that also near-ignorance cannot be really regarded as a way out of the
problem of starting statistical inference in conditions of very weak beliefs.
The key to this result is focusing on a setting characterized by a variable of
interest that is \emph{latent}. We argue that such a setting is by far the most
common case in practice, and we provide, for the case of categorical latent
variables (and general \emph{manifest} variables) a condition that, if
satisfied, prevents learning to take place under prior near-ignorance. This
condition is shown to be easily satisfied even in the most common statistical
problems. We regard these results as a strong form of evidence against the
possibility to adopt a condition of prior near-ignorance in real statistical
problems.

Temporal data mining for root-cause analysis of machine faults in
  automotive assembly lines
Engine assembly is a complex and heavily automated distributed-control
process, with large amounts of faults data logged everyday. We describe an
application of temporal data mining for analyzing fault logs in an engine
assembly plant. Frequent episode discovery framework is a model-free method
that can be used to deduce (temporal) correlations among events from the logs
in an efficient manner. In addition to being theoretically elegant and
computationally efficient, frequent episodes are also easy to interpret in the
form actionable recommendations. Incorporation of domain-specific information
is critical to successful application of the method for analyzing fault logs in
the manufacturing domain. We show how domain-specific knowledge can be
incorporated using heuristic rules that act as pre-filters and post-filters to
frequent episode discovery. The system described here is currently being used
in one of the engine assembly plants of General Motors and is planned for
adaptation in other plants. To the best of our knowledge, this paper presents
the first real, large-scale application of temporal data mining in the
manufacturing domain. We believe that the ideas presented in this paper can
help practitioners engineer tools for analysis in other similar or related
application domains as well.

Combining Supervised and Unsupervised Learning for GIS Classification
This paper presents a new hybrid learning algorithm for unsupervised
classification tasks. We combined Fuzzy c-means learning algorithm and a
supervised version of Minimerror to develop a hybrid incremental strategy
allowing unsupervised classifications. We applied this new approach to a
real-world database in order to know if the information contained in unlabeled
features of a Geographic Information System (GIS), allows to well classify it.
Finally, we compared our results to a classical supervised classification
obtained by a multilayer perceptron.

Average-Case Active Learning with Costs
We analyze the expected cost of a greedy active learning algorithm. Our
analysis extends previous work to a more general setting in which different
queries have different costs. Moreover, queries may have more than two possible
responses and the distribution over hypotheses may be non uniform. Specific
applications include active learning with label costs, active learning for
multiclass and partial label queries, and batch mode active learning. We also
discuss an approximate version of interest when there are very many queries.

Transfer Learning Using Feature Selection
We present three related ways of using Transfer Learning to improve feature
selection. The three methods address different problems, and hence share
different kinds of information between tasks or feature classes, but all three
are based on the information theoretic Minimum Description Length (MDL)
principle and share the same underlying Bayesian interpretation. The first
method, MIC, applies when predictive models are to be built simultaneously for
multiple tasks (``simultaneous transfer'') that share the same set of features.
MIC allows each feature to be added to none, some, or all of the task models
and is most beneficial for selecting a small set of predictive features from a
large pool of features, as is common in genomic and biological datasets. Our
second method, TPC (Three Part Coding), uses a similar methodology for the case
when the features can be divided into feature classes. Our third method,
Transfer-TPC, addresses the ``sequential transfer'' problem in which the task
to which we want to transfer knowledge may not be known in advance and may have
different amounts of data than the other tasks. Transfer-TPC is most beneficial
when we want to transfer knowledge between tasks which have unequal amounts of
labeled data, for example the data for disambiguating the senses of different
verbs. We demonstrate the effectiveness of these approaches with experimental
results on real world data pertaining to genomics and to Word Sense
Disambiguation (WSD).

Equations of States in Statistical Learning for a Nonparametrizable and
  Regular Case
Many learning machines that have hierarchical structure or hidden variables
are now being used in information science, artificial intelligence, and
bioinformatics. However, several learning machines used in such fields are not
regular but singular statistical models, hence their generalization performance
is still left unknown. To overcome these problems, in the previous papers, we
proved new equations in statistical learning, by which we can estimate the
Bayes generalization loss from the Bayes training loss and the functional
variance, on the condition that the true distribution is a singularity
contained in a learning machine. In this paper, we prove that the same
equations hold even if a true distribution is not contained in a parametric
model. Also we prove that, the proposed equations in a regular case are
asymptotically equivalent to the Takeuchi information criterion. Therefore, the
proposed equations are always applicable without any condition on the unknown
true distribution.

An optimal linear separator for the Sonar Signals Classification task
The problem of classifying sonar signals from rocks and mines first studied
by Gorman and Sejnowski has become a benchmark against which many learning
algorithms have been tested. We show that both the training set and the test
set of this benchmark are linearly separable, although with different
hyperplanes. Moreover, the complete set of learning and test patterns together,
is also linearly separable. We give the weights that separate these sets, which
may be used to compare results found by other algorithms.

Bayesian History Reconstruction of Complex Human Gene Clusters on a
  Phylogeny
Clusters of genes that have evolved by repeated segmental duplication present
difficult challenges throughout genomic analysis, from sequence assembly to
functional analysis. Improved understanding of these clusters is of utmost
importance, since they have been shown to be the source of evolutionary
innovation, and have been linked to multiple diseases, including HIV and a
variety of cancers. Previously, Zhang et al. (2008) developed an algorithm for
reconstructing parsimonious evolutionary histories of such gene clusters, using
only human genomic sequence data. In this paper, we propose a probabilistic
model for the evolution of gene clusters on a phylogeny, and an MCMC algorithm
for reconstruction of duplication histories from genomic sequences in multiple
species. Several projects are underway to obtain high quality BAC-based
assemblies of duplicated clusters in multiple species, and we anticipate that
our method will be useful in analyzing these valuable new data sets.

Bayesian two-sample tests
In this paper, we present two classes of Bayesian approaches to the
two-sample problem. Our first class of methods extends the Bayesian t-test to
include all parametric models in the exponential family and their conjugate
priors. Our second class of methods uses Dirichlet process mixtures (DPM) of
such conjugate-exponential distributions as flexible nonparametric priors over
the unknown distributions.

Acquiring Knowledge for Evaluation of Teachers Performance in Higher
  Education using a Questionnaire
In this paper, we present the step by step knowledge acquisition process by
choosing a structured method through using a questionnaire as a knowledge
acquisition tool. Here we want to depict the problem domain as, how to evaluate
teachers performance in higher education through the use of expert system
technology. The problem is how to acquire the specific knowledge for a selected
problem efficiently and effectively from human experts and encode it in the
suitable computer format. Acquiring knowledge from human experts in the process
of expert systems development is one of the most common problems cited till
yet. This questionnaire was sent to 87 domain experts within all public and
private universities in Pakistani. Among them 25 domain experts sent their
valuable opinions. Most of the domain experts were highly qualified, well
experienced and highly responsible persons. The whole questionnaire was divided
into 15 main groups of factors, which were further divided into 99 individual
questions. These facts were analyzed further to give a final shape to the
questionnaire. This knowledge acquisition technique may be used as a learning
tool for further research work.

Unsupervised Search-based Structured Prediction
We describe an adaptation and application of a search-based structured
prediction algorithm "Searn" to unsupervised learning problems. We show that it
is possible to reduce unsupervised learning to supervised learning and
demonstrate a high-quality unsupervised shift-reduce parsing model. We
additionally show a close connection between unsupervised Searn and expectation
maximization. Finally, we demonstrate the efficacy of a semi-supervised
extension. The key idea that enables this is an application of the predict-self
idea for unsupervised learning.

Random DFAs are Efficiently PAC Learnable
This paper has been withdrawn due to an error found by Dana Angluin and Lev
Reyzin.

Bayesian Multitask Learning with Latent Hierarchies
We learn multiple hypotheses for related tasks under a latent hierarchical
relationship between tasks. We exploit the intuition that for domain
adaptation, we wish to share classifier structure, but for multitask learning,
we wish to share covariance structure. Our hierarchical model is seen to
subsume several previously proposed multitask learning models and performs well
on three distinct real-world data sets.

A Bayesian Model for Supervised Clustering with the Dirichlet Process
  Prior
We develop a Bayesian framework for tackling the supervised clustering
problem, the generic problem encountered in tasks such as reference matching,
coreference resolution, identity uncertainty and record linkage. Our clustering
model is based on the Dirichlet process prior, which enables us to define
distributions over the countably infinite sets that naturally arise in this
problem. We add supervision to our model by positing the existence of a set of
unobserved random variables (we call these "reference types") that are generic
across all clusters. Inference in our framework, which requires integrating
over infinitely many parameters, is solved using Markov chain Monte Carlo
techniques. We present algorithms for both conjugate and non-conjugate priors.
We present a simple--but general--parameterization of our model based on a
Gaussian assumption. We evaluate this model on one artificial task and three
real-world tasks, comparing it against both unsupervised and state-of-the-art
supervised algorithms. Our results show that our model is able to outperform
other models across a variety of tasks and performance metrics.

Fast search for Dirichlet process mixture models
Dirichlet process (DP) mixture models provide a flexible Bayesian framework
for density estimation. Unfortunately, their flexibility comes at a cost:
inference in DP mixture models is computationally expensive, even when
conjugate distributions are used. In the common case when one seeks only a
maximum a posteriori assignment of data points to clusters, we show that search
algorithms provide a practical alternative to expensive MCMC and variational
techniques. When a true posterior sample is desired, the solution found by
search can serve as a good initializer for MCMC. Experimental results show that
using these techniques is it possible to apply DP mixture models to very large
data sets.

Clustering for Improved Learning in Maze Traversal Problem
The maze traversal problem (finding the shortest distance to the goal from
any position in a maze) has been an interesting challenge in computational
intelligence. Recent work has shown that the cellular simultaneous recurrent
neural network (CSRN) can solve this problem for simple mazes. This thesis
focuses on exploiting relevant information about the maze to improve learning
and decrease the training time for the CSRN to solve mazes. Appropriate
variables are identified to create useful clusters using relevant information.
The CSRN was next modified to allow for an additional external input. With this
additional input, several methods were tested and results show that clustering
the mazes improves the overall learning of the traversal problem for the CSRN.

Randomized Algorithms for Large scale SVMs
We propose a randomized algorithm for training Support vector machines(SVMs)
on large datasets. By using ideas from Random projections we show that the
combinatorial dimension of SVMs is $O({log} n)$ with high probability. This
estimate of combinatorial dimension is used to derive an iterative algorithm,
called RandSVM, which at each step calls an existing solver to train SVMs on a
randomly chosen subset of size $O({log} n)$. The algorithm has probabilistic
guarantees and is capable of training SVMs with Kernels for both classification
and regression problems. Experiments done on synthetic and real life data sets
demonstrate that the algorithm scales up existing SVM learners, without loss of
accuracy.

Scalable Inference for Latent Dirichlet Allocation
We investigate the problem of learning a topic model - the well-known Latent
Dirichlet Allocation - in a distributed manner, using a cluster of C processors
and dividing the corpus to be learned equally among them. We propose a simple
approximated method that can be tuned, trading speed for accuracy according to
the task at hand. Our approach is asynchronous, and therefore suitable for
clusters of heterogenous machines.

Post-Processing of Discovered Association Rules Using Ontologies
In Data Mining, the usefulness of association rules is strongly limited by
the huge amount of delivered rules. In this paper we propose a new approach to
prune and filter discovered rules. Using Domain Ontologies, we strengthen the
integration of user knowledge in the post-processing task. Furthermore, an
interactive and iterative framework is designed to assist the user along the
analyzing task. On the one hand, we represent user domain knowledge using a
Domain Ontology over database. On the other hand, a novel technique is
suggested to prune and to filter discovered rules. The proposed framework was
applied successfully over the client database provided by Nantes Habitat.

Variable sigma Gaussian processes: An expectation propagation
  perspective
Gaussian processes (GPs) provide a probabilistic nonparametric representation
of functions in regression, classification, and other problems. Unfortunately,
exact learning with GPs is intractable for large datasets. A variety of
approximate GP methods have been proposed that essentially map the large
dataset into a small set of basis points. The most advanced of these, the
variable-sigma GP (VSGP) (Walder et al., 2008), allows each basis point to have
its own length scale. However, VSGP was only derived for regression. We
describe how VSGP can be applied to classification and other problems, by
deriving it as an expectation propagation algorithm. In this view, sparse GP
approximations correspond to a KL-projection of the true posterior onto a
compact exponential family of GPs. VSGP constitutes one such family, and we
show how to enlarge this family to get additional accuracy. In particular, we
show that endowing each basis point with its own full covariance matrix
provides a significant increase in approximation power.

Effectiveness and Limitations of Statistical Spam Filters
In this paper we discuss the techniques involved in the design of the famous
statistical spam filters that include Naive Bayes, Term Frequency-Inverse
Document Frequency, K-Nearest Neighbor, Support Vector Machine, and Bayes
Additive Regression Tree. We compare these techniques with each other in terms
of accuracy, recall, precision, etc. Further, we discuss the effectiveness and
limitations of statistical filters in filtering out various types of spam from
legitimate e-mails.

Competing with Gaussian linear experts
We study the problem of online regression. We prove a theoretical bound on
the square loss of Ridge Regression. We do not make any assumptions about input
vectors or outcomes. We also show that Bayesian Ridge Regression can be thought
of as an online algorithm competing with all the Gaussian linear experts.

Anomaly Detection with Score functions based on Nearest Neighbor Graphs
We propose a novel non-parametric adaptive anomaly detection algorithm for
high dimensional data based on score functions derived from nearest neighbor
graphs on $n$-point nominal data. Anomalies are declared whenever the score of
a test sample falls below $\alpha$, which is supposed to be the desired false
alarm level. The resulting anomaly detector is shown to be asymptotically
optimal in that it is uniformly most powerful for the specified false alarm
level, $\alpha$, for the case when the anomaly density is a mixture of the
nominal and a known density. Our algorithm is computationally efficient, being
linear in dimension and quadratic in data size. It does not require choosing
complicated tuning parameters or function approximation classes and it can
adapt to local structure such as local change in dimensionality. We demonstrate
the algorithm on both artificial and real data sets in high dimensional feature
spaces.

A Mirroring Theorem and its Application to a New Method of Unsupervised
  Hierarchical Pattern Classification
In this paper, we prove a crucial theorem called Mirroring Theorem which
affirms that given a collection of samples with enough information in it such
that it can be classified into classes and subclasses then (i) There exists a
mapping which classifies and subclassifies these samples (ii) There exists a
hierarchical classifier which can be constructed by using Mirroring Neural
Networks (MNNs) in combination with a clustering algorithm that can approximate
this mapping. Thus, the proof of the Mirroring theorem provides a theoretical
basis for the existence and a practical feasibility of constructing
hierarchical classifiers, given the maps. Our proposed Mirroring Theorem can
also be considered as an extension to Kolmogrovs theorem in providing a
realistic solution for unsupervised classification. The techniques we develop,
are general in nature and have led to the construction of learning machines
which are (i) tree like in structure, (ii) modular (iii) with each module
running on a common algorithm (tandem algorithm) and (iv) selfsupervised. We
have actually built the architecture, developed the tandem algorithm of such a
hierarchical classifier and demonstrated it on an example problem.

Sequential anomaly detection in the presence of noise and limited
  feedback
This paper describes a methodology for detecting anomalies from sequentially
observed and potentially noisy data. The proposed approach consists of two main
elements: (1) {\em filtering}, or assigning a belief or likelihood to each
successive measurement based upon our ability to predict it from previous noisy
observations, and (2) {\em hedging}, or flagging potential anomalies by
comparing the current belief against a time-varying and data-adaptive
threshold. The threshold is adjusted based on the available feedback from an
end user. Our algorithms, which combine universal prediction with recent work
on online convex programming, do not require computing posterior distributions
given all current observations and involve simple primal-dual parameter
updates. At the heart of the proposed approach lie exponential-family models
which can be used in a wide variety of contexts and applications, and which
yield methods that achieve sublinear per-round regret against both static and
slowly varying product distributions with marginals drawn from the same
exponential family. Moreover, the regret against static distributions coincides
with the minimax value of the corresponding online strongly convex game. We
also prove bounds on the number of mistakes made during the hedging step
relative to the best offline choice of the threshold with access to all
estimated beliefs and feedback signals. We validate the theory on synthetic
data drawn from a time-varying distribution over binary vectors of high
dimensionality, as well as on the Enron email dataset.

Keystroke Dynamics Authentication For Collaborative Systems
We present in this paper a study on the ability and the benefits of using a
keystroke dynamics authentication method for collaborative systems.
Authentication is a challenging issue in order to guarantee the security of use
of collaborative systems during the access control step. Many solutions exist
in the state of the art such as the use of one time passwords or smart-cards.
We focus in this paper on biometric based solutions that do not necessitate any
additional sensor. Keystroke dynamics is an interesting solution as it uses
only the keyboard and is invisible for users. Many methods have been published
in this field. We make a comparative study of many of them considering the
operational constraints of use for collaborative systems.

Statistical exponential families: A digest with flash cards
This document describes concisely the ubiquitous class of exponential family
distributions met in statistics. The first part recalls definitions and
summarizes main properties and duality with Bregman divergences (all proofs are
skipped). The second part lists decompositions and related formula of common
exponential family distributions. We recall the Fisher-Rao-Riemannian
geometries and the dual affine connection information geometries of statistical
manifolds. It is intended to maintain and update this document and catalog by
adding new distribution items.

Learning Mixtures of Gaussians using the k-means Algorithm
One of the most popular algorithms for clustering in Euclidean space is the
$k$-means algorithm; $k$-means is difficult to analyze mathematically, and few
theoretical guarantees are known about it, particularly when the data is {\em
well-clustered}. In this paper, we attempt to fill this gap in the literature
by analyzing the behavior of $k$-means on well-clustered data. In particular,
we study the case when each cluster is distributed as a different Gaussian --
or, in other words, when the input comes from a mixture of Gaussians.
  We analyze three aspects of the $k$-means algorithm under this assumption.
First, we show that when the input comes from a mixture of two spherical
Gaussians, a variant of the 2-means algorithm successfully isolates the
subspace containing the means of the mixture components. Second, we show an
exact expression for the convergence of our variant of the 2-means algorithm,
when the input is a very large number of samples from a mixture of spherical
Gaussians. Our analysis does not require any lower bound on the separation
between the mixture components.
  Finally, we study the sample requirement of $k$-means; for a mixture of 2
spherical Gaussians, we show an upper bound on the number of samples required
by a variant of 2-means to get close to the true solution. The sample
requirement grows with increasing dimensionality of the data, and decreasing
separation between the means of the Gaussians. To match our upper bound, we
show an information-theoretic lower bound on any algorithm that learns mixtures
of two spherical Gaussians; our lower bound indicates that in the case when the
overlap between the probability masses of the two distributions is small, the
sample requirement of $k$-means is {\em near-optimal}.

Delay-Optimal Power and Subcarrier Allocation for OFDMA Systems via
  Stochastic Approximation
In this paper, we consider delay-optimal power and subcarrier allocation
design for OFDMA systems with $N_F$ subcarriers, $K$ mobiles and one base
station. There are $K$ queues at the base station for the downlink traffic to
the $K$ mobiles with heterogeneous packet arrivals and delay requirements. We
shall model the problem as a $K$-dimensional infinite horizon average reward
Markov Decision Problem (MDP) where the control actions are assumed to be a
function of the instantaneous Channel State Information (CSI) as well as the
joint Queue State Information (QSI). This problem is challenging because it
corresponds to a stochastic Network Utility Maximization (NUM) problem where
general solution is still unknown. We propose an {\em online stochastic value
iteration} solution using {\em stochastic approximation}. The proposed power
control algorithm, which is a function of both the CSI and the QSI, takes the
form of multi-level water-filling. We prove that under two mild conditions in
Theorem 1 (One is the stepsize condition. The other is the condition on
accessibility of the Markov Chain, which can be easily satisfied in most of the
cases we are interested.), the proposed solution converges to the optimal
solution almost surely (with probability 1) and the proposed framework offers a
possible solution to the general stochastic NUM problem. By exploiting the
birth-death structure of the queue dynamics, we obtain a reduced complexity
decomposed solution with linear $\mathcal{O}(KN_F)$ complexity and
$\mathcal{O}(K)$ memory requirement.

Association Rule Pruning based on Interestingness Measures with
  Clustering
Association rule mining plays vital part in knowledge mining. The difficult
task is discovering knowledge or useful rules from the large number of rules
generated for reduced support. For pruning or grouping rules, several
techniques are used such as rule structure cover methods, informative cover
methods, rule clustering, etc. Another way of selecting association rules is
based on interestingness measures such as support, confidence, correlation, and
so on. In this paper, we study how rule clusters of the pattern Xi - Y are
distributed over different interestingness measures.

Early Detection of Breast Cancer using SVM Classifier Technique
This paper presents a tumor detection algorithm from mammogram. The proposed
system focuses on the solution of two problems. One is how to detect tumors as
suspicious regions with a very weak contrast to their background and another is
how to extract features which categorize tumors. The tumor detection method
follows the scheme of (a) mammogram enhancement. (b) The segmentation of the
tumor area. (c) The extraction of features from the segmented tumor area. (d)
The use of SVM classifier. The enhancement can be defined as conversion of the
image quality to a better and more understandable level. The mammogram
enhancement procedure includes filtering, top hat operation, DWT. Then the
contrast stretching is used to increase the contrast of the image. The
segmentation of mammogram images has been playing an important role to improve
the detection and diagnosis of breast cancer. The most common segmentation
method used is thresholding. The features are extracted from the segmented
breast area. Next stage include, which classifies the regions using the SVM
classifier. The method was tested on 75 mammographic images, from the mini-MIAS
database. The methodology achieved a sensitivity of 88.75%.

Performance Analysis of AIM-K-means & K-means in Quality Cluster
  Generation
Among all the partition based clustering algorithms K-means is the most
popular and well known method. It generally shows impressive results even in
considerably large data sets. The computational complexity of K-means does not
suffer from the size of the data set. The main disadvantage faced in performing
this clustering is that the selection of initial means. If the user does not
have adequate knowledge about the data set, it may lead to erroneous results.
The algorithm Automatic Initialization of Means (AIM), which is an extension to
K-means, has been proposed to overcome the problem of initial mean generation.
In this paper an attempt has been made to compare the performance of the
algorithms through implementation

Gaussian Process Optimization in the Bandit Setting: No Regret and
  Experimental Design
Many applications require optimizing an unknown, noisy function that is
expensive to evaluate. We formalize this task as a multi-armed bandit problem,
where the payoff function is either sampled from a Gaussian process (GP) or has
low RKHS norm. We resolve the important open problem of deriving regret bounds
for this setting, which imply novel convergence rates for GP optimization. We
analyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its
cumulative regret in terms of maximal information gain, establishing a novel
connection between GP optimization and experimental design. Moreover, by
bounding the latter in terms of operator spectra, we obtain explicit sublinear
regret bounds for many commonly used covariance functions. In some important
cases, our bounds have surprisingly weak dependence on the dimensionality. In
our experiments on real sensor data, GP-UCB compares favorably with other
heuristical GP optimization approaches.

Optimal Query Complexity for Reconstructing Hypergraphs
In this paper we consider the problem of reconstructing a hidden weighted
hypergraph of constant rank using additive queries. We prove the following: Let
$G$ be a weighted hidden hypergraph of constant rank with n vertices and $m$
hyperedges. For any $m$ there exists a non-adaptive algorithm that finds the
edges of the graph and their weights using $$ O(\frac{m\log n}{\log m}) $$
additive queries. This solves the open problem in [S. Choi, J. H. Kim. Optimal
Query Complexity Bounds for Finding Graphs. {\em STOC}, 749--758,~2008].
  When the weights of the hypergraph are integers that are less than
$O(poly(n^d/m))$ where $d$ is the rank of the hypergraph (and therefore for
unweighted hypergraphs) there exists a non-adaptive algorithm that finds the
edges of the graph and their weights using $$ O(\frac{m\log \frac{n^d}{m}}{\log
m}). $$ additive queries.
  Using the information theoretic bound the above query complexities are tight.

Linear Probability Forecasting
Multi-class classification is one of the most important tasks in machine
learning. In this paper we consider two online multi-class classification
problems: classification by a linear model and by a kernelized model. The
quality of predictions is measured by the Brier loss function. We suggest two
computationally efficient algorithms to work with these problems and prove
theoretical guarantees on their losses. We kernelize one of the algorithms and
prove theoretical guarantees on its loss. We perform experiments and compare
our algorithms with logistic regression.

Measuring Latent Causal Structure
Discovering latent representations of the observed world has become
increasingly more relevant in data analysis. Much of the effort concentrates on
building latent variables which can be used in prediction problems, such as
classification and regression. A related goal of learning latent structure from
data is that of identifying which hidden common causes generate the
observations, such as in applications that require predicting the effect of
policies. This will be the main problem tackled in our contribution: given a
dataset of indicators assumed to be generated by unknown and unmeasured common
causes, we wish to discover which hidden common causes are those, and how they
generate our data. This is possible under the assumption that observed
variables are linear functions of the latent causes with additive noise.
Previous results in the literature present solutions for the case where each
observed variable is a noisy function of a single latent variable. We show how
to extend the existing results for some cases where observed variables measure
more than one latent variable.

Asymptotic Learning Curve and Renormalizable Condition in Statistical
  Learning Theory
Bayes statistics and statistical physics have the common mathematical
structure, where the log likelihood function corresponds to the random
Hamiltonian. Recently, it was discovered that the asymptotic learning curves in
Bayes estimation are subject to a universal law, even if the log likelihood
function can not be approximated by any quadratic form. However, it is left
unknown what mathematical property ensures such a universal law. In this paper,
we define a renormalizable condition of the statistical estimation problem, and
show that, under such a condition, the asymptotic learning curves are ensured
to be subject to the universal law, even if the true distribution is
unrealizable and singular for a statistical model. Also we study a
nonrenormalizable case, in which the learning curves have the different
asymptotic behaviors from the universal law.

Role of Interestingness Measures in CAR Rule Ordering for Associative
  Classifier: An Empirical Approach
Associative Classifier is a novel technique which is the integration of
Association Rule Mining and Classification. The difficult task in building
Associative Classifier model is the selection of relevant rules from a large
number of class association rules (CARs). A very popular method of ordering
rules for selection is based on confidence, support and antecedent size (CSA).
Other methods are based on hybrid orderings in which CSA method is combined
with other measures. In the present work, we study the effect of using
different interestingness measures of Association rules in CAR rule ordering
and selection for associative classifier.

Trajectory Clustering and an Application to Airspace Monitoring
This paper presents a framework aimed at monitoring the behavior of aircraft
in a given airspace. Nominal trajectories are determined and learned using data
driven methods. Standard procedures are used by air traffic controllers (ATC)
to guide aircraft, ensure the safety of the airspace, and to maximize the
runway occupancy. Even though standard procedures are used by ATC, the control
of the aircraft remains with the pilots, leading to a large variability in the
flight patterns observed. Two methods to identify typical operations and their
variability from recorded radar tracks are presented. This knowledge base is
then used to monitor the conformance of current operations against operations
previously identified as standard. A tool called AirTrajectoryMiner is
presented, aiming at monitoring the instantaneous health of the airspace, in
real time. The airspace is "healthy" when all aircraft are flying according to
the nominal procedures. A measure of complexity is introduced, measuring the
conformance of current flight to nominal flight patterns. When an aircraft does
not conform, the complexity increases as more attention from ATC is required to
ensure a safe separation between aircraft.

Aggregating Algorithm competing with Banach lattices
The paper deals with on-line regression settings with signals belonging to a
Banach lattice. Our algorithms work in a semi-online setting where all the
inputs are known in advance and outcomes are unknown and given step by step. We
apply the Aggregating Algorithm to construct a prediction method whose
cumulative loss over all the input vectors is comparable with the cumulative
loss of any linear functional on the Banach lattice. As a by-product we get an
algorithm that takes signals from an arbitrary domain. Its cumulative loss is
comparable with the cumulative loss of any predictor function from Besov and
Triebel-Lizorkin spaces. We describe several applications of our setting.

A CHAID Based Performance Prediction Model in Educational Data Mining
The performance in higher secondary school education in India is a turning
point in the academic lives of all students. As this academic performance is
influenced by many factors, it is essential to develop predictive data mining
model for students' performance so as to identify the slow learners and study
the influence of the dominant factors on their academic performance. In the
present investigation, a survey cum experimental methodology was adopted to
generate a database and it was constructed from a primary and a secondary
source. While the primary data was collected from the regular students, the
secondary data was gathered from the school and office of the Chief Educational
Officer (CEO). A total of 1000 datasets of the year 2006 from five different
schools in three different districts of Tamilnadu were collected. The raw data
was preprocessed in terms of filling up missing values, transforming values in
one form into another and relevant attribute/ variable selection. As a result,
we had 772 student records, which were used for CHAID prediction model
construction. A set of prediction rules were extracted from CHIAD prediction
model and the efficiency of the generated CHIAD prediction model was found. The
accuracy of the present model was compared with other model and it has been
found to be satisfactory.

Dimensionality Reduction: An Empirical Study on the Usability of IFE-CF
  (Independent Feature Elimination- by C-Correlation and F-Correlation)
  Measures
The recent increase in dimensionality of data has thrown a great challenge to
the existing dimensionality reduction methods in terms of their effectiveness.
Dimensionality reduction has emerged as one of the significant preprocessing
steps in machine learning applications and has been effective in removing
inappropriate data, increasing learning accuracy, and improving
comprehensibility. Feature redundancy exercises great influence on the
performance of classification process. Towards the better classification
performance, this paper addresses the usefulness of truncating the highly
correlated and redundant attributes. Here, an effort has been made to verify
the utility of dimensionality reduction by applying LVQ (Learning Vector
Quantization) method on two Benchmark datasets of 'Pima Indian Diabetic
patients' and 'Lung cancer patients'.

Online Distributed Sensor Selection
A key problem in sensor networks is to decide which sensors to query when, in
order to obtain the most useful information (e.g., for performing accurate
prediction), subject to constraints (e.g., on power and bandwidth). In many
applications the utility function is not known a priori, must be learned from
data, and can even change over time. Furthermore for large sensor networks
solving a centralized optimization problem to select sensors is not feasible,
and thus we seek a fully distributed solution. In this paper, we present
Distributed Online Greedy (DOG), an efficient, distributed algorithm for
repeatedly selecting sensors online, only receiving feedback about the utility
of the selected sensors. We prove very strong theoretical no-regret guarantees
that apply whenever the (unknown) utility function satisfies a natural
diminishing returns property called submodularity. Our algorithm has extremely
low communication requirements, and scales well to large sensor deployments. We
extend DOG to allow observation-dependent sensor selection. We empirically
demonstrate the effectiveness of our algorithm on several real-world sensing
tasks.

On the Stability of Empirical Risk Minimization in the Presence of
  Multiple Risk Minimizers
Recently Kutin and Niyogi investigated several notions of algorithmic
stability--a property of a learning map conceptually similar to
continuity--showing that training-stability is sufficient for consistency of
Empirical Risk Minimization while distribution-free CV-stability is necessary
and sufficient for having finite VC-dimension. This paper concerns a phase
transition in the training stability of ERM, conjectured by the same authors.
Kutin and Niyogi proved that ERM on finite hypothesis spaces containing a
unique risk minimizer has training stability that scales exponentially with
sample size, and conjectured that the existence of multiple risk minimizers
prevents even super-quadratic convergence. We prove this result for the
strictly weaker notion of CV-stability, positively resolving the conjecture.

Collaborative Filtering in a Non-Uniform World: Learning with the
  Weighted Trace Norm
We show that matrix completion with trace-norm regularization can be
significantly hurt when entries of the matrix are sampled non-uniformly. We
introduce a weighted version of the trace-norm regularizer that works well also
with non-uniform sampling. Our experimental results demonstrate that the
weighted trace-norm regularization indeed yields significant gains on the
(highly non-uniformly sampled) Netflix dataset.

Interactive Submodular Set Cover
We introduce a natural generalization of submodular set cover and exact
active learning with a finite hypothesis class (query learning). We call this
new problem interactive submodular set cover. Applications include advertising
in social networks with hidden information. We give an approximation guarantee
for a novel greedy algorithm and give a hardness of approximation result which
matches up to constant factors. We also discuss negative results for simpler
approaches and present encouraging early experimental results.

Word level Script Identification from Bangla and Devanagri Handwritten
  Texts mixed with Roman Script
India is a multi-lingual country where Roman script is often used alongside
different Indic scripts in a text document. To develop a script specific
handwritten Optical Character Recognition (OCR) system, it is therefore
necessary to identify the scripts of handwritten text correctly. In this paper,
we present a system, which automatically separates the scripts of handwritten
words from a document, written in Bangla or Devanagri mixed with Roman scripts.
In this script separation technique, we first, extract the text lines and words
from document pages using a script independent Neighboring Component Analysis
technique. Then we have designed a Multi Layer Perceptron (MLP) based
classifier for script separation, trained with 8 different wordlevel holistic
features. Two equal sized datasets, one with Bangla and Roman scripts and the
other with Devanagri and Roman scripts, are prepared for the system evaluation.
On respective independent text samples, word-level script identification
accuracies of 99.29% and 98.43% are achieved.

Contextual Bandit Algorithms with Supervised Learning Guarantees
We address the problem of learning in an online, bandit setting where the
learner must repeatedly select among $K$ actions, but only receives partial
feedback based on its choices. We establish two new facts: First, using a new
algorithm called Exp4.P, we show that it is possible to compete with the best
in a set of $N$ experts with probability $1-\delta$ while incurring regret at
most $O(\sqrt{KT\ln(N/\delta)})$ over $T$ time steps. The new algorithm is
tested empirically in a large-scale, real-world dataset. Second, we give a new
algorithm called VE that competes with a possibly infinite set of policies of
VC-dimension $d$ while incurring regret at most $O(\sqrt{T(d\ln(T) + \ln
(1/\delta))})$ with probability $1-\delta$. These guarantees improve on those
of all previous algorithms, whether in a stochastic or adversarial environment,
and bring us closer to providing supervised learning type guarantees for the
contextual bandit setting.

Adaptive Bound Optimization for Online Convex Optimization
We introduce a new online convex optimization algorithm that adaptively
chooses its regularization function based on the loss functions observed so
far. This is in contrast to previous algorithms that use a fixed regularization
function such as L2-squared, and modify it only via a single time-dependent
parameter. Our algorithm's regret bounds are worst-case optimal, and for
certain realistic classes of loss functions they are much better than existing
bounds. These bounds are problem-dependent, which means they can exploit the
structure of the actual problem instance. Critically, however, our algorithm
does not need to know this structure in advance. Rather, we prove competitive
guarantees that show the algorithm provides a bound within a constant factor of
the best possible bound (of a certain functional form) in hindsight.

State-Space Dynamics Distance for Clustering Sequential Data
This paper proposes a novel similarity measure for clustering sequential
data. We first construct a common state-space by training a single
probabilistic model with all the sequences in order to get a unified
representation for the dataset. Then, distances are obtained attending to the
transition matrices induced by each sequence in that state-space. This approach
solves some of the usual overfitting and scalability issues of the existing
semi-parametric techniques, that rely on training a model for each sequence.
Empirical studies on both synthetic and real-world datasets illustrate the
advantages of the proposed similarity measure for clustering sequences.

Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable
  Information Criterion in Singular Learning Theory
In regular statistical models, the leave-one-out cross-validation is
asymptotically equivalent to the Akaike information criterion. However, since
many learning machines are singular statistical models, the asymptotic behavior
of the cross-validation remains unknown. In previous studies, we established
the singular learning theory and proposed a widely applicable information
criterion, the expectation value of which is asymptotically equal to the
average Bayes generalization loss. In the present paper, we theoretically
compare the Bayes cross-validation loss and the widely applicable information
criterion and prove two theorems. First, the Bayes cross-validation loss is
asymptotically equivalent to the widely applicable information criterion as a
random variable. Therefore, model selection and hyperparameter optimization
using these two values are asymptotically equivalent. Second, the sum of the
Bayes generalization error and the Bayes cross-validation error is
asymptotically equal to $2\lambda/n$, where $\lambda$ is the real log canonical
threshold and $n$ is the number of training samples. Therefore the relation
between the cross-validation error and the generalization error is determined
by the algebraic geometrical structure of a learning machine. We also clarify
that the deviance information criteria are different from the Bayes
cross-validation and the widely applicable information criterion.

Generation and Interpretation of Temporal Decision Rules
We present a solution to the problem of understanding a system that produces
a sequence of temporally ordered observations. Our solution is based on
generating and interpreting a set of temporal decision rules. A temporal
decision rule is a decision rule that can be used to predict or retrodict the
value of a decision attribute, using condition attributes that are observed at
times other than the decision attribute's time of observation. A rule set,
consisting of a set of temporal decision rules with the same decision
attribute, can be interpreted by our Temporal Investigation Method for
Enregistered Record Sequences (TIMERS) to signify an instantaneous, an acausal
or a possibly causal relationship between the condition attributes and the
decision attribute. We show the effectiveness of our method, by describing a
number of experiments with both synthetic and real temporal data.

Bregman Distance to L1 Regularized Logistic Regression
In this work we investigate the relationship between Bregman distances and
regularized Logistic Regression model. We present a detailed study of Bregman
Distance minimization, a family of generalized entropy measures associated with
convex functions. We convert the L1-regularized logistic regression into this
more general framework and propose a primal-dual method based algorithm for
learning the parameters. We pose L1-regularized logistic regression into
Bregman distance minimization and then apply non-linear constrained
optimization techniques to estimate the parameters of the logistic model.

Efficient Learning with Partially Observed Attributes
We describe and analyze efficient algorithms for learning a linear predictor
from examples when the learner can only view a few attributes of each training
example. This is the case, for instance, in medical research, where each
patient participating in the experiment is only willing to go through a small
number of tests. Our analysis bounds the number of additional examples
sufficient to compensate for the lack of full information on each training
example. We demonstrate the efficiency of our algorithms by showing that when
running on digit recognition data, they obtain a high prediction accuracy even
when the learner gets to see only four pixels of each image.

Learning from Multiple Outlooks
We propose a novel problem formulation of learning a single task when the
data are provided in different feature spaces. Each such space is called an
outlook, and is assumed to contain both labeled and unlabeled data. The
objective is to take advantage of the data from all the outlooks to better
classify each of the outlooks. We devise an algorithm that computes optimal
affine mappings from different outlooks to a target outlook by matching moments
of the empirical distributions. We further derive a probabilistic
interpretation of the resulting algorithm and a sample complexity bound
indicating how many samples are needed to adequately find the mapping. We
report the results of extensive experiments on activity recognition tasks that
show the value of the proposed approach in boosting performance.

A Geometric View of Conjugate Priors
In Bayesian machine learning, conjugate priors are popular, mostly due to
mathematical convenience. In this paper, we show that there are deeper reasons
for choosing a conjugate prior. Specifically, we formulate the conjugate prior
in the form of Bregman divergence and show that it is the inherent geometry of
conjugate priors that makes them appropriate and intuitive. This geometric
interpretation allows one to view the hyperparameters of conjugate priors as
the {\it effective} sample points, thus providing additional intuition. We use
this geometric understanding of conjugate priors to derive the hyperparameters
and expression of the prior used to couple the generative and discriminative
components of a hybrid model for semi-supervised learning.

Distributive Stochastic Learning for Delay-Optimal OFDMA Power and
  Subband Allocation
In this paper, we consider the distributive queue-aware power and subband
allocation design for a delay-optimal OFDMA uplink system with one base
station, $K$ users and $N_F$ independent subbands. Each mobile has an uplink
queue with heterogeneous packet arrivals and delay requirements. We model the
problem as an infinite horizon average reward Markov Decision Problem (MDP)
where the control actions are functions of the instantaneous Channel State
Information (CSI) as well as the joint Queue State Information (QSI). To
address the distributive requirement and the issue of exponential memory
requirement and computational complexity, we approximate the subband allocation
Q-factor by the sum of the per-user subband allocation Q-factor and derive a
distributive online stochastic learning algorithm to estimate the per-user
Q-factor and the Lagrange multipliers (LM) simultaneously and determine the
control actions using an auction mechanism. We show that under the proposed
auction mechanism, the distributive online learning converges almost surely
(with probability 1). For illustration, we apply the proposed distributive
stochastic learning framework to an application example with exponential packet
size distribution. We show that the delay-optimal power control has the {\em
multi-level water-filling} structure where the CSI determines the instantaneous
power allocation and the QSI determines the water-level. The proposed algorithm
has linear signaling overhead and computational complexity $\mathcal O(KN)$,
which is desirable from an implementation perspective.

Statistical Learning in Automated Troubleshooting: Application to LTE
  Interference Mitigation
This paper presents a method for automated healing as part of off-line
automated troubleshooting. The method combines statistical learning with
constraint optimization. The automated healing aims at locally optimizing radio
resource management (RRM) or system parameters of cells with poor performance
in an iterative manner. The statistical learning processes the data using
Logistic Regression (LR) to extract closed form (functional) relations between
Key Performance Indicators (KPIs) and Radio Resource Management (RRM)
parameters. These functional relations are then processed by an optimization
engine which proposes new parameter values. The advantage of the proposed
formulation is the small number of iterations required by the automated healing
method to converge, making it suitable for off-line implementation. The
proposed method is applied to heal an Inter-Cell Interference Coordination
(ICIC) process in a 3G Long Term Evolution (LTE) network which is based on
soft-frequency reuse scheme. Numerical simulations illustrate the benefits of
the proposed approach.

The Complex Gaussian Kernel LMS algorithm
Although the real reproducing kernels are used in an increasing number of
machine learning problems, complex kernels have not, yet, been used, in spite
of their potential interest in applications such as communications. In this
work, we focus our attention on the complex gaussian kernel and its possible
application in the complex Kernel LMS algorithm. In order to derive the
gradients needed to develop the complex kernel LMS (CKLMS), we employ the
powerful tool of Wirtinger's Calculus, which has recently attracted much
attention in the signal processing community. Writinger's calculus simplifies
computations and offers an elegant tool for treating complex signals. To this
end, the notion of Writinger's calculus is extended to include complex RKHSs.
Experiments verify that the CKLMS offers significant performance improvements
over the traditional complex LMS or Widely Linear complex LMS (WL-LMS)
algorithms, when dealing with nonlinearities.

Extension of Wirtinger Calculus in RKH Spaces and the Complex Kernel LMS
Over the last decade, kernel methods for nonlinear processing have
successfully been used in the machine learning community. However, so far, the
emphasis has been on batch techniques. It is only recently, that online
adaptive techniques have been considered in the context of signal processing
tasks. To the best of our knowledge, no kernel-based strategy has been
developed, so far, that is able to deal with complex valued signals. In this
paper, we take advantage of a technique called complexification of real RKHSs
to attack this problem. In order to derive gradients and subgradients of
operators that need to be defined on the associated complex RKHSs, we employ
the powerful tool ofWirtinger's Calculus, which has recently attracted much
attention in the signal processing community. Writinger's calculus simplifies
computations and offers an elegant tool for treating complex signals. To this
end, in this paper, the notion of Writinger's calculus is extended, for the
first time, to include complex RKHSs and use it to derive the Complex Kernel
Least-Mean-Square (CKLMS) algorithm. Experiments verify that the CKLMS can be
used to derive nonlinear stable algorithms, which offer significant performance
improvements over the traditional complex LMS orWidely Linear complex LMS
(WL-LMS) algorithms, when dealing with nonlinearities.

Improving Semi-Supervised Support Vector Machines Through Unlabeled
  Instances Selection
Semi-supervised support vector machines (S3VMs) are a kind of popular
approaches which try to improve learning performance by exploiting unlabeled
data. Though S3VMs have been found helpful in many situations, they may
degenerate performance and the resultant generalization ability may be even
worse than using the labeled data only. In this paper, we try to reduce the
chance of performance degeneration of S3VMs. Our basic idea is that, rather
than exploiting all unlabeled data, the unlabeled instances should be selected
such that only the ones which are very likely to be helpful are exploited,
while some highly risky unlabeled instances are avoided. We propose the
S3VM-\emph{us} method by using hierarchical clustering to select the unlabeled
instances. Experiments on a broad range of data sets over eighty-eight
different settings show that the chance of performance degeneration of
S3VM-\emph{us} is much smaller than that of existing S3VMs.

Prediction with Expert Advice under Discounted Loss
We study prediction with expert advice in the setting where the losses are
accumulated with some discounting---the impact of old losses may gradually
vanish. We generalize the Aggregating Algorithm and the Aggregating Algorithm
for Regression to this case, propose a suitable new variant of exponential
weights algorithm, and prove respective loss bounds.

Detecting Blackholes and Volcanoes in Directed Networks
In this paper, we formulate a novel problem for finding blackhole and volcano
patterns in a large directed graph. Specifically, a blackhole pattern is a
group which is made of a set of nodes in a way such that there are only inlinks
to this group from the rest nodes in the graph. In contrast, a volcano pattern
is a group which only has outlinks to the rest nodes in the graph. Both
patterns can be observed in real world. For instance, in a trading network, a
blackhole pattern may represent a group of traders who are manipulating the
market. In the paper, we first prove that the blackhole mining problem is a
dual problem of finding volcanoes. Therefore, we focus on finding the blackhole
patterns. Along this line, we design two pruning schemes to guide the blackhole
finding process. In the first pruning scheme, we strategically prune the search
space based on a set of pattern-size-independent pruning rules and develop an
iBlackhole algorithm. The second pruning scheme follows a divide-and-conquer
strategy to further exploit the pruning results from the first pruning scheme.
Indeed, a target directed graphs can be divided into several disconnected
subgraphs by the first pruning scheme, and thus the blackhole finding can be
conducted in each disconnected subgraph rather than in a large graph. Based on
these two pruning schemes, we also develop an iBlackhole-DC algorithm. Finally,
experimental results on real-world data show that the iBlackhole-DC algorithm
can be several orders of magnitude faster than the iBlackhole algorithm, which
has a huge computational advantage over a brute-force method.

Robustness and Generalization
We derive generalization bounds for learning algorithms based on their
robustness: the property that if a testing sample is "similar" to a training
sample, then the testing error is close to the training error. This provides a
novel approach, different from the complexity or stability arguments, to study
generalization of learning algorithms. We further show that a weak notion of
robustness is both sufficient and necessary for generalizability, which implies
that robustness is a fundamental property for learning algorithms to work.

Online Learning of Noisy Data with Kernels
We study online learning when individual instances are corrupted by
adversarially chosen random noise. We assume the noise distribution is unknown,
and may change over time with no restriction other than having zero mean and
bounded variance. Our technique relies on a family of unbiased estimators for
non-linear functions, which may be of independent interest. We show that a
variant of online gradient descent can learn functions in any dot-product
(e.g., polynomial) or Gaussian kernel space with any analytic convex loss
function. Our variant uses randomized estimates that need to query a random
number of noisy copies of each instance, where with high probability this
number is upper bounded by a constant. Allowing such multiple queries cannot be
avoided: Indeed, we show that online learning is in general impossible when
only one noisy copy of each instance can be accessed.

Evolution with Drifting Targets
We consider the question of the stability of evolutionary algorithms to
gradual changes, or drift, in the target concept. We define an algorithm to be
resistant to drift if, for some inverse polynomial drift rate in the target
function, it converges to accuracy 1 -- \epsilon , with polynomial resources,
and then stays within that accuracy indefinitely, except with probability
\epsilon , at any one time. We show that every evolution algorithm, in the
sense of Valiant (2007; 2009), can be converted using the Correlational Query
technique of Feldman (2008), into such a drift resistant algorithm. For certain
evolutionary algorithms, such as for Boolean conjunctions, we give bounds on
the rates of drift that they can resist. We develop some new evolution
algorithms that are resistant to significant drift. In particular, we give an
algorithm for evolving linear separators over the spherically symmetric
distribution that is resistant to a drift rate of O(\epsilon /n), and another
algorithm over the more general product normal distributions that resists a
smaller drift rate.
  The above translation result can be also interpreted as one on the robustness
of the notion of evolvability itself under changes of definition. As a second
result in that direction we show that every evolution algorithm can be
converted to a quasi-monotonic one that can evolve from any starting point
without the performance ever dipping significantly below that of the starting
point. This permits the somewhat unnatural feature of arbitrary performance
degradations to be removed from several known robustness translations.

Learning Kernel-Based Halfspaces with the Zero-One Loss
We describe and analyze a new algorithm for agnostically learning
kernel-based halfspaces with respect to the \emph{zero-one} loss function.
Unlike most previous formulations which rely on surrogate convex loss functions
(e.g. hinge-loss in SVM and log-loss in logistic regression), we provide finite
time/sample guarantees with respect to the more natural zero-one loss function.
The proposed algorithm can learn kernel-based halfspaces in worst-case time
$\poly(\exp(L\log(L/\epsilon)))$, for $\emph{any}$ distribution, where $L$ is a
Lipschitz constant (which can be thought of as the reciprocal of the margin),
and the learned classifier is worse than the optimal halfspace by at most
$\epsilon$. We also prove a hardness result, showing that under a certain
cryptographic assumption, no algorithm can learn kernel-based halfspaces in
time polynomial in $L$.

On the clustering aspect of nonnegative matrix factorization
This paper provides a theoretical explanation on the clustering aspect of
nonnegative matrix factorization (NMF). We prove that even without imposing
orthogonality nor sparsity constraint on the basis and/or coefficient matrix,
NMF still can give clustering results, thus providing a theoretical support for
many works, e.g., Xu et al. [1] and Kim et al. [2], that show the superiority
of the standard NMF as a clustering method.

Multi-View Active Learning in the Non-Realizable Case
The sample complexity of active learning under the realizability assumption
has been well-studied. The realizability assumption, however, rarely holds in
practice. In this paper, we theoretically characterize the sample complexity of
active learning in the non-realizable case under multi-view setting. We prove
that, with unbounded Tsybakov noise, the sample complexity of multi-view active
learning can be $\widetilde{O}(\log\frac{1}{\epsilon})$, contrasting to
single-view setting where the polynomial improvement is the best possible
achievement. We also prove that in general multi-view setting the sample
complexity of active learning with unbounded Tsybakov noise is
$\widetilde{O}(\frac{1}{\epsilon})$, where the order of $1/\epsilon$ is
independent of the parameter in Tsybakov noise, contrasting to previous
polynomial bounds where the order of $1/\epsilon$ is related to the parameter
in Tsybakov noise.

Prediction with Advice of Unknown Number of Experts
In the framework of prediction with expert advice, we consider a recently
introduced kind of regret bounds: the bounds that depend on the effective
instead of nominal number of experts. In contrast to the NormalHedge bound,
which mainly depends on the effective number of experts and also weakly depends
on the nominal one, we obtain a bound that does not contain the nominal number
of experts at all. We use the defensive forecasting method and introduce an
application of defensive forecasting to multivalued supermartingales.

Predictive PAC learnability: a paradigm for learning from exchangeable
  input data
Exchangeable random variables form an important and well-studied
generalization of i.i.d. variables, however simple examples show that no
nontrivial concept or function classes are PAC learnable under general
exchangeable data inputs $X_1,X_2,\ldots$. Inspired by the work of Berti and
Rigo on a Glivenko--Cantelli theorem for exchangeable inputs, we propose a new
paradigm, adequate for learning from exchangeable data: predictive PAC
learnability. A learning rule $\mathcal L$ for a function class $\mathscr F$ is
predictive PAC if for every $\e,\delta>0$ and each function $f\in {\mathscr
F}$, whenever $\abs{\sigma}\geq s(\delta,\e)$, we have with confidence
$1-\delta$ that the expected difference between $f(X_{n+1})$ and the image of
$f\vert\sigma$ under $\mathcal L$ does not exceed $\e$ conditionally on
$X_1,X_2,\ldots,X_n$. Thus, instead of learning the function $f$ as such, we
are learning to a given accuracy $\e$ the predictive behaviour of $f$ at the
future points $X_i(\omega)$, $i>n$ of the sample path. Using de Finetti's
theorem, we show that if a universally separable function class $\mathscr F$ is
distribution-free PAC learnable under i.i.d. inputs, then it is
distribution-free predictive PAC learnable under exchangeable inputs, with a
slightly worse sample complexity.

Regression on fixed-rank positive semidefinite matrices: a Riemannian
  approach
The paper addresses the problem of learning a regression model parameterized
by a fixed-rank positive semidefinite matrix. The focus is on the nonlinear
nature of the search space and on scalability to high-dimensional problems. The
mathematical developments rely on the theory of gradient descent algorithms
adapted to the Riemannian geometry that underlies the set of fixed-rank
positive semidefinite matrices. In contrast with previous contributions in the
literature, no restrictions are imposed on the range space of the learned
matrix. The resulting algorithms maintain a linear complexity in the problem
size and enjoy important invariance properties. We apply the proposed
algorithms to the problem of learning a distance function parameterized by a
positive semidefinite matrix. Good performance is observed on classical
benchmarks.

Dyadic Prediction Using a Latent Feature Log-Linear Model
In dyadic prediction, labels must be predicted for pairs (dyads) whose
members possess unique identifiers and, sometimes, additional features called
side-information. Special cases of this problem include collaborative filtering
and link prediction. We present the first model for dyadic prediction that
satisfies several important desiderata: (i) labels may be ordinal or nominal,
(ii) side-information can be easily exploited if present, (iii) with or without
side-information, latent features are inferred for dyad members, (iv) it is
resistant to sample-selection bias, (v) it can learn well-calibrated
probabilities, and (vi) it can scale to very large datasets. To our knowledge,
no existing method satisfies all the above criteria. In particular, many
methods assume that the labels are ordinal and ignore side-information when it
is present. Experimental results show that the new method is competitive with
state-of-the-art methods for the special cases of collaborative filtering and
link prediction, and that it makes accurate predictions on nominal data.

Agnostic Active Learning Without Constraints
We present and analyze an agnostic active learning algorithm that works
without keeping a version space. This is unlike all previous approaches where a
restricted set of candidate hypotheses is maintained throughout learning, and
only hypotheses from this set are ever returned. By avoiding this version space
approach, our algorithm sheds the computational burden and brittleness
associated with maintaining version spaces, yet still allows for substantial
improvements over supervised learning for classification.

Extension of Wirtinger's Calculus to Reproducing Kernel Hilbert Spaces
  and the Complex Kernel LMS
Over the last decade, kernel methods for nonlinear processing have
successfully been used in the machine learning community. The primary
mathematical tool employed in these methods is the notion of the Reproducing
Kernel Hilbert Space. However, so far, the emphasis has been on batch
techniques. It is only recently, that online techniques have been considered in
the context of adaptive signal processing tasks. Moreover, these efforts have
only been focussed on real valued data sequences. To the best of our knowledge,
no adaptive kernel-based strategy has been developed, so far, for complex
valued signals. Furthermore, although the real reproducing kernels are used in
an increasing number of machine learning problems, complex kernels have not,
yet, been used, in spite of their potential interest in applications that deal
with complex signals, with Communications being a typical example. In this
paper, we present a general framework to attack the problem of adaptive
filtering of complex signals, using either real reproducing kernels, taking
advantage of a technique called \textit{complexification} of real RKHSs, or
complex reproducing kernels, highlighting the use of the complex gaussian
kernel. In order to derive gradients of operators that need to be defined on
the associated complex RKHSs, we employ the powerful tool of Wirtinger's
Calculus, which has recently attracted attention in the signal processing
community. To this end, in this paper, the notion of Wirtinger's calculus is
extended, for the first time, to include complex RKHSs and use it to derive
several realizations of the Complex Kernel Least-Mean-Square (CKLMS) algorithm.
Experiments verify that the CKLMS offers significant performance improvements
over several linear and nonlinear algorithms, when dealing with nonlinearities.

MINLIP for the Identification of Monotone Wiener Systems
This paper studies the MINLIP estimator for the identification of Wiener
systems consisting of a sequence of a linear FIR dynamical model, and a
monotonically increasing (or decreasing) static function. Given $T$
observations, this algorithm boils down to solving a convex quadratic program
with $O(T)$ variables and inequality constraints, implementing an inference
technique which is based entirely on model complexity control. The resulting
estimates of the linear submodel are found to be almost consistent when no
noise is present in the data, under a condition of smoothness of the true
nonlinearity and local Persistency of Excitation (local PE) of the data. This
result is novel as it does not rely on classical tools as a 'linearization'
using a Taylor decomposition, nor exploits stochastic properties of the data.
It is indicated how to extend the method to cope with noisy data, and empirical
evidence contrasts performance of the estimator against other recently proposed
techniques.

PAC learnability of a concept class under non-atomic measures: a problem
  by Vidyasagar
In response to a 1997 problem of M. Vidyasagar, we state a necessary and
sufficient condition for distribution-free PAC learnability of a concept class
$\mathscr C$ under the family of all non-atomic (diffuse) measures on the
domain $\Omega$. Clearly, finiteness of the classical Vapnik-Chervonenkis
dimension of $\mathscr C$ is a sufficient, but no longer necessary, condition.
Besides, learnability of $\mathscr C$ under non-atomic measures does not imply
the uniform Glivenko-Cantelli property with regard to non-atomic measures. Our
learnability criterion is stated in terms of a combinatorial parameter
$\VC({\mathscr C}\,{\mathrm{mod}}\,\omega_1)$ which we call the VC dimension of
$\mathscr C$ modulo countable sets. The new parameter is obtained by
``thickening up'' single points in the definition of VC dimension to
uncountable ``clusters''. Equivalently, $\VC(\mathscr C\modd\omega_1)\leq d$ if
and only if every countable subclass of $\mathscr C$ has VC dimension $\leq d$
outside a countable subset of $\Omega$. The new parameter can be also expressed
as the classical VC dimension of $\mathscr C$ calculated on a suitable subset
of a compactification of $\Omega$. We do not make any measurability assumptions
on $\mathscr C$, assuming instead the validity of Martin's Axiom (MA).

The Latent Bernoulli-Gauss Model for Data Analysis
We present a new latent-variable model employing a Gaussian mixture
integrated with a feature selection procedure (the Bernoulli part of the model)
which together form a "Latent Bernoulli-Gauss" distribution. The model is
applied to MAP estimation, clustering, feature selection and collaborative
filtering and fares favorably with the state-of-the-art latent-variable models.

Filtrage vaste marge pour l'Ã©tiquetage sÃ©quentiel Ã  noyaux de
  signaux
We address in this paper the problem of multi-channel signal sequence
labeling. In particular, we consider the problem where the signals are
contaminated by noise or may present some dephasing with respect to their
labels. For that, we propose to jointly learn a SVM sample classifier with a
temporal filtering of the channels. This will lead to a large margin filtering
that is adapted to the specificity of each channel (noise and time-lag). We
derive algorithms to solve the optimization problem and we discuss different
filter regularizations for automated scaling or selection of channels. Our
approach is tested on a non-linear toy example and on a BCI dataset. Results
show that the classification performance on these problems can be improved by
learning a large margin filtering.

A note on sample complexity of learning binary output neural networks
  under fixed input distributions
We show that the learning sample complexity of a sigmoidal neural network
constructed by Sontag (1992) required to achieve a given misclassification
error under a fixed purely atomic distribution can grow arbitrarily fast: for
any prescribed rate of growth there is an input distribution having this rate
as the sample complexity, and the bound is asymptotically tight. The rate can
be superexponential, a non-recursive function, etc. We further observe that
Sontag's ANN is not Glivenko-Cantelli under any input distribution having a
non-atomic part.

Reinforcement Learning via AIXI Approximation
This paper introduces a principled approach for the design of a scalable
general reinforcement learning agent. This approach is based on a direct
approximation of AIXI, a Bayesian optimality notion for general reinforcement
learning agents. Previously, it has been unclear whether the theory of AIXI
could motivate the design of practical algorithms. We answer this hitherto open
question in the affirmative, by providing the first computationally feasible
approximation to the AIXI agent. To develop our approximation, we introduce a
Monte Carlo Tree Search algorithm along with an agent-specific extension of the
Context Tree Weighting algorithm. Empirically, we present a set of encouraging
results on a number of stochastic, unknown, and partially observable domains.

Adapting to the Shifting Intent of Search Queries
Search engines today present results that are often oblivious to abrupt
shifts in intent. For example, the query `independence day' usually refers to a
US holiday, but the intent of this query abruptly changed during the release of
a major film by that name. While no studies exactly quantify the magnitude of
intent-shifting traffic, studies suggest that news events, seasonal topics, pop
culture, etc account for 50% of all search queries. This paper shows that the
signals a search engine receives can be used to both determine that a shift in
intent has happened, as well as find a result that is now more relevant. We
present a meta-algorithm that marries a classifier with a bandit algorithm to
achieve regret that depends logarithmically on the number of query impressions,
under certain assumptions. We provide strong evidence that this regret is close
to the best achievable. Finally, via a series of experiments, we demonstrate
that our algorithm outperforms prior approaches, particularly as the amount of
intent-shifting traffic increases.

Comparison of Support Vector Machine and Back Propagation Neural Network
  in Evaluating the Enterprise Financial Distress
Recently, applying the novel data mining techniques for evaluating enterprise
financial distress has received much research alternation. Support Vector
Machine (SVM) and back propagation neural (BPN) network has been applied
successfully in many areas with excellent generalization results, such as rule
extraction, classification and evaluation. In this paper, a model based on SVM
with Gaussian RBF kernel is proposed here for enterprise financial distress
evaluation. BPN network is considered one of the simplest and are most general
methods used for supervised training of multilayered neural network. The
comparative results show that through the difference between the performance
measures is marginal; SVM gives higher precision and lower error rates.

Close Clustering Based Automated Color Image Annotation
Most image-search approaches today are based on the text based tags
associated with the images which are mostly human generated and are subject to
various kinds of errors. The results of a query to the image database thus can
often be misleading and may not satisfy the requirements of the user. In this
work we propose our approach to automate this tagging process of images, where
image results generated can be fine filtered based on a probabilistic tagging
mechanism. We implement a tool which helps to automate the tagging process by
maintaining a training database, wherein the system is trained to identify
certain set of input images, the results generated from which are used to
create a probabilistic tagging mechanism. Given a certain set of segments in an
image it calculates the probability of presence of particular keywords. This
probability table is further used to generate the candidate tags for input
images.

Bounded Coordinate-Descent for Biological Sequence Classification in
  High Dimensional Predictor Space
We present a framework for discriminative sequence classification where the
learner works directly in the high dimensional predictor space of all
subsequences in the training set. This is possible by employing a new
coordinate-descent algorithm coupled with bounding the magnitude of the
gradient for selecting discriminative subsequences fast. We characterize the
loss functions for which our generic learning algorithm can be applied and
present concrete implementations for logistic regression (binomial
log-likelihood loss) and support vector machines (squared hinge loss).
Application of our algorithm to protein remote homology detection and remote
fold recognition results in performance comparable to that of state-of-the-art
methods (e.g., kernel support vector machines). Unlike state-of-the-art
classifiers, the resulting classification models are simply lists of weighted
discriminative subsequences and can thus be interpreted and related to the
biological problem.

Semi-Supervised Kernel PCA
We present three generalisations of Kernel Principal Components Analysis
(KPCA) which incorporate knowledge of the class labels of a subset of the data
points. The first, MV-KPCA, penalises within class variances similar to Fisher
discriminant analysis. The second, LSKPCA is a hybrid of least squares
regression and kernel PCA. The final LR-KPCA is an iteratively reweighted
version of the previous which achieves a sigmoid loss function on the labeled
points. We provide a theoretical risk bound as well as illustrative experiments
on real and toy data sets.

Online Learning in Case of Unbounded Losses Using the Follow Perturbed
  Leader Algorithm
In this paper the sequential prediction problem with expert advice is
considered for the case where losses of experts suffered at each step cannot be
bounded in advance. We present some modification of Kalai and Vempala algorithm
of following the perturbed leader where weights depend on past losses of the
experts. New notions of a volume and a scaled fluctuation of a game are
introduced. We present a probabilistic algorithm protected from unrestrictedly
large one-step losses. This algorithm has the optimal performance in the case
when the scaled fluctuations of one-step losses of experts of the pool tend to
zero.

Switching between Hidden Markov Models using Fixed Share
In prediction with expert advice the goal is to design online prediction
algorithms that achieve small regret (additional loss on the whole data)
compared to a reference scheme. In the simplest such scheme one compares to the
loss of the best expert in hindsight. A more ambitious goal is to split the
data into segments and compare to the best expert on each segment. This is
appropriate if the nature of the data changes between segments. The standard
fixed-share algorithm is fast and achieves small regret compared to this
scheme.
  Fixed share treats the experts as black boxes: there are no assumptions about
how they generate their predictions. But if the experts are learning, the
following question arises: should the experts learn from all data or only from
data in their own segment? The original algorithm naturally addresses the first
case. Here we consider the second option, which is more appropriate exactly
when the nature of the data changes between segments. In general extending
fixed share to this second case will slow it down by a factor of T on T
outcomes. We show, however, that no such slowdown is necessary if the experts
are hidden Markov models.

Freezing and Sleeping: Tracking Experts that Learn by Evolving Past
  Posteriors
A problem posed by Freund is how to efficiently track a small pool of experts
out of a much larger set. This problem was solved when Bousquet and Warmuth
introduced their mixing past posteriors (MPP) algorithm in 2001.
  In Freund's problem the experts would normally be considered black boxes.
However, in this paper we re-examine Freund's problem in case the experts have
internal structure that enables them to learn. In this case the problem has two
possible interpretations: should the experts learn from all data or only from
the subsequence on which they are being tracked? The MPP algorithm solves the
first case. Our contribution is to generalise MPP to address the second option.
The results we obtain apply to any expert structure that can be formalised
using (expert) hidden Markov models. Curiously enough, for our interpretation
there are \emph{two} natural reference schemes: freezing and sleeping. For each
scheme, we provide an efficient prediction strategy and prove the relevant loss
bound.

Exploring Language-Independent Emotional Acoustic Features via Feature
  Selection
We propose a novel feature selection strategy to discover
language-independent acoustic features that tend to be responsible for emotions
regardless of languages, linguistics and other factors. Experimental results
suggest that the language-independent feature subset discovered yields the
performance comparable to the full feature set on various emotional speech
corpora.

Fast Overlapping Group Lasso
The group Lasso is an extension of the Lasso for feature selection on
(predefined) non-overlapping groups of features. The non-overlapping group
structure limits its applicability in practice. There have been several recent
attempts to study a more general formulation, where groups of features are
given, potentially with overlaps between the groups. The resulting optimization
is, however, much more challenging to solve due to the group overlaps. In this
paper, we consider the efficient optimization of the overlapping group Lasso
penalized problem. We reveal several key properties of the proximal operator
associated with the overlapping group Lasso, and compute the proximal operator
by solving the smooth and convex dual problem, which allows the use of the
gradient descent type of algorithms for the optimization. We have performed
empirical evaluations using the breast cancer gene expression data set, which
consists of 8,141 genes organized into (overlapping) gene sets. Experimental
results demonstrate the efficiency and effectiveness of the proposed algorithm.

Reinforcement Learning by Comparing Immediate Reward
This paper introduces an approach to Reinforcement Learning Algorithm by
comparing their immediate rewards using a variation of Q-Learning algorithm.
Unlike the conventional Q-Learning, the proposed algorithm compares current
reward with immediate reward of past move and work accordingly. Relative reward
based Q-learning is an approach towards interactive learning. Q-Learning is a
model free reinforcement learning method that used to learn the agents. It is
observed that under normal circumstances algorithm take more episodes to reach
optimal Q-value due to its normal reward or sometime negative reward. In this
new form of algorithm agents select only those actions which have a higher
immediate reward signal in comparison to previous one. The contribution of this
article is the presentation of new Q-Learning Algorithm in order to maximize
the performance of algorithm and reduce the number of episode required to reach
optimal Q-value. Effectiveness of proposed algorithm is simulated in a 20 x20
Grid world deterministic environment and the result for the two forms of
Q-Learning Algorithms is given.

A Unified View of Regularized Dual Averaging and Mirror Descent with
  Implicit Updates
We study three families of online convex optimization algorithms:
follow-the-proximally-regularized-leader (FTRL-Proximal), regularized dual
averaging (RDA), and composite-objective mirror descent. We first prove
equivalence theorems that show all of these algorithms are instantiations of a
general FTRL update. This provides theoretical insight on previous experimental
observations. In particular, even though the FOBOS composite mirror descent
algorithm handles L1 regularization explicitly, it has been observed that RDA
is even more effective at producing sparsity. Our results demonstrate that
FOBOS uses subgradient approximations to the L1 penalty from previous rounds,
leading to less sparsity than RDA, which handles the cumulative penalty in
closed form. The FTRL-Proximal algorithm can be seen as a hybrid of these two,
and outperforms both on a large, real-world dataset.
  Our second contribution is a unified analysis which produces regret bounds
that match (up to logarithmic terms) or improve the best previously known
bounds. This analysis also extends these algorithms in two important ways: we
support a more general type of composite objective and we analyze implicit
updates, which replace the subgradient approximation of the current loss
function with an exact optimization.

Conditional Random Fields and Support Vector Machines: A Hybrid Approach
We propose a novel hybrid loss for multiclass and structured prediction
problems that is a convex combination of log loss for Conditional Random Fields
(CRFs) and a multiclass hinge loss for Support Vector Machines (SVMs). We
provide a sufficient condition for when the hybrid loss is Fisher consistent
for classification. This condition depends on a measure of dominance between
labels - specifically, the gap in per observation probabilities between the
most likely labels. We also prove Fisher consistency is necessary for
parametric consistency when learning models such as CRFs.
  We demonstrate empirically that the hybrid loss typically performs as least
as well as - and often better than - both of its constituent losses on variety
of tasks. In doing so we also provide an empirical comparison of the efficacy
of probabilistic and margin based approaches to multiclass and structured
prediction and the effects of label dominance on these results.

Geometric Decision Tree
In this paper we present a new algorithm for learning oblique decision trees.
Most of the current decision tree algorithms rely on impurity measures to
assess the goodness of hyperplanes at each node while learning a decision tree
in a top-down fashion. These impurity measures do not properly capture the
geometric structures in the data. Motivated by this, our algorithm uses a
strategy to assess the hyperplanes in such a way that the geometric structure
in the data is taken into account. At each node of the decision tree, we find
the clustering hyperplanes for both the classes and use their angle bisectors
as the split rule at that node. We show through empirical studies that this
idea leads to small decision trees and better performance. We also present some
analysis to show that the angle bisectors of clustering hyperplanes that we use
as the split rules at each node, are solutions of an interesting optimization
problem and hence argue that this is a principled method of learning a decision
tree.

On the Doubt about Margin Explanation of Boosting
Margin theory provides one of the most popular explanations to the success of
\texttt{AdaBoost}, where the central point lies in the recognition that
\textit{margin} is the key for characterizing the performance of
\texttt{AdaBoost}. This theory has been very influential, e.g., it has been
used to argue that \texttt{AdaBoost} usually does not overfit since it tends to
enlarge the margin even after the training error reaches zero. Previously the
\textit{minimum margin bound} was established for \texttt{AdaBoost}, however,
\cite{Breiman1999} pointed out that maximizing the minimum margin does not
necessarily lead to a better generalization. Later, \cite{Reyzin:Schapire2006}
emphasized that the margin distribution rather than minimum margin is crucial
to the performance of \texttt{AdaBoost}. In this paper, we first present the
\textit{$k$th margin bound} and further study on its relationship to previous
work such as the minimum margin bound and Emargin bound. Then, we improve the
previous empirical Bernstein bounds
\citep{Maurer:Pontil2009,Audibert:Munos:Szepesvari2009}, and based on such
findings, we defend the margin-based explanation against Breiman's doubts by
proving a new generalization error bound that considers exactly the same
factors as \cite{Schapire:Freund:Bartlett:Lee1998} but is sharper than
\cite{Breiman1999}'s minimum margin bound. By incorporating factors such as
average margin and variance, we present a generalization error bound that is
heavily related to the whole margin distribution. We also provide margin
distribution bounds for generalization error of voting classifiers in finite
VC-dimension space.

Totally Corrective Multiclass Boosting with Binary Weak Learners
In this work, we propose a new optimization framework for multiclass boosting
learning. In the literature, AdaBoost.MO and AdaBoost.ECC are the two
successful multiclass boosting algorithms, which can use binary weak learners.
We explicitly derive these two algorithms' Lagrange dual problems based on
their regularized loss functions. We show that the Lagrange dual formulations
enable us to design totally-corrective multiclass algorithms by using the
primal-dual optimization technique. Experiments on benchmark data sets suggest
that our multiclass boosting can achieve a comparable generalization capability
with state-of-the-art, but the convergence speed is much faster than stage-wise
gradient descent boosting. In other words, the new totally corrective
algorithms can maximize the margin more aggressively.

Optimistic Rates for Learning with a Smooth Loss
We establish an excess risk bound of O(H R_n^2 + R_n \sqrt{H L*}) for
empirical risk minimization with an H-smooth loss function and a hypothesis
class with Rademacher complexity R_n, where L* is the best risk achievable by
the hypothesis class. For typical hypothesis classes where R_n = \sqrt{R/n},
this translates to a learning rate of O(RH/n) in the separable (L*=0) case and
O(RH/n + \sqrt{L^* RH/n}) more generally. We also provide similar guarantees
for online and stochastic convex optimization with a smooth non-negative
objective.

Efficient L1/Lq Norm Regularization
Sparse learning has recently received increasing attention in many areas
including machine learning, statistics, and applied mathematics. The mixed-norm
regularization based on the L1/Lq norm with q > 1 is attractive in many
applications of regression and classification in that it facilitates group
sparsity in the model. The resulting optimization problem is, however,
challenging to solve due to the structure of the L1/Lq -regularization.
Existing work deals with special cases including q = 2,infinity, and they
cannot be easily extended to the general case. In this paper, we propose an
efficient algorithm based on the accelerated gradient method for solving the
L1/Lq -regularized problem, which is applicable for all values of q larger than
1, thus significantly extending existing work. One key building block of the
proposed algorithm is the L1/Lq -regularized Euclidean projection (EP1q). Our
theoretical analysis reveals the key properties of EP1q and illustrates why
EP1q for the general q is significantly more challenging to solve than the
special cases. Based on our theoretical analysis, we develop an efficient
algorithm for EP1q by solving two zero finding problems. Experimental results
demonstrate the efficiency of the proposed algorithm.

Multi-parametric Solution-path Algorithm for Instance-weighted Support
  Vector Machines
An instance-weighted variant of the support vector machine (SVM) has
attracted considerable attention recently since they are useful in various
machine learning tasks such as non-stationary data analysis, heteroscedastic
data modeling, transfer learning, learning to rank, and transduction. An
important challenge in these scenarios is to overcome the computational
bottleneck---instance weights often change dynamically or adaptively, and thus
the weighted SVM solutions must be repeatedly computed. In this paper, we
develop an algorithm that can efficiently and exactly update the weighted SVM
solutions for arbitrary change of instance weights. Technically, this
contribution can be regarded as an extension of the conventional solution-path
algorithm for a single regularization parameter to multiple instance-weight
parameters. However, this extension gives rise to a significant problem that
breakpoints (at which the solution path turns) have to be identified in
high-dimensional space. To facilitate this, we introduce a parametric
representation of instance weights. We also provide a geometric interpretation
in weight space using a notion of critical region: a polyhedron in which the
current affine solution remains to be optimal. Then we find breakpoints at
intersections of the solution path and boundaries of polyhedrons. Through
extensive experiments on various practical applications, we demonstrate the
usefulness of the proposed algorithm.

Portfolio Allocation for Bayesian Optimization
Bayesian optimization with Gaussian processes has become an increasingly
popular tool in the machine learning community. It is efficient and can be used
when very little is known about the objective function, making it popular in
expensive black-box optimization scenarios. It uses Bayesian methods to sample
the objective efficiently using an acquisition function which incorporates the
model's estimate of the objective and the uncertainty at any given point.
However, there are several different parameterized acquisition functions in the
literature, and it is often unclear which one to use. Instead of using a single
acquisition function, we adopt a portfolio of acquisition functions governed by
an online multi-armed bandit strategy. We propose several portfolio strategies,
the best of which we call GP-Hedge, and show that this method outperforms the
best individual acquisition function. We also provide a theoretical bound on
the algorithm's performance.

Fast Reinforcement Learning for Energy-Efficient Wireless Communications
We consider the problem of energy-efficient point-to-point transmission of
delay-sensitive data (e.g. multimedia data) over a fading channel. Existing
research on this topic utilizes either physical-layer centric solutions, namely
power-control and adaptive modulation and coding (AMC), or system-level
solutions based on dynamic power management (DPM); however, there is currently
no rigorous and unified framework for simultaneously utilizing both
physical-layer centric and system-level techniques to achieve the minimum
possible energy consumption, under delay constraints, in the presence of
stochastic and a priori unknown traffic and channel conditions. In this report,
we propose such a framework. We formulate the stochastic optimization problem
as a Markov decision process (MDP) and solve it online using reinforcement
learning. The advantages of the proposed online method are that (i) it does not
require a priori knowledge of the traffic arrival and channel statistics to
determine the jointly optimal power-control, AMC, and DPM policies; (ii) it
exploits partial information about the system so that less information needs to
be learned than when using conventional reinforcement learning algorithms; and
(iii) it obviates the need for action exploration, which severely limits the
adaptation speed and run-time performance of conventional reinforcement
learning algorithms. Our results show that the proposed learning algorithms can
converge up to two orders of magnitude faster than a state-of-the-art learning
algorithm for physical layer power-control and up to three orders of magnitude
faster than conventional reinforcement learning algorithms.

The Attentive Perceptron
We propose a focus of attention mechanism to speed up the Perceptron
algorithm. Focus of attention speeds up the Perceptron algorithm by lowering
the number of features evaluated throughout training and prediction. Whereas
the traditional Perceptron evaluates all the features of each example, the
Attentive Perceptron evaluates less features for easy to classify examples,
thereby achieving significant speedups and small losses in prediction accuracy.
Focus of attention allows the Attentive Perceptron to stop the evaluation of
features at any interim point and filter the example. This creates an attentive
filter which concentrates computation at examples that are hard to classify,
and quickly filters examples that are easy to classify.

Queue-Aware Distributive Resource Control for Delay-Sensitive Two-Hop
  MIMO Cooperative Systems
In this paper, we consider a queue-aware distributive resource control
algorithm for two-hop MIMO cooperative systems. We shall illustrate that relay
buffering is an effective way to reduce the intrinsic half-duplex penalty in
cooperative systems. The complex interactions of the queues at the source node
and the relays are modeled as an average-cost infinite horizon Markov Decision
Process (MDP). The traditional approach solving this MDP problem involves
centralized control with huge complexity. To obtain a distributive and low
complexity solution, we introduce a linear structure which approximates the
value function of the associated Bellman equation by the sum of per-node value
functions. We derive a distributive two-stage two-winner auction-based control
policy which is a function of the local CSI and local QSI only. Furthermore, to
estimate the best fit approximation parameter, we propose a distributive online
stochastic learning algorithm using stochastic approximation theory. Finally,
we establish technical conditions for almost-sure convergence and show that
under heavy traffic, the proposed low complexity distributive control is global
optimal.

Time Series Classification by Class-Specific Mahalanobis Distance
  Measures
To classify time series by nearest neighbors, we need to specify or learn one
or several distance measures. We consider variations of the Mahalanobis
distance measures which rely on the inverse covariance matrix of the data.
Unfortunately --- for time series data --- the covariance matrix has often low
rank. To alleviate this problem we can either use a pseudoinverse, covariance
shrinking or limit the matrix to its diagonal. We review these alternatives and
benchmark them against competitive methods such as the related Large Margin
Nearest Neighbor Classification (LMNN) and the Dynamic Time Warping (DTW)
distance. As we expected, we find that the DTW is superior, but the Mahalanobis
distance measures are one to two orders of magnitude faster. To get best
results with Mahalanobis distance measures, we recommend learning one distance
measure per class using either covariance shrinking or the diagonal approach.

Algorithms for nonnegative matrix factorization with the beta-divergence
This paper describes algorithms for nonnegative matrix factorization (NMF)
with the beta-divergence (beta-NMF). The beta-divergence is a family of cost
functions parametrized by a single shape parameter beta that takes the
Euclidean distance, the Kullback-Leibler divergence and the Itakura-Saito
divergence as special cases (beta = 2,1,0, respectively). The proposed
algorithms are based on a surrogate auxiliary function (a local majorization of
the criterion function). We first describe a majorization-minimization (MM)
algorithm that leads to multiplicative updates, which differ from standard
heuristic multiplicative updates by a beta-dependent power exponent. The
monotonicity of the heuristic algorithm can however be proven for beta in (0,1)
using the proposed auxiliary function. Then we introduce the concept of
majorization-equalization (ME) algorithm which produces updates that move along
constant level sets of the auxiliary function and lead to larger steps than MM.
Simulations on synthetic and real data illustrate the faster convergence of the
ME approach. The paper also describes how the proposed algorithms can be
adapted to two common variants of NMF : penalized NMF (i.e., when a penalty
function of the factors is added to the criterion function) and convex-NMF
(when the dictionary is assumed to belong to a known subspace).

Hardness Results for Agnostically Learning Low-Degree Polynomial
  Threshold Functions
Hardness results for maximum agreement problems have close connections to
hardness results for proper learning in computational learning theory. In this
paper we prove two hardness results for the problem of finding a low degree
polynomial threshold function (PTF) which has the maximum possible agreement
with a given set of labeled examples in $\R^n \times \{-1,1\}.$ We prove that
for any constants $d\geq 1, \eps > 0$,
  {itemize}
  Assuming the Unique Games Conjecture, no polynomial-time algorithm can find a
degree-$d$ PTF that is consistent with a $(\half + \eps)$ fraction of a given
set of labeled examples in $\R^n \times \{-1,1\}$, even if there exists a
degree-$d$ PTF that is consistent with a $1-\eps$ fraction of the examples.
  It is $\NP$-hard to find a degree-2 PTF that is consistent with a $(\half +
\eps)$ fraction of a given set of labeled examples in $\R^n \times \{-1,1\}$,
even if there exists a halfspace (degree-1 PTF) that is consistent with a $1 -
\eps$ fraction of the examples.
  {itemize}
  These results immediately imply the following hardness of learning results:
(i) Assuming the Unique Games Conjecture, there is no better-than-trivial
proper learning algorithm that agnostically learns degree-$d$ PTFs under
arbitrary distributions; (ii) There is no better-than-trivial learning
algorithm that outputs degree-2 PTFs and agnostically learns halfspaces (i.e.
degree-1 PTFs) under arbitrary distributions.

Efficient Matrix Completion with Gaussian Models
A general framework based on Gaussian models and a MAP-EM algorithm is
introduced in this paper for solving matrix/table completion problems. The
numerical experiments with the standard and challenging movie ratings data show
that the proposed approach, based on probably one of the simplest probabilistic
models, leads to the results in the same ballpark as the state-of-the-art, at a
lower computational cost.

Large-Scale Clustering Based on Data Compression
This paper considers the clustering problem for large data sets. We propose
an approach based on distributed optimization. The clustering problem is
formulated as an optimization problem of maximizing the classification gain. We
show that the optimization problem can be reformulated and decomposed into
small-scale sub optimization problems by using the Dantzig-Wolfe decomposition
method. Generally speaking, the Dantzig-Wolfe method can only be used for
convex optimization problems, where the duality gaps are zero. Even though, the
considered optimization problem in this paper is non-convex, we prove that the
duality gap goes to zero, as the problem size goes to infinity. Therefore, the
Dantzig-Wolfe method can be applied here. In the proposed approach, the
clustering problem is iteratively solved by a group of computers coordinated by
one center processor, where each computer solves one independent small-scale
sub optimization problem during each iteration, and only a small amount of data
communication is needed between the computers and center processor. Numerical
results show that the proposed approach is effective and efficient.

Sublinear Optimization for Machine Learning
We give sublinear-time approximation algorithms for some optimization
problems arising in machine learning, such as training linear classifiers and
finding minimum enclosing balls. Our algorithms can be extended to some
kernelized versions of these problems, such as SVDD, hard margin SVM, and
L2-SVM, for which sublinear-time algorithms were not known before. These new
algorithms use a combination of a novel sampling techniques and a new
multiplicative update algorithm. We give lower bounds which show the running
times of many of our algorithms to be nearly best possible in the unit-cost RAM
model. We also give implementations of our algorithms in the semi-streaming
setting, obtaining the first low pass polylogarithmic space and sublinear time
algorithms achieving arbitrary approximation factor.

Regularized Risk Minimization by Nesterov's Accelerated Gradient
  Methods: Algorithmic Extensions and Empirical Studies
Nesterov's accelerated gradient methods (AGM) have been successfully applied
in many machine learning areas. However, their empirical performance on
training max-margin models has been inferior to existing specialized solvers.
In this paper, we first extend AGM to strongly convex and composite objective
functions with Bregman style prox-functions. Our unifying framework covers both
the $\infty$-memory and 1-memory styles of AGM, tunes the Lipschiz constant
adaptively, and bounds the duality gap. Then we demonstrate various ways to
apply this framework of methods to a wide range of machine learning problems.
Emphasis will be given on their rate of convergence and how to efficiently
compute the gradient and optimize the models. The experimental results show
that with our extensions AGM outperforms state-of-the-art solvers on max-margin
models.

Online Importance Weight Aware Updates
An importance weight quantifies the relative importance of one example over
another, coming up in applications of boosting, asymmetric classification
costs, reductions, and active learning. The standard approach for dealing with
importance weights in gradient descent is via multiplication of the gradient.
We first demonstrate the problems of this approach when importance weights are
large, and argue in favor of more sophisticated ways for dealing with them. We
then develop an approach which enjoys an invariance property: that updating
twice with importance weight $h$ is equivalent to updating once with importance
weight $2h$. For many important losses this has a closed form update which
satisfies standard regret guarantees when all examples have $h=1$. We also
briefly discuss two other reasonable approaches for handling large importance
weights. Empirically, these approaches yield substantially superior prediction
with similar computational performance while reducing the sensitivity of the
algorithm to the exact setting of the learning rate. We apply these to online
active learning yielding an extraordinarily fast active learning algorithm that
works even in the presence of adversarial noise.

On Theorem 2.3 in "Prediction, Learning, and Games" by Cesa-Bianchi and
  Lugosi
The note presents a modified proof of a loss bound for the exponentially
weighted average forecaster with time-varying potential. The regret term of the
algorithm is upper-bounded by sqrt{n ln(N)} (uniformly in n), where N is the
number of experts and n is the number of steps.

Estimating Probabilities in Recommendation Systems
Recommendation systems are emerging as an important business application with
significant economic impact. Currently popular systems include Amazon's book
recommendations, Netflix's movie recommendations, and Pandora's music
recommendations. In this paper we address the problem of estimating
probabilities associated with recommendation system data using non-parametric
kernel smoothing. In our estimation we interpret missing items as randomly
censored observations and obtain efficient computation schemes using
combinatorial properties of generating functions. We demonstrate our approach
with several case studies involving real world movie recommendation data. The
results are comparable with state-of-the-art techniques while also providing
probabilistic preference estimates outside the scope of traditional recommender
systems.

A Tutorial on Bayesian Optimization of Expensive Cost Functions, with
  Application to Active User Modeling and Hierarchical Reinforcement Learning
We present a tutorial on Bayesian optimization, a method of finding the
maximum of expensive cost functions. Bayesian optimization employs the Bayesian
technique of setting a prior over the objective function and combining it with
evidence to get a posterior function. This permits a utility-based selection of
the next observation to make on the objective function, which must take into
account both exploration (sampling from areas of high uncertainty) and
exploitation (sampling areas likely to offer improvement over the current best
observation). We also present two detailed extensions of Bayesian optimization,
with experiments---active user modelling with preferences, and hierarchical
reinforcement learning---and a discussion of the pros and cons of Bayesian
optimization based on our experiences.

Queue-Aware Dynamic Clustering and Power Allocation for Network MIMO
  Systems via Distributive Stochastic Learning
In this paper, we propose a two-timescale delay-optimal dynamic clustering
and power allocation design for downlink network MIMO systems. The dynamic
clustering control is adaptive to the global queue state information (GQSI)
only and computed at the base station controller (BSC) over a longer time
scale. On the other hand, the power allocations of all the BSs in one cluster
are adaptive to both intra-cluster channel state information (CCSI) and
intra-cluster queue state information (CQSI), and computed at the cluster
manager (CM) over a shorter time scale. We show that the two-timescale
delay-optimal control can be formulated as an infinite-horizon average cost
Constrained Partially Observed Markov Decision Process (CPOMDP). By exploiting
the special problem structure, we shall derive an equivalent Bellman equation
in terms of Pattern Selection Q-factor to solve the CPOMDP. To address the
distributive requirement and the issue of exponential memory requirement and
computational complexity, we approximate the Pattern Selection Q-factor by the
sum of Per-cluster Potential functions and propose a novel distributive online
learning algorithm to estimate the Per-cluster Potential functions (at each CM)
as well as the Lagrange multipliers (LM) (at each BS). We show that the
proposed distributive online learning algorithm converges almost surely (with
probability 1). By exploiting the birth-death structure of the queue dynamics,
we further decompose the Per-cluster Potential function into sum of Per-cluster
Per-user Potential functions and formulate the instantaneous power allocation
as a Per-stage QSI-aware Interference Game played among all the CMs. We also
propose a QSI-aware Simultaneous Iterative Water-filling Algorithm (QSIWFA) and
show that it can achieve the Nash Equilibrium (NE).

Survey & Experiment: Towards the Learning Accuracy
To attain the best learning accuracy, people move on with difficulties and
frustrations. Though one can optimize the empirical objective using a given set
of samples, its generalization ability to the entire sample distribution
remains questionable. Even if a fair generalization guarantee is offered, one
still wants to know what is to happen if the regularizer is removed, and/or how
well the artificial loss (like the hinge loss) relates to the accuracy.
  For such reason, this report surveys four different trials towards the
learning accuracy, embracing the major advances in supervised learning theory
in the past four years. Starting from the generic setting of learning, the
first two trials introduce the best optimization and generalization bounds for
convex learning, and the third trial gets rid of the regularizer. As an
innovative attempt, the fourth trial studies the optimization when the
objective is exactly the accuracy, in the special case of binary
classification. This report also analyzes the last trial through experiments.

Travel Time Estimation Using Floating Car Data
This report explores the use of machine learning techniques to accurately
predict travel times in city streets and highways using floating car data
(location information of user vehicles on a road network). The aim of this
report is twofold, first we present a general architecture of solving this
problem, then present and evaluate few techniques on real floating car data
gathered over a month on a 5 Km highway in New Delhi.

How I won the "Chess Ratings - Elo vs the Rest of the World" Competition
This article discusses in detail the rating system that won the kaggle
competition "Chess Ratings: Elo vs the rest of the world". The competition
provided a historical dataset of outcomes for chess games, and aimed to
discover whether novel approaches can predict the outcomes of future games,
more accurately than the well-known Elo rating system. The winning rating
system, called Elo++ in the rest of the article, builds upon the Elo rating
system. Like Elo, Elo++ uses a single rating per player and predicts the
outcome of a game, by using a logistic curve over the difference in ratings of
the players. The major component of Elo++ is a regularization technique that
avoids overfitting these ratings. The dataset of chess games and outcomes is
relatively small and one has to be careful not to draw "too many conclusions"
out of the limited data. Many approaches tested in the competition showed signs
of such an overfitting. The leader-board was dominated by attempts that did a
very good job on a small test dataset, but couldn't generalize well on the
private hold-out dataset. The Elo++ regularization takes into account the
number of games per player, the recency of these games and the ratings of the
opponents. Finally, Elo++ employs a stochastic gradient descent scheme for
training the ratings, and uses only two global parameters (white's advantage
and regularization constant) that are optimized using cross-validation.

The Role of Normalization in the Belief Propagation Algorithm
An important part of problems in statistical physics and computer science can
be expressed as the computation of marginal probabilities over a Markov Random
Field. The belief propagation algorithm, which is an exact procedure to compute
these marginals when the underlying graph is a tree, has gained its popularity
as an efficient way to approximate them in the more general case. In this
paper, we focus on an aspect of the algorithm that did not get that much
attention in the literature, which is the effect of the normalization of the
messages. We show in particular that, for a large class of normalization
strategies, it is possible to focus only on belief convergence. Following this,
we express the necessary and sufficient conditions for local stability of a
fixed point in terms of the graph structure and the beliefs values at the fixed
point. We also explicit some connexion between the normalization constants and
the underlying Bethe Free Energy.

Close the Gaps: A Learning-while-Doing Algorithm for a Class of
  Single-Product Revenue Management Problems
We consider a retailer selling a single product with limited on-hand
inventory over a finite selling season. Customer demand arrives according to a
Poisson process, the rate of which is influenced by a single action taken by
the retailer (such as price adjustment, sales commission, advertisement
intensity, etc.). The relationship between the action and the demand rate is
not known in advance. However, the retailer is able to learn the optimal action
"on the fly" as she maximizes her total expected revenue based on the observed
demand reactions.
  Using the pricing problem as an example, we propose a dynamic
"learning-while-doing" algorithm that only involves function value estimation
to achieve a near-optimal performance. Our algorithm employs a series of
shrinking price intervals and iteratively tests prices within that interval
using a set of carefully chosen parameters. We prove that the convergence rate
of our algorithm is among the fastest of all possible algorithms in terms of
asymptotic "regret" (the relative loss comparing to the full information
optimal solution). Our result closes the performance gaps between parametric
and non-parametric learning and between a post-price mechanism and a
customer-bidding mechanism. Important managerial insight from this research is
that the values of information on both the parametric form of the demand
function as well as each customer's exact reservation price are less important
than prior literature suggests. Our results also suggest that firms would be
better off to perform dynamic learning and action concurrently rather than
sequentially.

A Novel Template-Based Learning Model
This article presents a model which is capable of learning and abstracting
new concepts based on comparing observations and finding the resemblance
between the observations. In the model, the new observations are compared with
the templates which have been derived from the previous experiences. In the
first stage, the objects are first represented through a geometric description
which is used for finding the object boundaries and a descriptor which is
inspired by the human visual system and then they are fed into the model. Next,
the new observations are identified through comparing them with the
previously-learned templates and are used for producing new templates. The
comparisons are made based on measures like Euclidean or correlation distance.
The new template is created by applying onion-pealing algorithm. The algorithm
consecutively uses convex hulls which are made by the points representing the
objects. If the new observation is remarkably similar to one of the observed
categories, it is no longer utilized in creating a new template. The existing
templates are used to provide a description of the new observation. This
description is provided in the templates space. Each template represents a
dimension of the feature space. The degree of the resemblance each template
bears to each object indicates the value associated with the object in that
dimension of the templates space. In this way, the description of the new
observation becomes more accurate and detailed as the time passes and the
experiences increase. We have used this model for learning and recognizing the
new polygons in the polygon space. Representing the polygons was made possible
through employing a geometric method and a method inspired by human visual
system. Various implementations of the model have been compared. The evaluation
results of the model prove its efficiency in learning and deriving new
templates.

EigenNet: A Bayesian hybrid of generative and conditional models for
  sparse learning
It is a challenging task to select correlated variables in a high dimensional
space. To address this challenge, the elastic net has been developed and
successfully applied to many applications. Despite its great success, the
elastic net does not explicitly use correlation information embedded in data to
select correlated variables. To overcome this limitation, we present a novel
Bayesian hybrid model, the EigenNet, that uses the eigenstructures of data to
guide variable selection. Specifically, it integrates a sparse conditional
classification model with a generative model capturing variable correlations in
a principled Bayesian framework. We reparameterize the hybrid model in the
eigenspace to avoid overfiting and to increase the computational efficiency of
its MCMC sampler. Furthermore, we provide an alternative view to the EigenNet
from a regularization perspective: the EigenNet has an adaptive
eigenspace-based composite regularizer, which naturally generalizes the
$l_{1/2}$ regularizer used by the elastic net. Experiments on synthetic and
real data show that the EigenNet significantly outperforms the lasso, the
elastic net, and the Bayesian lasso in terms of prediction accuracy, especially
when the number of training samples is smaller than the number of variables.

Transductive Ordinal Regression
Ordinal regression is commonly formulated as a multi-class problem with
ordinal constraints. The challenge of designing accurate classifiers for
ordinal regression generally increases with the number of classes involved, due
to the large number of labeled patterns that are needed. The availability of
ordinal class labels, however, is often costly to calibrate or difficult to
obtain. Unlabeled patterns, on the other hand, often exist in much greater
abundance and are freely available. To take benefits from the abundance of
unlabeled patterns, we present a novel transductive learning paradigm for
ordinal regression in this paper, namely Transductive Ordinal Regression (TOR).
The key challenge of the present study lies in the precise estimation of both
the ordinal class label of the unlabeled data and the decision functions of the
ordinal classes, simultaneously. The core elements of the proposed TOR include
an objective function that caters to several commonly used loss functions
casted in transductive settings, for general ordinal regression. A label
swapping scheme that facilitates a strictly monotonic decrease in the objective
function value is also introduced. Extensive numerical studies on commonly used
benchmark datasets including the real world sentiment prediction problem are
then presented to showcase the characteristics and efficacies of the proposed
transductive ordinal regression. Further, comparisons to recent
state-of-the-art ordinal regression methods demonstrate the introduced
transductive learning paradigm for ordinal regression led to the robust and
improved performance.

Learning transformed product distributions
We consider the problem of learning an unknown product distribution $X$ over
$\{0,1\}^n$ using samples $f(X)$ where $f$ is a \emph{known} transformation
function. Each choice of a transformation function $f$ specifies a learning
problem in this framework.
  Information-theoretic arguments show that for every transformation function
$f$ the corresponding learning problem can be solved to accuracy $\eps$, using
$\tilde{O}(n/\eps^2)$ examples, by a generic algorithm whose running time may
be exponential in $n.$ We show that this learning problem can be
computationally intractable even for constant $\eps$ and rather simple
transformation functions. Moreover, the above sample complexity bound is nearly
optimal for the general problem, as we give a simple explicit linear
transformation function $f(x)=w \cdot x$ with integer weights $w_i \leq n$ and
prove that the corresponding learning problem requires $\Omega(n)$ samples.
  As our main positive result we give a highly efficient algorithm for learning
a sum of independent unknown Bernoulli random variables, corresponding to the
transformation function $f(x)= \sum_{i=1}^n x_i$. Our algorithm learns to
$\eps$-accuracy in poly$(n)$ time, using a surprising poly$(1/\eps)$ number of
samples that is independent of $n.$ We also give an efficient algorithm that
uses $\log n \cdot \poly(1/\eps)$ samples but has running time that is only
$\poly(\log n, 1/\eps).$

A Feature Selection Method for Multivariate Performance Measures
Feature selection with specific multivariate performance measures is the key
to the success of many applications, such as image retrieval and text
classification. The existing feature selection methods are usually designed for
classification error. In this paper, we propose a generalized sparse
regularizer. Based on the proposed regularizer, we present a unified feature
selection framework for general loss functions. In particular, we study the
novel feature selection paradigm by optimizing multivariate performance
measures. The resultant formulation is a challenging problem for
high-dimensional data. Hence, a two-layer cutting plane algorithm is proposed
to solve this problem, and the convergence is presented. In addition, we adapt
the proposed method to optimize multivariate measures for multiple instance
learning problems. The analyses by comparing with the state-of-the-art feature
selection methods show that the proposed method is superior to others.
Extensive experiments on large-scale and high-dimensional real world datasets
show that the proposed method outperforms $l_1$-SVM and SVM-RFE when choosing a
small subset of features, and achieves significantly improved performances over
SVM$^{perf}$ in terms of $F_1$-score.

Parallel Online Learning
In this work we study parallelization of online learning, a core primitive in
machine learning. In a parallel environment all known approaches for parallel
online learning lead to delayed updates, where the model is updated using
out-of-date information. In the worst case, or when examples are temporally
correlated, delay can have a very adverse effect on the learning algorithm.
Here, we analyze and present preliminary empirical results on a set of learning
architectures based on a feature sharding approach that present various
tradeoffs between delay, degree of parallelism, representation power and
empirical performance.

Gaussian Robust Classification
Supervised learning is all about the ability to generalize knowledge.
Specifically, the goal of the learning is to train a classifier using training
data, in such a way that it will be capable of classifying new unseen data
correctly. In order to acheive this goal, it is important to carefully design
the learner, so it will not overfit the training data. The later can is done
usually by adding a regularization term. The statistical learning theory
explains the success of this method by claiming that it restricts the
complexity of the learned model. This explanation, however, is rather abstract
and does not have a geometric intuition. The generalization error of a
classifier may be thought of as correlated with its robustness to perturbations
of the data: a classifier that copes with disturbance is expected to generalize
well. Indeed, Xu et al. [2009] have shown that the SVM formulation is
equivalent to a robust optimization (RO) formulation, in which an adversary
displaces the training and testing points within a ball of pre-determined
radius. In this work we explore a different kind of robustness, namely changing
each data point with a Gaussian cloud centered at the sample. Loss is evaluated
as the expectation of an underlying loss function on the cloud. This setup fits
the fact that in many applications, the data is sampled along with noise. We
develop an RO framework, in which the adversary chooses the covariance of the
noise. In our algorithm named GURU, the tuning parameter is a spectral bound on
the noise, thus it can be estimated using physical or applicative
considerations. Our experiments show that this framework performs as well as
SVM and even slightly better in some cases. Generalizations for Mercer kernels
and for the multiclass case are presented as well. We also show that our
framework may be further generalized, using the technique of convex perspective
functions.

Meaningful Clustered Forest: an Automatic and Robust Clustering
  Algorithm
We propose a new clustering technique that can be regarded as a numerical
method to compute the proximity gestalt. The method analyzes edge length
statistics in the MST of the dataset and provides an a contrario cluster
detection criterion. The approach is fully parametric on the chosen distance
and can detect arbitrarily shaped clusters. The method is also automatic, in
the sense that only a single parameter is left to the user. This parameter has
an intuitive interpretation as it controls the expected number of false
detections. We show that the iterative application of our method can (1)
provide robustness to noise and (2) solve a masking phenomenon in which a
highly populated and salient cluster dominates the scene and inhibits the
detection of less-populated, but still salient, clusters.

PAC learnability versus VC dimension: a footnote to a basic result of
  statistical learning
A fundamental result of statistical learnig theory states that a concept
class is PAC learnable if and only if it is a uniform Glivenko-Cantelli class
if and only if the VC dimension of the class is finite. However, the theorem is
only valid under special assumptions of measurability of the class, in which
case the PAC learnability even becomes consistent. Otherwise, there is a
classical example, constructed under the Continuum Hypothesis by Dudley and
Durst and further adapted by Blumer, Ehrenfeucht, Haussler, and Warmuth, of a
concept class of VC dimension one which is neither uniform Glivenko-Cantelli
nor consistently PAC learnable. We show that, rather surprisingly, under an
additional set-theoretic hypothesis which is much milder than the Continuum
Hypothesis (Martin's Axiom), PAC learnability is equivalent to finite VC
dimension for every concept class.

Temporal Second Difference Traces
Q-learning is a reliable but inefficient off-policy temporal-difference
method, backing up reward only one step at a time. Replacing traces, using a
recency heuristic, are more efficient but less reliable. In this work, we
introduce model-free, off-policy temporal difference methods that make better
use of experience than Watkins' Q(\lambda). We introduce both Optimistic
Q(\lambda) and the temporal second difference trace (TSDT). TSDT is
particularly powerful in deterministic domains. TSDT uses neither recency nor
frequency heuristics, storing (s,a,r,s',\delta) so that off-policy updates can
be performed after apparently suboptimal actions have been taken. There are
additional advantages when using state abstraction, as in MAXQ. We demonstrate
that TSDT does significantly better than both Q-learning and Watkins'
Q(\lambda) in a deterministic cliff-walking domain. Results in a noisy
cliff-walking domain are less advantageous for TSDT, but demonstrate the
efficacy of Optimistic Q(\lambda), a replacing trace with some of the
advantages of TSDT.

Reducing Commitment to Tasks with Off-Policy Hierarchical Reinforcement
  Learning
In experimenting with off-policy temporal difference (TD) methods in
hierarchical reinforcement learning (HRL) systems, we have observed unwanted
on-policy learning under reproducible conditions. Here we present modifications
to several TD methods that prevent unintentional on-policy learning from
occurring. These modifications create a tension between exploration and
learning. Traditional TD methods require commitment to finishing subtasks
without exploration in order to update Q-values for early actions with high
probability. One-step intra-option learning and temporal second difference
traces (TSDT) do not suffer from this limitation. We demonstrate that our HRL
system is efficient without commitment to completion of subtasks in a
cliff-walking domain, contrary to a widespread claim in the literature that it
is critical for efficiency of learning. Furthermore, decreasing commitment as
exploration progresses is shown to improve both online performance and the
resultant policy in the taxicab domain, opening a new avenue for research into
when it is more beneficial to continue with the current subtask or to replan.

Attacking and Defending Covert Channels and Behavioral Models
In this paper we present methods for attacking and defending $k$-gram
statistical analysis techniques that are used, for example, in network traffic
analysis and covert channel detection. The main new result is our demonstration
of how to use a behavior's or process' $k$-order statistics to build a
stochastic process that has those same $k$-order stationary statistics but
possesses different, deliberately designed, $(k+1)$-order statistics if
desired. Such a model realizes a "complexification" of the process or behavior
which a defender can use to monitor whether an attacker is shaping the
behavior. By deliberately introducing designed $(k+1)$-order behaviors, the
defender can check to see if those behaviors are present in the data. We also
develop constructs for source codes that respect the $k$-order statistics of a
process while encoding covert information. One fundamental consequence of these
results is that certain types of behavior analyses techniques come down to an
{\em arms race} in the sense that the advantage goes to the party that has more
computing resources applied to the problem.

Suboptimal Solution Path Algorithm for Support Vector Machine
We consider a suboptimal solution path algorithm for the Support Vector
Machine. The solution path algorithm is an effective tool for solving a
sequence of a parametrized optimization problems in machine learning. The path
of the solutions provided by this algorithm are very accurate and they satisfy
the optimality conditions more strictly than other SVM optimization algorithms.
In many machine learning application, however, this strict optimality is often
unnecessary, and it adversely affects the computational efficiency. Our
algorithm can generate the path of suboptimal solutions within an arbitrary
user-specified tolerance level. It allows us to control the trade-off between
the accuracy of the solution and the computational cost. Moreover, We also show
that our suboptimal solutions can be interpreted as the solution of a
\emph{perturbed optimization problem} from the original one. We provide some
theoretical analyses of our algorithm based on this novel interpretation. The
experimental results also demonstrate the effectiveness of our algorithm.

Domain Adaptation: Overfitting and Small Sample Statistics
We study the prevalent problem when a test distribution differs from the
training distribution. We consider a setting where our training set consists of
a small number of sample domains, but where we have many samples in each
domain. Our goal is to generalize to a new domain. For example, we may want to
learn a similarity function using only certain classes of objects, but we
desire that this similarity function be applicable to object classes not
present in our training sample (e.g. we might seek to learn that "dogs are
similar to dogs" even though images of dogs were absent from our training set).
Our theoretical analysis shows that we can select many more features than
domains while avoiding overfitting by utilizing data-dependent variance
properties. We present a greedy feature selection algorithm based on using
T-statistics. Our experiments validate this theory showing that our T-statistic
based greedy feature selection is more robust at avoiding overfitting than the
classical greedy procedure.

Adaptively Learning the Crowd Kernel
We introduce an algorithm that, given n objects, learns a similarity matrix
over all n^2 pairs, from crowdsourced data alone. The algorithm samples
responses to adaptively chosen triplet-based relative-similarity queries. Each
query has the form "is object 'a' more similar to 'b' or to 'c'?" and is chosen
to be maximally informative given the preceding responses. The output is an
embedding of the objects into Euclidean space (like MDS); we refer to this as
the "crowd kernel." SVMs reveal that the crowd kernel captures prominent and
subtle features across a number of domains, such as "is striped" among neckties
and "vowel vs. consonant" among letters.

A Maximal Large Deviation Inequality for Sub-Gaussian Variables
In this short note we prove a maximal concentration lemma for sub-Gaussian
random variables stating that for independent sub-Gaussian random variables we
have \[P<(\max_{1\le i\le N}S_{i}>\epsilon>)
\le\exp<(-\frac{1}{N^2}\sum_{i=1}^{N}\frac{\epsilon^{2}}{2\sigma_{i}^{2}}>), \]
where $S_i$ is the sum of $i$ zero mean independent sub-Gaussian random
variables and $\sigma_i$ is the variance of the $i$th random variable.

Calibration with Changing Checking Rules and Its Application to
  Short-Term Trading
We provide a natural learning process in which a financial trader without a
risk receives a gain in case when Stock Market is inefficient. In this process,
the trader rationally choose his gambles using a prediction made by a
randomized calibrated algorithm. Our strategy is based on Dawid's notion of
calibration with more general changing checking rules and on some modification
of Kakade and Foster's randomized algorithm for computing calibrated forecasts.

Bounding the Fat Shattering Dimension of a Composition Function Class
  Built Using a Continuous Logic Connective
We begin this report by describing the Probably Approximately Correct (PAC)
model for learning a concept class, consisting of subsets of a domain, and a
function class, consisting of functions from the domain to the unit interval.
Two combinatorial parameters, the Vapnik-Chervonenkis (VC) dimension and its
generalization, the Fat Shattering dimension of scale e, are explained and a
few examples of their calculations are given with proofs. We then explain
Sauer's Lemma, which involves the VC dimension and is used to prove the
equivalence of a concept class being distribution-free PAC learnable and it
having finite VC dimension.
  As the main new result of our research, we explore the construction of a new
function class, obtained by forming compositions with a continuous logic
connective, a uniformly continuous function from the unit hypercube to the unit
interval, from a collection of function classes. Vidyasagar had proved that
such a composition function class has finite Fat Shattering dimension of all
scales if the classes in the original collection do; however, no estimates of
the dimension were known. Using results by Mendelson-Vershynin and Talagrand,
we bound the Fat Shattering dimension of scale e of this new function class in
terms of the Fat Shattering dimensions of the collection's classes.
  We conclude this report by providing a few open questions and future research
topics involving the PAC learning model.

Online Learning, Stability, and Stochastic Gradient Descent
In batch learning, stability together with existence and uniqueness of the
solution corresponds to well-posedness of Empirical Risk Minimization (ERM)
methods; recently, it was proved that CV_loo stability is necessary and
sufficient for generalization and consistency of ERM. In this note, we
introduce CV_on stability, which plays a similar note in online learning. We
show that stochastic gradient descent (SDG) with the usual hypotheses is CVon
stable and we then discuss the implications of CV_on stability for convergence
of SGD.

Large-Scale Music Annotation and Retrieval: Learning to Rank in Joint
  Semantic Spaces
Music prediction tasks range from predicting tags given a song or clip of
audio, predicting the name of the artist, or predicting related songs given a
song, clip, artist name or tag. That is, we are interested in every semantic
relationship between the different musical concepts in our database. In
realistically sized databases, the number of songs is measured in the hundreds
of thousands or more, and the number of artists in the tens of thousands or
more, providing a considerable challenge to standard machine learning
techniques. In this work, we propose a method that scales to such datasets
which attempts to capture the semantic similarities between the database items
by modeling audio, artist names, and tags in a single low-dimensional semantic
space. This choice of space is learnt by optimizing the set of prediction tasks
of interest jointly using multi-task learning. Our method both outperforms
baseline methods and, in comparison to them, is faster and consumes less
memory. We then demonstrate how our method learns an interpretable model, where
the semantic space captures well the similarities of interest.

Kernel Belief Propagation
We propose a nonparametric generalization of belief propagation, Kernel
Belief Propagation (KBP), for pairwise Markov random fields. Messages are
represented as functions in a reproducing kernel Hilbert space (RKHS), and
message updates are simple linear operations in the RKHS. KBP makes none of the
assumptions commonly required in classical BP algorithms: the variables need
not arise from a finite domain or a Gaussian distribution, nor must their
relations take any particular parametric form. Rather, the relations between
variables are represented implicitly, and are learned nonparametrically from
training data. KBP has the advantage that it may be used on any domain where
kernels are defined (Rd, strings, groups), even where explicit parametric
models are not known, or closed form expressions for the BP updates do not
exist. The computational cost of message updates in KBP is polynomial in the
training data size. We also propose a constant time approximate message update
procedure by representing messages using a small number of basis functions. In
experiments, we apply KBP to image denoising, depth prediction from still
images, and protein configuration prediction: KBP is faster than competing
classical and nonparametric approaches (by orders of magnitude, in some cases),
while providing significantly more accurate results.

The Perceptron with Dynamic Margin
The classical perceptron rule provides a varying upper bound on the maximum
margin, namely the length of the current weight vector divided by the total
number of updates up to that time. Requiring that the perceptron updates its
internal state whenever the normalized margin of a pattern is found not to
exceed a certain fraction of this dynamic upper bound we construct a new
approximate maximum margin classifier called the perceptron with dynamic margin
(PDM). We demonstrate that PDM converges in a finite number of steps and derive
an upper bound on them. We also compare experimentally PDM with other
perceptron-like algorithms and support vector machines on hard margin tasks
involving linear kernels which are equivalent to 2-norm soft margin.

A Unified Framework for Approximating and Clustering Data
Given a set $F$ of $n$ positive functions over a ground set $X$, we consider
the problem of computing $x^*$ that minimizes the expression $\sum_{f\in
F}f(x)$, over $x\in X$. A typical application is \emph{shape fitting}, where we
wish to approximate a set $P$ of $n$ elements (say, points) by a shape $x$ from
a (possibly infinite) family $X$ of shapes. Here, each point $p\in P$
corresponds to a function $f$ such that $f(x)$ is the distance from $p$ to $x$,
and we seek a shape $x$ that minimizes the sum of distances from each point in
$P$. In the $k$-clustering variant, each $x\in X$ is a tuple of $k$ shapes, and
$f(x)$ is the distance from $p$ to its closest shape in $x$.
  Our main result is a unified framework for constructing {\em coresets} and
{\em approximate clustering} for such general sets of functions. To achieve our
results, we forge a link between the classic and well defined notion of
$\varepsilon$-approximations from the theory of PAC Learning and VC dimension,
to the relatively new (and not so consistent) paradigm of coresets, which are
some kind of "compressed representation" of the input set $F$. Using
traditional techniques, a coreset usually implies an LTAS (linear time
approximation scheme) for the corresponding optimization problem, which can be
computed in parallel, via one pass over the data, and using only
polylogarithmic space (i.e, in the streaming model).
  We show how to generalize the results of our framework for squared distances
(as in $k$-mean), distances to the $q$th power, and deterministic
constructions.

Max-Margin Stacking and Sparse Regularization for Linear Classifier
  Combination and Selection
The main principle of stacked generalization (or Stacking) is using a
second-level generalizer to combine the outputs of base classifiers in an
ensemble. In this paper, we investigate different combination types under the
stacking framework; namely weighted sum (WS), class-dependent weighted sum
(CWS) and linear stacked generalization (LSG). For learning the weights, we
propose using regularized empirical risk minimization with the hinge loss. In
addition, we propose using group sparsity for regularization to facilitate
classifier selection. We performed experiments using two different ensemble
setups with differing diversities on 8 real-world datasets. Results show the
power of regularized learning with the hinge loss function. Using sparse
regularization, we are able to reduce the number of selected classifiers of the
diverse ensemble without sacrificing accuracy. With the non-diverse ensembles,
we even gain accuracy on average by using sparse regularization.

Reinforcement learning based sensing policy optimization for energy
  efficient cognitive radio networks
This paper introduces a machine learning based collaborative multi-band
spectrum sensing policy for cognitive radios. The proposed sensing policy
guides secondary users to focus the search of unused radio spectrum to those
frequencies that persistently provide them high data rate. The proposed policy
is based on machine learning, which makes it adaptive with the temporally and
spatially varying radio spectrum. Furthermore, there is no need for dynamic
modeling of the primary activity since it is implicitly learned over time.
Energy efficiency is achieved by minimizing the number of assigned sensors per
each subband under a constraint on miss detection probability. It is important
to control the missed detections because they cause collisions with primary
transmissions and lead to retransmissions at both the primary and secondary
user. Simulations show that the proposed machine learning based sensing policy
improves the overall throughput of the secondary network and improves the
energy efficiency while controlling the miss detection probability.

Learning the Dependence Graph of Time Series with Latent Factors
This paper considers the problem of learning, from samples, the dependency
structure of a system of linear stochastic differential equations, when some of
the variables are latent. In particular, we observe the time evolution of some
variables, and never observe other variables; from this, we would like to find
the dependency structure between the observed variables - separating out the
spurious interactions caused by the (marginalizing out of the) latent
variables' time series. We develop a new method, based on convex optimization,
to do so in the case when the number of latent variables is smaller than the
number of observed ones. For the case when the dependency structure between the
observed variables is sparse, we theoretically establish a high-dimensional
scaling result for structure recovery. We verify our theoretical result with
both synthetic and real data (from the stock market).

On epsilon-optimality of the pursuit learning algorithm
Estimator algorithms in learning automata are useful tools for adaptive,
real-time optimization in computer science and engineering applications. This
paper investigates theoretical convergence properties for a special case of
estimator algorithms: the pursuit learning algorithm. In this note, we identify
and fill a gap in existing proofs of probabilistic convergence for pursuit
learning. It is tradition to take the pursuit learning tuning parameter to be
fixed in practical applications, but our proof sheds light on the importance of
a vanishing sequence of tuning parameters in a theoretical convergence
analysis.

Decoding finger movements from ECoG signals using switching linear
  models
One of the major challenges of ECoG-based Brain-Machine Interfaces is the
movement prediction of a human subject. Several methods exist to predict an arm
2-D trajectory. The fourth BCI Competition gives a dataset in which the aim is
to predict individual finger movements (5-D trajectory). The difficulty lies in
the fact that there is no simple relation between ECoG signals and finger
movement. We propose in this paper to decode finger flexions using switching
models. This method permits to simplify the system as it is now described as an
ensemble of linear models depending on an internal state. We show that an
interesting accuracy prediction can be obtained by such a model.

Large margin filtering for signal sequence labeling
Signal Sequence Labeling consists in predicting a sequence of labels given an
observed sequence of samples. A naive way is to filter the signal in order to
reduce the noise and to apply a classification algorithm on the filtered
samples. We propose in this paper to jointly learn the filter with the
classifier leading to a large margin filtering for classification. This method
allows to learn the optimal cutoff frequency and phase of the filter that may
be different from zero. Two methods are proposed and tested on a toy dataset
and on a real life BCI dataset from BCI Competition III.

Handling uncertainties in SVM classification
This paper addresses the pattern classification problem arising when
available target data include some uncertainty information. Target data
considered here is either qualitative (a class label) or quantitative (an
estimation of the posterior probability). Our main contribution is a SVM
inspired formulation of this problem allowing to take into account class label
through a hinge loss as well as probability estimates using epsilon-insensitive
cost function together with a minimum norm (maximum margin) objective. This
formulation shows a dual form leading to a quadratic problem and allows the use
of a representer theorem and associated kernel. The solution provided can be
used for both decision and posterior probability estimation. Based on empirical
evidence our method outperforms regular SVM in terms of probability predictions
and classification performances.

Algorithmic Programming Language Identification
Motivated by the amount of code that goes unidentified on the web, we
introduce a practical method for algorithmically identifying the programming
language of source code. Our work is based on supervised learning and
intelligent statistical features. We also explored, but abandoned, a
grammatical approach. In testing, our implementation greatly outperforms that
of an existing tool that relies on a Bayesian classifier. Code is written in
Python and available under an MIT license.

Better Mini-Batch Algorithms via Accelerated Gradient Methods
Mini-batch algorithms have been proposed as a way to speed-up stochastic
convex optimization problems. We study how such algorithms can be improved
using accelerated gradient methods. We provide a novel analysis, which shows
how standard gradient methods may sometimes be insufficient to obtain a
significant speed-up and propose a novel accelerated gradient algorithm, which
deals with this deficiency, enjoys a uniformly superior guarantee and works
well in practice.

Potential-Based Shaping and Q-Value Initialization are Equivalent
Shaping has proven to be a powerful but precarious means of improving
reinforcement learning performance. Ng, Harada, and Russell (1999) proposed the
potential-based shaping algorithm for adding shaping rewards in a way that
guarantees the learner will learn optimal behavior. In this note, we prove
certain similarities between this shaping algorithm and the initialization step
required for several reinforcement learning algorithms. More specifically, we
prove that a reinforcement learner with initial Q-values based on the shaping
algorithm's potential function make the same updates throughout learning as a
learner receiving potential-based shaping rewards. We further prove that under
a broad category of policies, the behavior of these two learners are
indistinguishable. The comparison provides intuition on the theoretical
properties of the shaping algorithm as well as a suggestion for a simpler
method for capturing the algorithm's benefit. In addition, the equivalence
raises previously unaddressed issues concerning the efficiency of learning with
potential-based shaping.

IBSEAD: - A Self-Evolving Self-Obsessed Learning Algorithm for Machine
  Learning
We present IBSEAD or distributed autonomous entity systems based Interaction
- a learning algorithm for the computer to self-evolve in a self-obsessed
manner. This learning algorithm will present the computer to look at the
internal and external environment in series of independent entities, which will
interact with each other, with and/or without knowledge of the computer's
brain. When a learning algorithm interacts, it does so by detecting and
understanding the entities in the human algorithm. However, the problem with
this approach is that the algorithm does not consider the interaction of the
third party or unknown entities, which may be interacting with each other.
These unknown entities in their interaction with the non-computer entities make
an effect in the environment that influences the information and the behaviour
of the computer brain. Such details and the ability to process the dynamic and
unsettling nature of these interactions are absent in the current learning
algorithm such as the decision tree learning algorithm. IBSEAD is able to
evaluate and consider such algorithms and thus give us a better accuracy in
simulation of the highly evolved nature of the human brain. Processes such as
dreams, imagination and novelty, that exist in humans are not fully simulated
by the existing learning algorithms. Also, Hidden Markov models (HMM) are
useful in finding "hidden" entities, which may be known or unknown. However,
this model fails to consider the case of unknown entities which maybe unclear
or unknown. IBSEAD is better because it considers three types of entities-
known, unknown and invisible. We present our case with a comparison of existing
algorithms in known environments and cases and present the results of the
experiments using dry run of the simulated runs of the existing machine
learning algorithms versus IBSEAD.

A Note on Improved Loss Bounds for Multiple Kernel Learning
In this paper, we correct an upper bound, presented in~\cite{hs-11}, on the
generalisation error of classifiers learned through multiple kernel learning.
The bound in~\cite{hs-11} uses Rademacher complexity and has an\emph{additive}
dependence on the logarithm of the number of kernels and the margin achieved by
the classifier. However, there are some errors in parts of the proof which are
corrected in this paper. Unfortunately, the final result turns out to be a risk
bound which has a \emph{multiplicative} dependence on the logarithm of the
number of kernels and the margin achieved by the classifier.

GraphLab: A Distributed Framework for Machine Learning in the Cloud
Machine Learning (ML) techniques are indispensable in a wide range of fields.
Unfortunately, the exponential increase of dataset sizes are rapidly extending
the runtime of sequential algorithms and threatening to slow future progress in
ML. With the promise of affordable large-scale parallel computing, Cloud
systems offer a viable platform to resolve the computational challenges in ML.
However, designing and implementing efficient, provably correct distributed ML
algorithms is often prohibitively challenging. To enable ML researchers to
easily and efficiently use parallel systems, we introduced the GraphLab
abstraction which is designed to represent the computational patterns in ML
algorithms while permitting efficient parallel and distributed implementations.
In this paper we provide a formal description of the GraphLab parallel
abstraction and present an efficient distributed implementation. We conduct a
comprehensive evaluation of GraphLab on three state-of-the-art ML algorithms
using real large-scale data and a 64 node EC2 cluster of 512 processors. We
find that GraphLab achieves orders of magnitude performance gains over Hadoop
while performing comparably or superior to hand-tuned MPI implementations.

Towards Optimal One Pass Large Scale Learning with Averaged Stochastic
  Gradient Descent
For large scale learning problems, it is desirable if we can obtain the
optimal model parameters by going through the data in only one pass. Polyak and
Juditsky (1992) showed that asymptotically the test performance of the simple
average of the parameters obtained by stochastic gradient descent (SGD) is as
good as that of the parameters which minimize the empirical cost. However, to
our knowledge, despite its optimal asymptotic convergence rate, averaged SGD
(ASGD) received little attention in recent research on large scale learning.
One possible reason is that it may take a prohibitively large number of
training samples for ASGD to reach its asymptotic region for most real
problems. In this paper, we present a finite sample analysis for the method of
Polyak and Juditsky (1992). Our analysis shows that it indeed usually takes a
huge number of samples for ASGD to reach its asymptotic region for improperly
chosen learning rate. More importantly, based on our analysis, we propose a
simple way to properly set learning rate so that it takes a reasonable amount
of data for ASGD to reach its asymptotic region. We compare ASGD using our
proposed learning rate with other well known algorithms for training large
scale linear classifiers. The experiments clearly show the superiority of ASGD.

Discovering Knowledge using a Constraint-based Language
Discovering pattern sets or global patterns is an attractive issue from the
pattern mining community in order to provide useful information. By combining
local patterns satisfying a joint meaning, this approach produces patterns of
higher level and thus more useful for the data analyst than the usual local
patterns, while reducing the number of patterns. In parallel, recent works
investigating relationships between data mining and constraint programming (CP)
show that the CP paradigm is a nice framework to model and mine such patterns
in a declarative and generic way. We present a constraint-based language which
enables us to define queries addressing patterns sets and global patterns. The
usefulness of such a declarative approach is highlighted by several examples
coming from the clustering based on associations. This language has been
implemented in the CP framework.

On the Universality of Online Mirror Descent
We show that for a general class of convex online learning problems, Mirror
Descent can always achieve a (nearly) optimal regret guarantee.

The Divergence of Reinforcement Learning Algorithms with Value-Iteration
  and Function Approximation
This paper gives specific divergence examples of value-iteration for several
major Reinforcement Learning and Adaptive Dynamic Programming algorithms, when
using a function approximator for the value function. These divergence examples
differ from previous divergence examples in the literature, in that they are
applicable for a greedy policy, i.e. in a "value iteration" scenario. Perhaps
surprisingly, with a greedy policy, it is also possible to get divergence for
the algorithms TD(1) and Sarsa(1). In addition to these divergences, we also
achieve divergence for the Adaptive Dynamic Programming algorithms HDP, DHP and
GDHP.

Axioms for Rational Reinforcement Learning
We provide a formal, simple and intuitive theory of rational decision making
including sequential decisions that affect the environment. The theory has a
geometric flavor, which makes the arguments easy to visualize and understand.
Our theory is for complete decision makers, which means that they have a
complete set of preferences. Our main result shows that a complete rational
decision maker implicitly has a probabilistic model of the environment. We have
a countable version of this result that brings light on the issue of countable
vs finite additivity by showing how it depends on the geometry of the space
which we have preferences over. This is achieved through fruitfully connecting
rationality with the Hahn-Banach Theorem. The theory presented here can be
viewed as a formalization and extension of the betting odds approach to
probability of Ramsey and De Finetti.

Automatic Network Reconstruction using ASP
Building biological models by inferring functional dependencies from
experimental data is an im- portant issue in Molecular Biology. To relieve the
biologist from this traditionally manual process, various approaches have been
proposed to increase the degree of automation. However, available ap- proaches
often yield a single model only, rely on specific assumptions, and/or use
dedicated, heuris- tic algorithms that are intolerant to changing circumstances
or requirements in the view of the rapid progress made in Biotechnology. Our
aim is to provide a declarative solution to the problem by ap- peal to Answer
Set Programming (ASP) overcoming these difficulties. We build upon an existing
approach to Automatic Network Reconstruction proposed by part of the authors.
This approach has firm mathematical foundations and is well suited for ASP due
to its combinatorial flavor providing a characterization of all models
explaining a set of experiments. The usage of ASP has several ben- efits over
the existing heuristic algorithms. First, it is declarative and thus
transparent for biological experts. Second, it is elaboration tolerant and thus
allows for an easy exploration and incorporation of biological constraints.
Third, it allows for exploring the entire space of possible models. Finally,
our approach offers an excellent performance, matching existing,
special-purpose systems.

Feature Extraction for Change-Point Detection using Stationary Subspace
  Analysis
Detecting changes in high-dimensional time series is difficult because it
involves the comparison of probability densities that need to be estimated from
finite samples. In this paper, we present the first feature extraction method
tailored to change point detection, which is based on an extended version of
Stationary Subspace Analysis. We reduce the dimensionality of the data to the
most non-stationary directions, which are most informative for detecting state
changes in the time series. In extensive simulations on synthetic data we show
that the accuracy of three change point detection algorithms is significantly
increased by a prior feature extraction step. These findings are confirmed in
an application to industrial fault monitoring.

Optimal Algorithms for Ridge and Lasso Regression with Partially
  Observed Attributes
We consider the most common variants of linear regression, including Ridge,
Lasso and Support-vector regression, in a setting where the learner is allowed
to observe only a fixed number of attributes of each example at training time.
We present simple and efficient algorithms for these problems: for Lasso and
Ridge regression they need the same total number of attributes (up to
constants) as do full-information algorithms, for reaching a certain accuracy.
For Support-vector regression, we require exponentially less attributes
compared to the state of the art. By that, we resolve an open problem recently
posed by Cesa-Bianchi et al. (2010). Experiments show the theoretical bounds to
be justified by superior performance compared to the state of the art.

Non-trivial two-armed partial-monitoring games are bandits
We consider online learning in partial-monitoring games against an oblivious
adversary. We show that when the number of actions available to the learner is
two and the game is nontrivial then it is reducible to a bandit-like game and
thus the minimax regret is $\Theta(\sqrt{T})$.

Local Component Analysis
Kernel density estimation, a.k.a. Parzen windows, is a popular density
estimation method, which can be used for outlier detection or clustering. With
multivariate data, its performance is heavily reliant on the metric used within
the kernel. Most earlier work has focused on learning only the bandwidth of the
kernel (i.e., a scalar multiplicative factor). In this paper, we propose to
learn a full Euclidean metric through an expectation-minimization (EM)
procedure, which can be seen as an unsupervised counterpart to neighbourhood
component analysis (NCA). In order to avoid overfitting with a fully
nonparametric density estimator in high dimensions, we also consider a
semi-parametric Gaussian-Parzen density model, where some of the variables are
modelled through a jointly Gaussian density, while others are modelled through
Parzen windows. For these two models, EM leads to simple closed-form updates
based on matrix inversions and eigenvalue decompositions. We show empirically
that our method leads to density estimators with higher test-likelihoods than
natural competing methods, and that the metrics may be used within most
unsupervised learning techniques that rely on such metrics, such as spectral
clustering or manifold learning methods. Finally, we present a stochastic
approximation scheme which allows for the use of this method in a large-scale
setting.

Weighted Clustering
One of the most prominent challenges in clustering is "the user's dilemma,"
which is the problem of selecting an appropriate clustering algorithm for a
specific task. A formal approach for addressing this problem relies on the
identification of succinct, user-friendly properties that formally capture when
certain clustering methods are preferred over others.
  Until now these properties focused on advantages of classical Linkage-Based
algorithms, failing to identify when other clustering paradigms, such as
popular center-based methods, are preferable. We present surprisingly simple
new properties that delineate the differences between common clustering
paradigms, which clearly and formally demonstrates advantages of center-based
approaches for some applications. These properties address how sensitive
algorithms are to changes in element frequencies, which we capture in a
generalized setting where every element is associated with a real-valued
weight.

Learning From Labeled And Unlabeled Data: An Empirical Study Across
  Techniques And Domains
There has been increased interest in devising learning techniques that
combine unlabeled data with labeled data ? i.e. semi-supervised learning.
However, to the best of our knowledge, no study has been performed across
various techniques and different types and amounts of labeled and unlabeled
data. Moreover, most of the published work on semi-supervised learning
techniques assumes that the labeled and unlabeled data come from the same
distribution. It is possible for the labeling process to be associated with a
selection bias such that the distributions of data points in the labeled and
unlabeled sets are different. Not correcting for such bias can result in biased
function approximation with potentially poor performance. In this paper, we
present an empirical study of various semi-supervised learning techniques on a
variety of datasets. We attempt to answer various questions such as the effect
of independence or relevance amongst features, the effect of the size of the
labeled and unlabeled sets and the effect of noise. We also investigate the
impact of sample-selection bias on the semi-supervised learning techniques
under study and implement a bivariate probit technique particularly designed to
correct for such bias.

Efficiency versus Convergence of Boolean Kernels for On-Line Learning
  Algorithms
The paper studies machine learning problems where each example is described
using a set of Boolean features and where hypotheses are represented by linear
threshold elements. One method of increasing the expressiveness of learned
hypotheses in this context is to expand the feature set to include conjunctions
of basic features. This can be done explicitly or where possible by using a
kernel function. Focusing on the well known Perceptron and Winnow algorithms,
the paper demonstrates a tradeoff between the computational efficiency with
which the algorithm can be run over the expanded feature space and the
generalization ability of the corresponding learning algorithm. We first
describe several kernel functions which capture either limited forms of
conjunctions or all conjunctions. We show that these kernels can be used to
efficiently run the Perceptron algorithm over a feature space of exponentially
many conjunctions; however we also show that using such kernels, the Perceptron
algorithm can provably make an exponential number of mistakes even when
learning simple functions. We then consider the question of whether kernel
functions can analogously be used to run the multiplicative-update Winnow
algorithm over an expanded feature space of exponentially many conjunctions.
Known upper bounds imply that the Winnow algorithm can learn Disjunctive Normal
Form (DNF) formulae with a polynomial mistake bound in this setting. However,
we prove that it is computationally hard to simulate Winnows behavior for
learning DNF over such a feature set. This implies that the kernel functions
which correspond to running Winnow for this problem are not efficiently
computable, and that there is no general construction that can run Winnow with
kernels.

Risk-Sensitive Reinforcement Learning Applied to Control under
  Constraints
In this paper, we consider Markov Decision Processes (MDPs) with error
states. Error states are those states entering which is undesirable or
dangerous. We define the risk with respect to a policy as the probability of
entering such a state when the policy is pursued. We consider the problem of
finding good policies whose risk is smaller than some user-specified threshold,
and formalize it as a constrained MDP with two criteria. The first criterion
corresponds to the value function originally given. We will show that the risk
can be formulated as a second criterion function based on a cumulative return,
whose definition is independent of the original value function. We present a
model free, heuristic reinforcement learning algorithm that aims at finding
good deterministic policies. It is based on weighting the original value
function and the risk. The weight parameter is adapted in order to find a
feasible solution for the constrained problem that has a good performance with
respect to the value function. The algorithm was successfully applied to the
control of a feed tank with stochastic inflows that lies upstream of a
distillation column. This control task was originally formulated as an optimal
control problem with chance constraints, and it was solved under certain
assumptions on the model to obtain an optimal solution. The power of our
learning algorithm is that it can be used even when some of these restrictive
assumptions are relaxed.

Bandits with an Edge
We consider a bandit problem over a graph where the rewards are not directly
observed. Instead, the decision maker can compare two nodes and receive
(stochastic) information pertaining to the difference in their value. The graph
structure describes the set of possible comparisons. Consequently, comparing
between two nodes that are relatively far requires estimating the difference
between every pair of nodes on the path between them. We analyze this problem
from the perspective of sample complexity: How many queries are needed to find
an approximately optimal node with probability more than $1-\delta$ in the PAC
setup? We show that the topology of the graph plays a crucial in defining the
sample complexity: graphs with a low diameter have a much better sample
complexity.

Distributed User Profiling via Spectral Methods
User profiling is a useful primitive for constructing personalised services,
such as content recommendation. In the present paper we investigate the
feasibility of user profiling in a distributed setting, with no central
authority and only local information exchanges between users. We compute a
profile vector for each user (i.e., a low-dimensional vector that characterises
her taste) via spectral transformation of observed user-produced ratings for
items. Our two main contributions follow: i) We consider a low-rank
probabilistic model of user taste. More specifically, we consider that users
and items are partitioned in a constant number of classes, such that users and
items within the same class are statistically identical. We prove that without
prior knowledge of the compositions of the classes, based solely on few random
observed ratings (namely $O(N\log N)$ such ratings for $N$ users), we can
predict user preference with high probability for unrated items by running a
local vote among users with similar profile vectors. In addition, we provide
empirical evaluations characterising the way in which spectral profiling
performance depends on the dimension of the profile space. Such evaluations are
performed on a data set of real user ratings provided by Netflix. ii) We
develop distributed algorithms which provably achieve an embedding of users
into a low-dimensional space, based on spectral transformation. These involve
simple message passing among users, and provably converge to the desired
embedding. Our method essentially relies on a novel combination of gossiping
and the algorithm proposed by Oja and Karhunen.

Learning Topic Models by Belief Propagation
Latent Dirichlet allocation (LDA) is an important hierarchical Bayesian model
for probabilistic topic modeling, which attracts worldwide interests and
touches on many important applications in text mining, computer vision and
computational biology. This paper represents LDA as a factor graph within the
Markov random field (MRF) framework, which enables the classic loopy belief
propagation (BP) algorithm for approximate inference and parameter estimation.
Although two commonly-used approximate inference methods, such as variational
Bayes (VB) and collapsed Gibbs sampling (GS), have gained great successes in
learning LDA, the proposed BP is competitive in both speed and accuracy as
validated by encouraging experimental results on four large-scale document data
sets. Furthermore, the BP algorithm has the potential to become a generic
learning scheme for variants of LDA-based topic models. To this end, we show
how to learn two typical variants of LDA-based topic models, such as
author-topic models (ATM) and relational topic models (RTM), using BP based on
the factor graph representation.

Application of distances between terms for flat and hierarchical data
In machine learning, distance-based algorithms, and other approaches, use
information that is represented by propositional data. However, this kind of
representation can be quite restrictive and, in many cases, it requires more
complex structures in order to represent data in a more natural way. Terms are
the basis for functional and logic programming representation. Distances
between terms are a useful tool not only to compare terms, but also to
determine the search space in many of these applications. This dissertation
applies distances between terms, exploiting the features of each distance and
the possibility to compare from propositional data types to hierarchical
representations. The distances between terms are applied through the k-NN
(k-nearest neighbor) classification algorithm using XML as a common language
representation. To be able to represent these data in an XML structure and to
take advantage of the benefits of distance between terms, it is necessary to
apply some transformations. These transformations allow the conversion of flat
data into hierarchical data represented in XML, using some techniques based on
intuitive associations between the names and values of variables and
associations based on attribute similarity.
  Several experiments with the distances between terms of Nienhuys-Cheng and
Estruch et al. were performed. In the case of originally propositional data,
these distances are compared to the Euclidean distance. In all cases, the
experiments were performed with the distance-weighted k-nearest neighbor
algorithm, using several exponents for the attraction function (weighted
distance). It can be seen that in some cases, the term distances can
significantly improve the results on approaches applied to flat
representations.

Noise Tolerance under Risk Minimization
In this paper we explore noise tolerant learning of classifiers. We formulate
the problem as follows. We assume that there is an ${\bf unobservable}$
training set which is noise-free. The actual training set given to the learning
algorithm is obtained from this ideal data set by corrupting the class label of
each example. The probability that the class label of an example is corrupted
is a function of the feature vector of the example. This would account for most
kinds of noisy data one encounters in practice. We say that a learning method
is noise tolerant if the classifiers learnt with the ideal noise-free data and
with noisy data, both have the same classification accuracy on the noise-free
data. In this paper we analyze the noise tolerance properties of risk
minimization (under different loss functions), which is a generic method for
learning classifiers. We show that risk minimization under 0-1 loss function
has impressive noise tolerance properties and that under squared error loss is
tolerant only to uniform noise; risk minimization under other loss functions is
not noise tolerant. We conclude the paper with some discussion on implications
of these theoretical results.

Active Learning with Multiple Views
Active learners alleviate the burden of labeling large amounts of data by
detecting and asking the user to label only the most informative examples in
the domain. We focus here on active learning for multi-view domains, in which
there are several disjoint subsets of features (views), each of which is
sufficient to learn the target concept. In this paper we make several
contributions. First, we introduce Co-Testing, which is the first approach to
multi-view active learning. Second, we extend the multi-view learning framework
by also exploiting weak views, which are adequate only for learning a concept
that is more general/specific than the target concept. Finally, we empirically
show that Co-Testing outperforms existing active learners on a variety of real
world domains such as wrapper induction, Web page classification, advertisement
removal, and discourse tree parsing.

The Augmented Complex Kernel LMS
Recently, a unified framework for adaptive kernel based signal processing of
complex data was presented by the authors, which, besides offering techniques
to map the input data to complex Reproducing Kernel Hilbert Spaces, developed a
suitable Wirtinger-like Calculus for general Hilbert Spaces. In this short
paper, the extended Wirtinger's calculus is adopted to derive complex
kernel-based widely-linear estimation filters. Furthermore, we illuminate
several important characteristics of the widely linear filters. We show that,
although in many cases the gains from adopting widely linear estimation
filters, as alternatives to ordinary linear ones, are rudimentary, for the case
of kernel based widely linear filters significant performance improvements can
be obtained.

Dynamic Matrix Factorization: A State Space Approach
Matrix factorization from a small number of observed entries has recently
garnered much attention as the key ingredient of successful recommendation
systems. One unresolved problem in this area is how to adapt current methods to
handle changing user preferences over time. Recent proposals to address this
issue are heuristic in nature and do not fully exploit the time-dependent
structure of the problem. As a principled and general temporal formulation, we
propose a dynamical state space model of matrix factorization. Our proposal
builds upon probabilistic matrix factorization, a Bayesian model with Gaussian
priors. We utilize results in state tracking, such as the Kalman filter, to
provide accurate recommendations in the presence of both process and
measurement noise. We show how system parameters can be learned via
expectation-maximization and provide comparisons to current published
techniques.

Active Learning Using Smooth Relative Regret Approximations with
  Applications
The disagreement coefficient of Hanneke has become a central data independent
invariant in proving active learning rates. It has been shown in various ways
that a concept class with low complexity together with a bound on the
disagreement coefficient at an optimal solution allows active learning rates
that are superior to passive learning ones.
  We present a different tool for pool based active learning which follows from
the existence of a certain uniform version of low disagreement coefficient, but
is not equivalent to it. In fact, we present two fundamental active learning
problems of significant interest for which our approach allows nontrivial
active learning bounds. However, any general purpose method relying on the
disagreement coefficient bounds only fails to guarantee any useful bounds for
these problems.
  The tool we use is based on the learner's ability to compute an estimator of
the difference between the loss of any hypotheses and some fixed "pivotal"
hypothesis to within an absolute error of at most $\eps$ times the

Supervised learning of short and high-dimensional temporal sequences for
  life science measurements
The analysis of physiological processes over time are often given by
spectrometric or gene expression profiles over time with only few time points
but a large number of measured variables. The analysis of such temporal
sequences is challenging and only few methods have been proposed. The
information can be encoded time independent, by means of classical expression
differences for a single time point or in expression profiles over time.
Available methods are limited to unsupervised and semi-supervised settings. The
predictive variables can be identified only by means of wrapper or
post-processing techniques. This is complicated due to the small number of
samples for such studies. Here, we present a supervised learning approach,
termed Supervised Topographic Mapping Through Time (SGTM-TT). It learns a
supervised mapping of the temporal sequences onto a low dimensional grid. We
utilize a hidden markov model (HMM) to account for the time domain and
relevance learning to identify the relevant feature dimensions most predictive
over time. The learned mapping can be used to visualize the temporal sequences
and to predict the class of a new sequence. The relevance learning permits the
identification of discriminating masses or gen expressions and prunes
dimensions which are unnecessary for the classification task or encode mainly
noise. In this way we obtain a very efficient learning system for temporal
sequences. The results indicate that using simultaneous supervised learning and
metric adaptation significantly improves the prediction accuracy for
synthetically and real life data in comparison to the standard techniques. The
discriminating features, identified by relevance learning, compare favorably
with the results of alternative methods. Our method permits the visualization
of the data on a low dimensional grid, highlighting the observed temporal
structure.

Dynamic Batch Bayesian Optimization
Bayesian optimization (BO) algorithms try to optimize an unknown function
that is expensive to evaluate using minimum number of evaluations/experiments.
Most of the proposed algorithms in BO are sequential, where only one experiment
is selected at each iteration. This method can be time inefficient when each
experiment takes a long time and more than one experiment can be ran
concurrently. On the other hand, requesting a fix-sized batch of experiments at
each iteration causes performance inefficiency in BO compared to the sequential
policies. In this paper, we present an algorithm that asks a batch of
experiments at each time step t where the batch size p_t is dynamically
determined in each step. Our algorithm is based on the observation that the
sequence of experiments selected by the sequential policy can sometimes be
almost independent from each other. Our algorithm identifies such scenarios and
request those experiments at the same time without degrading the performance.
We evaluate our proposed method using the Expected Improvement policy and the
results show substantial speedup with little impact on the performance in eight
real and synthetic benchmarks.

Injecting External Solutions Into CMA-ES
This report considers how to inject external candidate solutions into the
CMA-ES algorithm. The injected solutions might stem from a gradient or a Newton
step, a surrogate model optimizer or any other oracle or search mechanism. They
can also be the result of a repair mechanism, for example to render infeasible
solutions feasible. Only small modifications to the CMA-ES are necessary to
turn injection into a reliable and effective method: too long steps need to be
tightly renormalized. The main objective of this report is to reveal this
simple mechanism. Depending on the source of the injected solutions,
interesting variants of CMA-ES arise. When the best-ever solution is always
(re-)injected, an elitist variant of CMA-ES with weighted multi-recombination
arises. When \emph{all} solutions are injected from an \emph{external} source,
the resulting algorithm might be viewed as \emph{adaptive encoding} with
step-size control. In first experiments, injected solutions of very good
quality lead to a convergence speed twice as fast as on the (simple) sphere
function without injection. This means that we observe an impressive speed-up
on otherwise difficult to solve functions. Single bad injected solutions on the
other hand do no significant harm.

Data-dependent kernels in nearly-linear time
We propose a method to efficiently construct data-dependent kernels which can
make use of large quantities of (unlabeled) data. Our construction makes an
approximation in the standard construction of semi-supervised kernels in
Sindhwani et al. 2005. In typical cases these kernels can be computed in
nearly-linear time (in the amount of data), improving on the cubic time of the
standard construction, enabling large scale semi-supervised learning in a
variety of contexts. The methods are validated on semi-supervised and
unsupervised problems on data sets containing upto 64,000 sample points.

Learning Hierarchical and Topographic Dictionaries with Structured
  Sparsity
Recent work in signal processing and statistics have focused on defining new
regularization functions, which not only induce sparsity of the solution, but
also take into account the structure of the problem. We present in this paper a
class of convex penalties introduced in the machine learning community, which
take the form of a sum of l_2 and l_infinity-norms over groups of variables.
They extend the classical group-sparsity regularization in the sense that the
groups possibly overlap, allowing more flexibility in the group design. We
review efficient optimization methods to deal with the corresponding inverse
problems, and their application to the problem of learning dictionaries of
natural image patches: On the one hand, dictionary learning has indeed proven
effective for various signal processing tasks. On the other hand, structured
sparsity provides a natural framework for modeling dependencies between
dictionary elements. We thus consider a structured sparse regularization to
learn dictionaries embedded in a particular structure, for instance a tree or a
two-dimensional grid. In the latter case, the results we obtain are similar to
the dictionaries produced by topographic independent component analysis.

Wikipedia Edit Number Prediction based on Temporal Dynamics Only
In this paper, we describe our approach to the Wikipedia Participation
Challenge which aims to predict the number of edits a Wikipedia editor will
make in the next 5 months. The best submission from our team, "zeditor",
achieved 41.7% improvement over WMF's baseline predictive model and the final
rank of 3rd place among 96 teams. An interesting characteristic of our approach
is that only temporal dynamics features (i.e., how the number of edits changes
in recent periods, etc.) are used in a self-supervised learning framework,
which makes it easy to be generalised to other application domains.

Deciding of HMM parameters based on number of critical points for
  gesture recognition from motion capture data
This paper presents a method of choosing number of states of a HMM based on
number of critical points of the motion capture data. The choice of Hidden
Markov Models(HMM) parameters is crucial for recognizer's performance as it is
the first step of the training and cannot be corrected automatically within
HMM. In this article we define predictor of number of states based on number of
critical points of the sequence and test its effectiveness against sample data.

PAC-Bayes-Bernstein Inequality for Martingales and its Application to
  Multiarmed Bandits
We develop a new tool for data-dependent analysis of the
exploration-exploitation trade-off in learning under limited feedback. Our tool
is based on two main ingredients. The first ingredient is a new concentration
inequality that makes it possible to control the concentration of weighted
averages of multiple (possibly uncountably many) simultaneously evolving and
interdependent martingales. The second ingredient is an application of this
inequality to the exploration-exploitation trade-off via importance weighted
sampling. We apply the new tool to the stochastic multiarmed bandit problem,
however, the main importance of this paper is the development and understanding
of the new tool rather than improvement of existing algorithms for stochastic
multiarmed bandits. In the follow-up work we demonstrate that the new tool can
improve over state-of-the-art in structurally richer problems, such as
stochastic multiarmed bandits with side information (Seldin et al., 2011a).

Confidence Estimation in Structured Prediction
Structured classification tasks such as sequence labeling and dependency
parsing have seen much interest by the Natural Language Processing and the
machine learning communities. Several online learning algorithms were adapted
for structured tasks such as Perceptron, Passive- Aggressive and the recently
introduced Confidence-Weighted learning . These online algorithms are easy to
implement, fast to train and yield state-of-the-art performance. However,
unlike probabilistic models like Hidden Markov Model and Conditional random
fields, these methods generate models that output merely a prediction with no
additional information regarding confidence in the correctness of the output.
In this work we fill the gap proposing few alternatives to compute the
confidence in the output of non-probabilistic algorithms.We show how to compute
confidence estimates in the prediction such that the confidence reflects the
probability that the word is labeled correctly. We then show how to use our
methods to detect mislabeled words, trade recall for precision and active
learning. We evaluate our methods on four noun-phrase chunking and named entity
recognition sequence labeling tasks, and on dependency parsing for 14
languages.

Robust Interactive Learning
In this paper we propose and study a generalization of the standard
active-learning model where a more general type of query, class conditional
query, is allowed. Such queries have been quite useful in applications, but
have been lacking theoretical understanding. In this work, we characterize the
power of such queries under two well-known noise models. We give nearly tight
upper and lower bounds on the number of queries needed to learn both for the
general agnostic setting and for the bounded noise model. We further show that
our methods can be made adaptive to the (unknown) noise rate, with only
negligible loss in query complexity.

Parametrized Stochastic Multi-armed Bandits with Binary Rewards
In this paper, we consider the problem of multi-armed bandits with a large,
possibly infinite number of correlated arms. We assume that the arms have
Bernoulli distributed rewards, independent across time, where the probabilities
of success are parametrized by known attribute vectors for each arm, as well as
an unknown preference vector, each of dimension $n$. For this model, we seek an
algorithm with a total regret that is sub-linear in time and independent of the
number of arms. We present such an algorithm, which we call the Two-Phase
Algorithm, and analyze its performance. We show upper bounds on the total
regret which applies uniformly in time, for both the finite and infinite arm
cases. The asymptotics of the finite arm bound show that for any $f \in
\omega(\log(T))$, the total regret can be made to be $O(n \cdot f(T))$. In the
infinite arm case, the total regret is $O(\sqrt{n^3 T})$.

Efficient Regression in Metric Spaces via Approximate Lipschitz
  Extension
We present a framework for performing efficient regression in general metric
spaces. Roughly speaking, our regressor predicts the value at a new point by
computing a Lipschitz extension --- the smoothest function consistent with the
observed data --- after performing structural risk minimization to avoid
overfitting. We obtain finite-sample risk bounds with minimal structural and
noise assumptions, and a natural speed-precision tradeoff. The offline
(learning) and online (prediction) stages can be solved by convex programming,
but this naive approach has runtime complexity $O(n^3)$, which is prohibitive
for large datasets. We design instead a regression algorithm whose speed and
generalization performance depend on the intrinsic dimension of the data, to
which the algorithm adapts. While our main innovation is algorithmic, the
statistical results may also be of independent interest.

Large Scale Spectral Clustering Using Approximate Commute Time Embedding
Spectral clustering is a novel clustering method which can detect complex
shapes of data clusters. However, it requires the eigen decomposition of the
graph Laplacian matrix, which is proportion to $O(n^3)$ and thus is not
suitable for large scale systems. Recently, many methods have been proposed to
accelerate the computational time of spectral clustering. These approximate
methods usually involve sampling techniques by which a lot information of the
original data may be lost. In this work, we propose a fast and accurate
spectral clustering approach using an approximate commute time embedding, which
is similar to the spectral embedding. The method does not require using any
sampling technique and computing any eigenvector at all. Instead it uses random
projection and a linear time solver to find the approximate embedding. The
experiments in several synthetic and real datasets show that the proposed
approach has better clustering quality and is faster than the state-of-the-art
approximate spectral clustering methods.

Trading Regret for Efficiency: Online Convex Optimization with Long Term
  Constraints
In this paper we propose a framework for solving constrained online convex
optimization problem. Our motivation stems from the observation that most
algorithms proposed for online convex optimization require a projection onto
the convex set $\mathcal{K}$ from which the decisions are made. While for
simple shapes (e.g. Euclidean ball) the projection is straightforward, for
arbitrary complex sets this is the main computational challenge and may be
inefficient in practice. In this paper, we consider an alternative online
convex optimization problem. Instead of requiring decisions belong to
$\mathcal{K}$ for all rounds, we only require that the constraints which define
the set $\mathcal{K}$ be satisfied in the long run. We show that our framework
can be utilized to solve a relaxed version of online learning with side
constraints addressed in \cite{DBLP:conf/colt/MannorT06} and
\cite{DBLP:conf/aaai/KvetonYTM08}. By turning the problem into an online
convex-concave optimization problem, we propose an efficient algorithm which
achieves $\tilde{\mathcal{O}}(\sqrt{T})$ regret bound and
$\tilde{\mathcal{O}}(T^{3/4})$ bound for the violation of constraints. Then we
modify the algorithm in order to guarantee that the constraints are satisfied
in the long run. This gain is achieved at the price of getting
$\tilde{\mathcal{O}}(T^{3/4})$ regret bound. Our second algorithm is based on
the Mirror Prox method \citep{nemirovski-2005-prox} to solve variational
inequalities which achieves $\tilde{\mathcal{\mathcal{O}}}(T^{2/3})$ bound for
both regret and the violation of constraints when the domain $\K$ can be
described by a finite number of linear constraints. Finally, we extend the
result to the setting where we only have partial access to the convex set
$\mathcal{K}$ and propose a multipoint bandit feedback algorithm with the same
bounds in expectation as our first algorithm.

Regret Bound by Variation for Online Convex Optimization
In citep{Hazan-2008-extract}, the authors showed that the regret of online
linear optimization can be bounded by the total variation of the cost vectors.
In this paper, we extend this result to general online convex optimization. We
first analyze the limitations of the algorithm in \citep{Hazan-2008-extract}
when applied it to online convex optimization. We then present two algorithms
for online convex optimization whose regrets are bounded by the variation of
cost functions. We finally consider the bandit setting, and present a
randomized algorithm for online bandit convex optimization with a
variation-based regret bound. We show that the regret bound for online bandit
convex optimization is optimal when the variation of cost functions is
independent of the number of trials.

Learning in embodied action-perception loops through exploration
Although exploratory behaviors are ubiquitous in the animal kingdom, their
computational underpinnings are still largely unknown. Behavioral Psychology
has identified learning as a primary drive underlying many exploratory
behaviors. Exploration is seen as a means for an animal to gather sensory data
useful for reducing its ignorance about the environment. While related problems
have been addressed in Data Mining and Reinforcement Learning, the
computational modeling of learning-driven exploration by embodied agents is
largely unrepresented.
  Here, we propose a computational theory for learning-driven exploration based
on the concept of missing information that allows an agent to identify
informative actions using Bayesian inference. We demonstrate that when
embodiment constraints are high, agents must actively coordinate their actions
to learn efficiently. Compared to earlier approaches, our exploration policy
yields more efficient learning across a range of worlds with diverse
structures. The improved learning in turn affords greater success in general
tasks including navigation and reward gathering. We conclude by discussing how
the proposed theory relates to previous information-theoretic objectives of
behavior, such as predictive information and the free energy principle, and how
it might contribute to a general theory of exploratory behavior.

An Identity for Kernel Ridge Regression
This paper derives an identity connecting the square loss of ridge regression
in on-line mode with the loss of the retrospectively best regressor. Some
corollaries about the properties of the cumulative loss of on-line ridge
regression are also obtained.

Bipartite ranking algorithm for classification and survival analysis
Unsupervised aggregation of independently built univariate predictors is
explored as an alternative regularization approach for noisy, sparse datasets.
Bipartite ranking algorithm Smooth Rank implementing this approach is
introduced. The advantages of this algorithm are demonstrated on two types of
problems. First, Smooth Rank is applied to two-class problems from bio-medical
field, where ranking is often preferable to classification. In comparison
against SVMs with radial and linear kernels, Smooth Rank had the best
performance on 8 out of 12 benchmark benchmarks. The second area of application
is survival analysis, which is reduced here to bipartite ranking in a way which
allows one to use commonly accepted measures of methods performance. In
comparison of Smooth Rank with Cox PH regression and CoxPath methods, Smooth
Rank proved to be the best on 9 out of 10 benchmark datasets.

Analysis and Extension of Arc-Cosine Kernels for Large Margin
  Classification
We investigate a recently proposed family of positive-definite kernels that
mimic the computation in large neural networks. We examine the properties of
these kernels using tools from differential geometry; specifically, we analyze
the geometry of surfaces in Hilbert space that are induced by these kernels.
When this geometry is described by a Riemannian manifold, we derive results for
the metric, curvature, and volume element. Interestingly, though, we find that
the simplest kernel in this family does not admit such an interpretation. We
explore two variations of these kernels that mimic computation in neural
networks with different activation functions. We experiment with these new
kernels on several data sets and highlight their general trends in performance
for classification.

Nonnegative Matrix Factorization for Semi-supervised Dimensionality
  Reduction
We show how to incorporate information from labeled examples into nonnegative
matrix factorization (NMF), a popular unsupervised learning algorithm for
dimensionality reduction. In addition to mapping the data into a space of lower
dimensionality, our approach aims to preserve the nonnegative components of the
data that are important for classification. We identify these components from
the support vectors of large-margin classifiers and derive iterative updates to
preserve them in a semi-supervised version of NMF. These updates have a simple
multiplicative form like their unsupervised counterparts; they are also
guaranteed at each iteration to decrease their loss function---a weighted sum
of I-divergences that captures the trade-off between unsupervised and
supervised learning. We evaluate these updates for dimensionality reduction
when they are used as a precursor to linear classification. In this role, we
find that they yield much better performance than their unsupervised
counterparts. We also find one unexpected benefit of the low dimensional
representations discovered by our approach: often they yield more accurate
classifiers than both ordinary and transductive SVMs trained in the original
input space.

Clustering and Latent Semantic Indexing Aspects of the Nonnegative
  Matrix Factorization
This paper provides a theoretical support for clustering aspect of the
nonnegative matrix factorization (NMF). By utilizing the Karush-Kuhn-Tucker
optimality conditions, we show that NMF objective is equivalent to graph
clustering objective, so clustering aspect of the NMF has a solid
justification. Different from previous approaches which usually discard the
nonnegativity constraints, our approach guarantees the stationary point being
used in deriving the equivalence is located on the feasible region in the
nonnegative orthant. Additionally, since clustering capability of a matrix
decomposition technique can sometimes imply its latent semantic indexing (LSI)
aspect, we will also evaluate LSI aspect of the NMF by showing its capability
in solving the synonymy and polysemy problems in synthetic datasets. And more
extensive evaluation will be conducted by comparing LSI performances of the NMF
and the singular value decomposition (SVD), the standard LSI method, using some
standard datasets.

Evaluation of Performance Measures for Classifiers Comparison
The selection of the best classification algorithm for a given dataset is a
very widespread problem, occuring each time one has to choose a classifier to
solve a real-world problem. It is also a complex task with many important
methodological decisions to make. Among those, one of the most crucial is the
choice of an appropriate measure in order to properly assess the classification
performance and rank the algorithms. In this article, we focus on this specific
task. We present the most popular measures and compare their behavior through
discrimination plots. We then discuss their properties from a more theoretical
perspective. It turns out several of them are equivalent for classifiers
comparison purposes. Futhermore. they can also lead to interpretation problems.
Among the numerous measures proposed over the years, it appears that the
classical overall success rate and marginal rates are the more suitable for
classifier comparison task.

Modeling transition dynamics in MDPs with RKHS embeddings of conditional
  distributions
We propose a new, nonparametric approach to estimating the value function in
reinforcement learning. This approach makes use of a recently developed
representation of conditional distributions as functions in a reproducing
kernel Hilbert space. Such representations bypass the need for estimating
transition probabilities, and apply to any domain on which kernels can be
defined. Our approach avoids the need to approximate intractable integrals
since expectations are represented as RKHS inner products whose computation has
linear complexity in the sample size. Thus, we can efficiently perform value
function estimation in a wide variety of settings, including finite state
spaces, continuous states spaces, and partially observable tasks where only
sensor measurements are available. A second advantage of the approach is that
we learn the conditional distribution representation from a training sample,
and do not require an exhaustive exploration of the state space. We prove
convergence of our approach either to the optimal policy, or to the closest
projection of the optimal policy in our model class, under reasonable
assumptions. In experiments, we demonstrate the performance of our algorithm on
a learning task in a continuous state space (the under-actuated pendulum), and
on a navigation problem where only images from a sensor are observed. We
compare with least-squares policy iteration where a Gaussian process is used
for value function estimation. Our algorithm achieves better performance in
both tasks.

Combining One-Class Classifiers via Meta-Learning
Selecting the best classifier among the available ones is a difficult task,
especially when only instances of one class exist. In this work we examine the
notion of combining one-class classifiers as an alternative for selecting the
best classifier. In particular, we propose two new one-class classification
performance measures to weigh classifiers and show that a simple ensemble that
implements these measures can outperform the most popular one-class ensembles.
Furthermore, we propose a new one-class ensemble scheme, TUPSO, which uses
meta-learning to combine one-class classifiers. Our experiments demonstrate the
superiority of TUPSO over all other tested ensembles and show that the TUPSO
performance is statistically indistinguishable from that of the hypothetical
best classifier.

Building high-level features using large scale unsupervised learning
We consider the problem of building high-level, class-specific feature
detectors from only unlabeled data. For example, is it possible to learn a face
detector using only unlabeled images? To answer this, we train a 9-layered
locally connected sparse autoencoder with pooling and local contrast
normalization on a large dataset of images (the model has 1 billion
connections, the dataset has 10 million 200x200 pixel images downloaded from
the Internet). We train this network using model parallelism and asynchronous
SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to
what appears to be a widely-held intuition, our experimental results reveal
that it is possible to train a face detector without having to label images as
containing a face or not. Control experiments show that this feature detector
is robust not only to translation but also to scaling and out-of-plane
rotation. We also find that the same network is sensitive to other high-level
concepts such as cat faces and human bodies. Starting with these learned
features, we trained our network to obtain 15.8% accuracy in recognizing 20,000
object categories from ImageNet, a leap of 70% relative improvement over the
previous state-of-the-art.

Two-Manifold Problems
Recently, there has been much interest in spectral approaches to learning
manifolds---so-called kernel eigenmap methods. These methods have had some
successes, but their applicability is limited because they are not robust to
noise. To address this limitation, we look at two-manifold problems, in which
we simultaneously reconstruct two related manifolds, each representing a
different view of the same data. By solving these interconnected learning
problems together and allowing information to flow between them, two-manifold
algorithms are able to succeed where a non-integrated approach would fail: each
view allows us to suppress noise in the other, reducing bias in the same way
that an instrumental variable allows us to remove bias in a {linear}
dimensionality reduction problem. We propose a class of algorithms for
two-manifold problems, based on spectral decomposition of cross-covariance
operators in Hilbert space. Finally, we discuss situations where two-manifold
problems are useful, and demonstrate that solving a two-manifold problem can
aid in learning a nonlinear dynamical system from limited data.

T-Learning
Traditional Reinforcement Learning (RL) has focused on problems involving
many states and few actions, such as simple grid worlds. Most real world
problems, however, are of the opposite type, Involving Few relevant states and
many actions. For example, to return home from a conference, humans identify
only few subgoal states such as lobby, taxi, airport etc. Each valid behavior
connecting two such states can be viewed as an action, and there are trillions
of them. Assuming the subgoal identification problem is already solved, the
quality of any RL method---in real-world settings---depends less on how well it
scales with the number of states than on how well it scales with the number of
actions. This is where our new method T-Learning excels, by evaluating the
relatively few possible transits from one state to another in a
policy-independent way, rather than a huge number of state-action pairs, or
states in traditional policy-dependent ways. Illustrative experiments
demonstrate that performance improvements of T-Learning over Q-learning can be
arbitrarily large.

A Topic Modeling Toolbox Using Belief Propagation
Latent Dirichlet allocation (LDA) is an important hierarchical Bayesian model
for probabilistic topic modeling, which attracts worldwide interests and
touches on many important applications in text mining, computer vision and
computational biology. This paper introduces a topic modeling toolbox (TMBP)
based on the belief propagation (BP) algorithms. TMBP toolbox is implemented by
MEX C++/Matlab/Octave for either Windows 7 or Linux. Compared with existing
topic modeling packages, the novelty of this toolbox lies in the BP algorithms
for learning LDA-based topic models. The current version includes BP algorithms
for latent Dirichlet allocation (LDA), author-topic models (ATM), relational
topic models (RTM), and labeled LDA (LaLDA). This toolbox is an ongoing project
and more BP-based algorithms for various topic models will be added in the near
future. Interested users may also extend BP algorithms for learning more
complicated topic models. The source codes are freely available under the GNU
General Public Licence, Version 1.0 at https://mloss.org/software/view/399/.

Customers Behavior Modeling by Semi-Supervised Learning in Customer
  Relationship Management
Leveraging the power of increasing amounts of data to analyze customer base
for attracting and retaining the most valuable customers is a major problem
facing companies in this information age. Data mining technologies extract
hidden information and knowledge from large data stored in databases or data
warehouses, thereby supporting the corporate decision making process. CRM uses
data mining (one of the elements of CRM) techniques to interact with customers.
This study investigates the use of a technique, semi-supervised learning, for
the management and analysis of customer-related data warehouse and information.
The idea of semi-supervised learning is to learn not only from the labeled
training data, but to exploit also the structural information in additionally
available unlabeled data. The proposed semi-supervised method is a model by
means of a feed-forward neural network trained by a back propagation algorithm
(multi-layer perceptron) in order to predict the category of an unknown
customer (potential customers). In addition, this technique can be used with
Rapid Miner tools for both labeled and unlabeled data.

Automatic Detection of Diabetes Diagnosis using Feature Weighted Support
  Vector Machines based on Mutual Information and Modified Cuckoo Search
Diabetes is a major health problem in both developing and developed countries
and its incidence is rising dramatically. In this study, we investigate a novel
automatic approach to diagnose Diabetes disease based on Feature Weighted
Support Vector Machines (FW-SVMs) and Modified Cuckoo Search (MCS). The
proposed model consists of three stages: Firstly, PCA is applied to select an
optimal subset of features out of set of all the features. Secondly, Mutual
Information is employed to construct the FWSVM by weighting different features
based on their degree of importance. Finally, since parameter selection plays a
vital role in classification accuracy of SVMs, MCS is applied to select the
best parameter values. The proposed MI-MCS-FWSVM method obtains 93.58% accuracy
on UCI dataset. The experimental results demonstrate that our method
outperforms the previous methods by not only giving more accurate results but
also significantly speeding up the classification procedure.

Stochastic Low-Rank Kernel Learning for Regression
We present a novel approach to learn a kernel-based regression function. It
is based on the useof conical combinations of data-based parameterized kernels
and on a new stochastic convex optimization procedure of which we establish
convergence guarantees. The overall learning procedure has the nice properties
that a) the learned conical combination is automatically designed to perform
the regression task at hand and b) the updates implicated by the optimization
procedure are quite inexpensive. In order to shed light on the appositeness of
our learning strategy, we present empirical results from experiments conducted
on various benchmark datasets.

Acoustical Quality Assessment of the Classroom Environment
Teaching is one of the most important factors affecting any education system.
Many research efforts have been conducted to facilitate the presentation modes
used by instructors in classrooms as well as provide means for students to
review lectures through web browsers. Other studies have been made to provide
acoustical design recommendations for classrooms like room size and
reverberation times. However, using acoustical features of classrooms as a way
to provide education systems with feedback about the learning process was not
thoroughly investigated in any of these studies. We propose a system that
extracts different sound features of students and instructors, and then uses
machine learning techniques to evaluate the acoustical quality of any learning
environment. We infer conclusions about the students' satisfaction with the
quality of lectures. Using classifiers instead of surveys and other subjective
ways of measures can facilitate and speed such experiments which enables us to
perform them continuously. We believe our system enables education systems to
continuously review and improve their teaching strategies and acoustical
quality of classrooms.

An Efficient Primal-Dual Prox Method for Non-Smooth Optimization
We study the non-smooth optimization problems in machine learning, where both
the loss function and the regularizer are non-smooth functions. Previous
studies on efficient empirical loss minimization assume either a smooth loss
function or a strongly convex regularizer, making them unsuitable for
non-smooth optimization. We develop a simple yet efficient method for a family
of non-smooth optimization problems where the dual form of the loss function is
bilinear in primal and dual variables. We cast a non-smooth optimization
problem into a minimax optimization problem, and develop a primal dual prox
method that solves the minimax optimization problem at a rate of $O(1/T)$
{assuming that the proximal step can be efficiently solved}, significantly
faster than a standard subgradient descent method that has an $O(1/\sqrt{T})$
convergence rate. Our empirical study verifies the efficiency of the proposed
method for various non-smooth optimization problems that arise ubiquitously in
machine learning by comparing it to the state-of-the-art first order methods.

A Comparison Between Data Mining Prediction Algorithms for Fault
  Detection(Case study: Ahanpishegan co.)
In the current competitive world, industrial companies seek to manufacture
products of higher quality which can be achieved by increasing reliability,
maintainability and thus the availability of products. On the other hand,
improvement in products lifecycle is necessary for achieving high reliability.
Typically, maintenance activities are aimed to reduce failures of industrial
machinery and minimize the consequences of such failures. So the industrial
companies try to improve their efficiency by using different fault detection
techniques. One strategy is to process and analyze previous generated data to
predict future failures. The purpose of this paper is to detect wasted parts
using different data mining algorithms and compare the accuracy of these
algorithms. A combination of thermal and physical characteristics has been used
and the algorithms were implemented on Ahanpishegan's current data to estimate
the availability of its produced parts.
  Keywords: Data Mining, Fault Detection, Availability, Prediction Algorithms.

Active Learning of Custering with Side Information Using $\eps$-Smooth
  Relative Regret Approximations
Clustering is considered a non-supervised learning setting, in which the goal
is to partition a collection of data points into disjoint clusters. Often a
bound $k$ on the number of clusters is given or assumed by the practitioner.
Many versions of this problem have been defined, most notably $k$-means and
$k$-median.
  An underlying problem with the unsupervised nature of clustering it that of
determining a similarity function. One approach for alleviating this difficulty
is known as clustering with side information, alternatively, semi-supervised
clustering. Here, the practitioner incorporates side information in the form of
"must be clustered" or "must be separated" labels for data point pairs. Each
such piece of information comes at a "query cost" (often involving human
response solicitation). The collection of labels is then incorporated in the
usual clustering algorithm as either strict or as soft constraints, possibly
adding a pairwise constraint penalty function to the chosen clustering
objective.
  Our work is mostly related to clustering with side information. We ask how to
choose the pairs of data points. Our analysis gives rise to a method provably
better than simply choosing them uniformly at random. Roughly speaking, we show
that the distribution must be biased so as more weight is placed on pairs
incident to elements in smaller clusters in some optimal solution. Of course we
do not know the optimal solution, hence we don't know the bias. Using the
recently introduced method of $\eps$-smooth relative regret approximations of
Ailon, Begleiter and Ezra, we can show an iterative process that improves both
the clustering and the bias in tandem. The process provably converges to the
optimal solution faster (in terms of query cost) than an algorithm selecting
pairs uniformly.

Contextual Bandit Learning with Predictable Rewards
Contextual bandit learning is a reinforcement learning problem where the
learner repeatedly receives a set of features (context), takes an action and
receives a reward based on the action and context. We consider this problem
under a realizability assumption: there exists a function in a (known) function
class, always capable of predicting the expected reward, given the action and
context. Under this assumption, we show three things. We present a new
algorithm---Regressor Elimination--- with a regret similar to the agnostic
setting (i.e. in the absence of realizability assumption). We prove a new lower
bound showing no algorithm can achieve superior performance in the worst case
even with the realizability assumption. However, we do show that for any set of
policies (mapping contexts to actions), there is a distribution over rewards
(given context) such that our new algorithm has constant regret unlike the
previous approaches.

On the Performance of Maximum Likelihood Inverse Reinforcement Learning
Inverse reinforcement learning (IRL) addresses the problem of recovering a
task description given a demonstration of the optimal policy used to solve such
a task. The optimal policy is usually provided by an expert or teacher, making
IRL specially suitable for the problem of apprenticeship learning. The task
description is encoded in the form of a reward function of a Markov decision
process (MDP). Several algorithms have been proposed to find the reward
function corresponding to a set of demonstrations. One of the algorithms that
has provided best results in different applications is a gradient method to
optimize a policy squared error criterion. On a parallel line of research,
other authors have presented recently a gradient approximation of the maximum
likelihood estimate of the reward signal. In general, both approaches
approximate the gradient estimate and the criteria at different stages to make
the algorithm tractable and efficient. In this work, we provide a detailed
description of the different methods to highlight differences in terms of
reward estimation, policy similarity and computational costs. We also provide
experimental results to evaluate the differences in performance of the methods.

PAC Bounds for Discounted MDPs
We study upper and lower bounds on the sample-complexity of learning
near-optimal behaviour in finite-state discounted Markov Decision Processes
(MDPs). For the upper bound we make the assumption that each action leads to at
most two possible next-states and prove a new bound for a UCRL-style algorithm
on the number of time-steps when it is not Probably Approximately Correct
(PAC). The new lower bound strengthens previous work by being both more general
(it applies to all policies) and tighter. The upper and lower bounds match up
to logarithmic factors.

Confusion Matrix Stability Bounds for Multiclass Classification
In this paper, we provide new theoretical results on the generalization
properties of learning algorithms for multiclass classification problems. The
originality of our work is that we propose to use the confusion matrix of a
classifier as a measure of its quality; our contribution is in the line of work
which attempts to set up and study the statistical properties of new evaluation
measures such as, e.g. ROC curves. In the confusion-based learning framework we
propose, we claim that a targetted objective is to minimize the size of the
confusion matrix C, measured through its operator norm ||C||. We derive
generalization bounds on the (size of the) confusion matrix in an extended
framework of uniform stability, adapted to the case of matrix valued loss.
Pivotal to our study is a very recent matrix concentration inequality that
generalizes McDiarmid's inequality. As an illustration of the relevance of our
theoretical results, we show how two SVM learning procedures can be proved to
be confusion-friendly. To the best of our knowledge, the present paper is the
first that focuses on the confusion matrix from a theoretical point of view.

Application of Gist SVM in Cancer Detection
In this paper, we study the application of GIST SVM in disease prediction
(detection of cancer). Pattern classification problems can be effectively
solved by Support vector machines. Here we propose a classifier which can
differentiate patients having benign and malignant cancer cells. To improve the
accuracy of classification, we propose to determine the optimal size of the
training set and perform feature selection. To find the optimal size of the
training set, different sizes of training sets are experimented and the one
with highest classification rate is selected. The optimal features are selected
through their F-Scores.

On the Necessity of Irrelevant Variables
This work explores the effects of relevant and irrelevant boolean variables
on the accuracy of classifiers. The analysis uses the assumption that the
variables are conditionally independent given the class, and focuses on a
natural family of learning algorithms for such sources when the relevant
variables have a small advantage over random guessing. The main result is that
algorithms relying predominately on irrelevant variables have error
probabilities that quickly go to 0 in situations where algorithms that limit
the use of irrelevant variables have errors bounded below by a positive
constant. We also show that accurate learning is possible even when there are
so few examples that one cannot determine with high confidence whether or not
any individual variable is relevant.

Data Mining: A Prediction for Performance Improvement of Engineering
  Students using Classification
Now-a-days the amount of data stored in educational database increasing
rapidly. These databases contain hidden information for improvement of
students' performance. Educational data mining is used to study the data
available in the educational field and bring out the hidden knowledge from it.
Classification methods like decision trees, Bayesian network etc can be applied
on the educational data for predicting the student's performance in
examination. This prediction will help to identify the weak students and help
them to score better marks. The C4.5, ID3 and CART decision tree algorithms are
applied on engineering student's data to predict their performance in the final
exam. The outcome of the decision tree predicted the number of students who are
likely to pass, fail or promoted to next year. The results provide steps to
improve the performance of the students who were predicted to fail or promoted.
After the declaration of the results in the final examination the marks
obtained by the students are fed into the system and the results were analyzed
for the next session. The comparative analysis of the results states that the
prediction has helped the weaker students to improve and brought out betterment
in the result.

Adaptive Mixture Methods Based on Bregman Divergences
We investigate adaptive mixture methods that linearly combine outputs of $m$
constituent filters running in parallel to model a desired signal. We use
"Bregman divergences" and obtain certain multiplicative updates to train the
linear combination weights under an affine constraint or without any
constraints. We use unnormalized relative entropy and relative entropy to
define two different Bregman divergences that produce an unnormalized
exponentiated gradient update and a normalized exponentiated gradient update on
the mixture weights, respectively. We then carry out the mean and the
mean-square transient analysis of these adaptive algorithms when they are used
to combine outputs of $m$ constituent filters. We illustrate the accuracy of
our results and demonstrate the effectiveness of these updates for sparse
mixture systems.

Very Short Literature Survey From Supervised Learning To Surrogate
  Modeling
The past century was era of linear systems. Either systems (especially
industrial ones) were simple (quasi)linear or linear approximations were
accurate enough. In addition, just at the ending decades of the century
profusion of computing devices were available, before then due to lack of
computational resources it was not easy to evaluate available nonlinear system
studies. At the moment both these two conditions changed, systems are highly
complex and also pervasive amount of computation strength is cheap and easy to
achieve. For recent era, a new branch of supervised learning well known as
surrogate modeling (meta-modeling, surface modeling) has been devised which
aimed at answering new needs of modeling realm. This short literature survey is
on to introduce surrogate modeling to whom is familiar with the concepts of
supervised learning. Necessity, challenges and visions of the topic are
considered.

Credal Classification based on AODE and compression coefficients
Bayesian model averaging (BMA) is an approach to average over alternative
models; yet, it usually gets excessively concentrated around the single most
probable model, therefore achieving only sub-optimal classification
performance. The compression-based approach (Boulle, 2007) overcomes this
problem, averaging over the different models by applying a logarithmic
smoothing over the models' posterior probabilities. This approach has shown
excellent performances when applied to ensembles of naive Bayes classifiers.
AODE is another ensemble of models with high performance (Webb, 2005), based on
a collection of non-naive classifiers (called SPODE) whose probabilistic
predictions are aggregated by simple arithmetic mean. Aggregating the SPODEs
via BMA rather than by arithmetic mean deteriorates the performance; instead,
we aggregate the SPODEs via the compression coefficients and we show that the
resulting classifier obtains a slight but consistent improvement over AODE.
However, an important issue in any Bayesian ensemble of models is the
arbitrariness in the choice of the prior over the models. We address this
problem by the paradigm of credal classification, namely by substituting the
unique prior with a set of priors. Credal classifier automatically recognize
the prior-dependent instances, namely the instances whose most probable class
varies, when different priors are considered; in these cases, credal
classifiers remain reliable by returning a set of classes rather than a single
class. We thus develop the credal version of both the BMA-based and the
compression-based ensemble of SPODEs, substituting the single prior over the
models by a set of priors. Experiments show that both credal classifiers
provide higher classification reliability than their determinate counterparts;
moreover the compression-based credal classifier compares favorably to previous
credal classifiers.

The Kernelized Stochastic Batch Perceptron
We present a novel approach for training kernel Support Vector Machines,
establish learning runtime guarantees for our method that are better then those
of any other known kernelized SVM optimization approach, and show that our
method works well in practice compared to existing alternatives.

Stochastic Feature Mapping for PAC-Bayes Classification
Probabilistic generative modeling of data distributions can potentially
exploit hidden information which is useful for discriminative classification.
This observation has motivated the development of approaches that couple
generative and discriminative models for classification. In this paper, we
propose a new approach to couple generative and discriminative models in an
unified framework based on PAC-Bayes risk theory. We first derive the
model-parameter-independent stochastic feature mapping from a practical MAP
classifier operating on generative models. Then we construct a linear
stochastic classifier equipped with the feature mapping, and derive the
explicit PAC-Bayes risk bounds for such classifier for both supervised and
semi-supervised learning. Minimizing the risk bound, using an EM-like iterative
procedure, results in a new posterior over hidden variables (E-step) and the
update rules of model parameters (M-step). The derivation of the posterior is
always feasible due to the way of equipping feature mapping and the explicit
form of bounding risk. The derived posterior allows the tuning of generative
models and subsequently the feature mappings for better classification. The
derived update rules of the model parameters are same to those of the uncoupled
models as the feature mapping is model-parameter-independent. Our experiments
show that the coupling between data modeling generative model and the
discriminative classifier via a stochastic feature mapping in this framework
leads to a general classification tool with state-of-the-art performance.

Supervised feature evaluation by consistency analysis: application to
  measure sets used to characterise geographic objects
Nowadays, supervised learning is commonly used in many domains. Indeed, many
works propose to learn new knowledge from examples that translate the expected
behaviour of the considered system. A key issue of supervised learning concerns
the description language used to represent the examples. In this paper, we
propose a method to evaluate the feature set used to describe them. Our method
is based on the computation of the consistency of the example base. We carried
out a case study in the domain of geomatic in order to evaluate the sets of
measures used to characterise geographic objects. The case study shows that our
method allows to give relevant evaluations of measure sets.

Minimax Classifier for Uncertain Costs
Many studies on the cost-sensitive learning assumed that a unique cost matrix
is known for a problem. However, this assumption may not hold for many
real-world problems. For example, a classifier might need to be applied in
several circumstances, each of which associates with a different cost matrix.
Or, different human experts have different opinions about the costs for a given
problem. Motivated by these facts, this study aims to seek the minimax
classifier over multiple cost matrices. In summary, we theoretically proved
that, no matter how many cost matrices are involved, the minimax problem can be
tackled by solving a number of standard cost-sensitive problems and
sub-problems that involve only two cost matrices. As a result, a general
framework for achieving minimax classifier over multiple cost matrices is
suggested and justified by preliminary empirical studies.

Greedy Multiple Instance Learning via Codebook Learning and Nearest
  Neighbor Voting
Multiple instance learning (MIL) has attracted great attention recently in
machine learning community. However, most MIL algorithms are very slow and
cannot be applied to large datasets. In this paper, we propose a greedy
strategy to speed up the multiple instance learning process. Our contribution
is two fold. First, we propose a density ratio model, and show that maximizing
a density ratio function is the low bound of the DD model under certain
conditions. Secondly, we make use of a histogram ratio between positive bags
and negative bags to represent the density ratio function and find codebooks
separately for positive bags and negative bags by a greedy strategy. For
testing, we make use of a nearest neighbor strategy to classify new bags. We
test our method on both small benchmark datasets and the large TRECVID MED11
dataset. The experimental results show that our method yields comparable
accuracy to the current state of the art, while being up to at least one order
of magnitude faster.

A Converged Algorithm for Tikhonov Regularized Nonnegative Matrix
  Factorization with Automatic Regularization Parameters Determination
We present a converged algorithm for Tikhonov regularized nonnegative matrix
factorization (NMF). We specially choose this regularization because it is
known that Tikhonov regularized least square (LS) is the more preferable form
in solving linear inverse problems than the conventional LS. Because an NMF
problem can be decomposed into LS subproblems, it can be expected that Tikhonov
regularized NMF will be the more appropriate approach in solving NMF problems.
The algorithm is derived using additive update rules which have been shown to
have convergence guarantee. We equip the algorithm with a mechanism to
automatically determine the regularization parameters based on the L-curve, a
well-known concept in the inverse problems community, but is rather unknown in
the NMF research. The introduction of this algorithm thus solves two inherent
problems in Tikhonov regularized NMF algorithm research, i.e., convergence
guarantee and regularization parameters determination.

Efficient Constrained Regret Minimization
Online learning constitutes a mathematical and compelling framework to
analyze sequential decision making problems in adversarial environments. The
learner repeatedly chooses an action, the environment responds with an outcome,
and then the learner receives a reward for the played action. The goal of the
learner is to maximize his total reward. However, there are situations in
which, in addition to maximizing the cumulative reward, there are some
additional constraints on the sequence of decisions that must be satisfied on
average by the learner. In this paper we study an extension to the online
learning where the learner aims to maximize the total reward given that some
additional constraints need to be satisfied. By leveraging on the theory of
Lagrangian method in constrained optimization, we propose Lagrangian
exponentially weighted average (LEWA) algorithm, which is a primal-dual variant
of the well known exponentially weighted average algorithm, to efficiently
solve constrained online decision making problems. Using novel theoretical
analysis, we establish the regret and the violation of the constraint bounds in
full information and bandit feedback models.

A Uniqueness Theorem for Clustering
Despite the widespread use of Clustering, there is distressingly little
general theory of clustering available. Questions like "What distinguishes a
clustering of data from other data partitioning?", "Are there any principles
governing all clustering paradigms?", "How should a user choose an appropriate
clustering algorithm for a particular task?", etc. are almost completely
unanswered by the existing body of clustering literature. We consider an
axiomatic approach to the theory of Clustering. We adopt the framework of
Kleinberg, [Kle03]. By relaxing one of Kleinberg's clustering axioms, we
sidestep his impossibility result and arrive at a consistent set of axioms. We
suggest to extend these axioms, aiming to provide an axiomatic taxonomy of
clustering paradigms. Such a taxonomy should provide users some guidance
concerning the choice of the appropriate clustering paradigm for a given task.
The main result of this paper is a set of abstract properties that characterize
the Single-Linkage clustering function. This characterization result provides
new insight into the properties of desired data groupings that make
Single-Linkage the appropriate choice. We conclude by considering a taxonomy of
clustering functions based on abstract properties that each satisfies.

The Entire Quantile Path of a Risk-Agnostic SVM Classifier
A quantile binary classifier uses the rule: Classify x as +1 if P(Y = 1|X =
x) >= t, and as -1 otherwise, for a fixed quantile parameter t {[0, 1]. It has
been shown that Support Vector Machines (SVMs) in the limit are quantile
classifiers with t = 1/2 . In this paper, we show that by using asymmetric cost
of misclassification SVMs can be appropriately extended to recover, in the
limit, the quantile binary classifier for any t. We then present a principled
algorithm to solve the extended SVM classifier for all values of t
simultaneously. This has two implications: First, one can recover the entire
conditional distribution P(Y = 1|X = x) = t for t {[0, 1]. Second, we can build
a risk-agnostic SVM classifier where the cost of misclassification need not be
known apriori. Preliminary numerical experiments show the effectiveness of the
proposed algorithm.

Probabilistic Structured Predictors
We consider MAP estimators for structured prediction with exponential family
models. In particular, we concentrate on the case that efficient algorithms for
uniform sampling from the output space exist. We show that under this
assumption (i) exact computation of the partition function remains a hard
problem, and (ii) the partition function and the gradient of the log partition
function can be approximated efficiently. Our main result is an approximation
scheme for the partition function based on Markov Chain Monte Carlo theory. We
also show that the efficient uniform sampling assumption holds in several
application settings that are of importance in machine learning.

REGAL: A Regularization based Algorithm for Reinforcement Learning in
  Weakly Communicating MDPs
We provide an algorithm that achieves the optimal regret rate in an unknown
weakly communicating Markov Decision Process (MDP). The algorithm proceeds in
episodes where, in each episode, it picks a policy using regularization based
on the span of the optimal bias vector. For an MDP with S states and A actions
whose optimal bias vector has span bounded by H, we show a regret bound of
~O(HSpAT). We also relate the span to various diameter-like quantities
associated with the MDP, demonstrating how our results improve on previous
regret bounds.

A Bayesian Sampling Approach to Exploration in Reinforcement Learning
We present a modular approach to reinforcement learning that uses a Bayesian
representation of the uncertainty over models. The approach, BOSS (Best of
Sampled Set), drives exploration by sampling multiple models from the posterior
and selecting actions optimistically. It extends previous work by providing a
rule for deciding when to resample and how to combine the models. We show that
our algorithm achieves nearoptimal reward with high probability with a sample
complexity that is low relative to the speed at which the posterior
distribution converges during learning. We demonstrate that BOSS performs quite
favorably compared to state-of-the-art reinforcement-learning approaches and
illustrate its flexibility by pairing it with a non-parametric model that
generalizes across states.

Decoupling Exploration and Exploitation in Multi-Armed Bandits
We consider a multi-armed bandit problem where the decision maker can explore
and exploit different arms at every round. The exploited arm adds to the
decision maker's cumulative reward (without necessarily observing the reward)
while the explored arm reveals its value. We devise algorithms for this setup
and show that the dependence on the number of arms, k, can be much better than
the standard square root of k dependence, depending on the behavior of the
arms' reward sequences. For the important case of piecewise stationary
stochastic bandits, we show a significant improvement over existing algorithms.
Our algorithms are based on a non-uniform sampling policy, which we show is
essential to the success of any algorithm in the adversarial setup. Finally, we
show some simulation results on an ultra-wide band channel selection inspired
setting indicating the applicability of our algorithms.

Normalized Maximum Likelihood Coding for Exponential Family with Its
  Applications to Optimal Clustering
We are concerned with the issue of how to calculate the normalized maximum
likelihood (NML) code-length. There is a problem that the normalization term of
the NML code-length may diverge when it is continuous and unbounded and a
straightforward computation of it is highly expensive when the data domain is
finite . In previous works it has been investigated how to calculate the NML
code-length for specific types of distributions. We first propose a general
method for computing the NML code-length for the exponential family. Then we
specifically focus on Gaussian mixture model (GMM), and propose a new efficient
method for computing the NML to them. We develop it by generalizing Rissanen's
re-normalizing technique. Then we apply this method to the clustering issue, in
which a clustering structure is modeled using a GMM, and the main task is to
estimate the optimal number of clusters on the basis of the NML code-length. We
demonstrate using artificial data sets the superiority of the NML-based
clustering over other criteria such as AIC, BIC in terms of the data size
required for high accuracy rate to be achieved.

Visualization of features of a series of measurements with
  one-dimensional cellular structure
This paper describes the method of visualization of periodic constituents and
instability areas in series of measurements, being based on the algorithm of
smoothing out and concept of one-dimensional cellular automata. A method can be
used at the analysis of temporal series, related to the volumes of thematic
publications in web-space.

The Role of Weight Shrinking in Large Margin Perceptron Learning
We introduce into the classical perceptron algorithm with margin a mechanism
that shrinks the current weight vector as a first step of the update. If the
shrinking factor is constant the resulting algorithm may be regarded as a
margin-error-driven version of NORMA with constant learning rate. In this case
we show that the allowed strength of shrinking depends on the value of the
maximum margin. We also consider variable shrinking factors for which there is
no such dependence. In both cases we obtain new generalizations of the
perceptron with margin able to provably attain in a finite number of steps any
desirable approximation of the maximal margin hyperplane. The new approximate
maximum margin classifiers appear experimentally to be very competitive in
2-norm soft margin tasks involving linear kernels.

Safe Exploration in Markov Decision Processes
In environments with uncertain dynamics exploration is necessary to learn how
to perform well. Existing reinforcement learning algorithms provide strong
exploration guarantees, but they tend to rely on an ergodicity assumption. The
essence of ergodicity is that any state is eventually reachable from any other
state by following a suitable policy. This assumption allows for exploration
algorithms that operate by simply favoring states that have rarely been visited
before. For most physical systems this assumption is impractical as the systems
would break before any reasonable exploration has taken place, i.e., most
physical systems don't satisfy the ergodicity assumption. In this paper we
address the need for safe exploration methods in Markov decision processes. We
first propose a general formulation of safety through ergodicity. We show that
imposing safety by restricting attention to the resulting set of guaranteed
safe policies is NP-hard. We then present an efficient algorithm for guaranteed
safe, but potentially suboptimal, exploration. At the core is an optimization
formulation in which the constraints restrict attention to a subset of the
guaranteed safe policies and the objective favors exploration policies. Our
framework is compatible with the majority of previously proposed exploration
methods, which rely on an exploration bonus. Our experiments, which include a
Martian terrain exploration problem, show that our method is able to explore
better than classical exploration methods.

Off-Policy Actor-Critic
This paper presents the first actor-critic algorithm for off-policy
reinforcement learning. Our algorithm is online and incremental, and its
per-time-step complexity scales linearly with the number of learned weights.
Previous work on actor-critic algorithms is limited to the on-policy setting
and does not take advantage of the recent advances in off-policy gradient
temporal-difference learning. Off-policy techniques, such as Greedy-GQ, enable
a target policy to be learned while following and obtaining data from another
(behavior) policy. For many problems, however, actor-critic methods are more
practical than action value methods (like Greedy-GQ) because they explicitly
represent the policy; consequently, the policy can be stochastic and utilize a
large action space. In this paper, we illustrate how to practically combine the
generality and learning potential of off-policy learning with the flexibility
in action selection given by actor-critic methods. We derive an incremental,
linear time and space complexity algorithm that includes eligibility traces,
prove convergence under assumptions similar to previous off-policy algorithms,
and empirically show better or comparable performance to existing algorithms on
standard reinforcement-learning benchmark problems.

Multiclass Learning Approaches: A Theoretical Comparison with
  Implications
We theoretically analyze and compare the following five popular multiclass
classification methods: One vs. All, All Pairs, Tree-based classifiers, Error
Correcting Output Codes (ECOC) with randomly generated code matrices, and
Multiclass SVM. In the first four methods, the classification is based on a
reduction to binary classification. We consider the case where the binary
classifier comes from a class of VC dimension $d$, and in particular from the
class of halfspaces over $\reals^d$. We analyze both the estimation error and
the approximation error of these methods. Our analysis reveals interesting
conclusions of practical relevance, regarding the success of the different
approaches under various conditions. Our proof technique employs tools from VC
theory to analyze the \emph{approximation error} of hypothesis classes. This is
in sharp contrast to most, if not all, previous uses of VC theory, which only
deal with estimation error.

An Optimization Framework for Semi-Supervised and Transfer Learning
  using Multiple Classifiers and Clusterers
Unsupervised models can provide supplementary soft constraints to help
classify new, "target" data since similar instances in the target set are more
likely to share the same class label. Such models can also help detect possible
differences between training and target distributions, which is useful in
applications where concept drift may take place, as in transfer learning
settings. This paper describes a general optimization framework that takes as
input class membership estimates from existing classifiers learnt on previously
encountered "source" data, as well as a similarity matrix from a cluster
ensemble operating solely on the target data to be classified, and yields a
consensus labeling of the target data. This framework admits a wide range of
loss functions and classification/clustering methods. It exploits properties of
Bregman divergences in conjunction with Legendre duality to yield a principled
and scalable approach. A variety of experiments show that the proposed
framework can yield results substantially superior to those provided by popular
transductive learning techniques or by naively applying classifiers learnt on
the original task to the target data.

Comparison of the C4.5 and a Naive Bayes Classifier for the Prediction
  of Lung Cancer Survivability
Numerous data mining techniques have been developed to extract information
and identify patterns and predict trends from large data sets. In this study,
two classification techniques, the J48 implementation of the C4.5 algorithm and
a Naive Bayes classifier are applied to predict lung cancer survivability from
an extensive data set with fifteen years of patient records. The purpose of the
project is to verify the predictive effectiveness of the two techniques on
real, historical data. Besides the performance outcome that renders J48
marginally better than the Naive Bayes technique, there is a detailed
description of the data and the required pre-processing activities. The
performance results confirm expectations while some of the issues that appeared
during experimentation, underscore the value of having domain-specific
understanding to leverage any domain-specific characteristics inherent in the
data.

Cumulative Step-size Adaptation on Linear Functions: Technical Report
The CSA-ES is an Evolution Strategy with Cumulative Step size Adaptation,
where the step size is adapted measuring the length of a so-called cumulative
path. The cumulative path is a combination of the previous steps realized by
the algorithm, where the importance of each step decreases with time. This
article studies the CSA-ES on composites of strictly increasing with affine
linear functions through the investigation of its underlying Markov chains.
Rigorous results on the change and the variation of the step size are derived
with and without cumulation. The step-size diverges geometrically fast in most
cases. Furthermore, the influence of the cumulation parameter is studied.

Communication-Efficient Parallel Belief Propagation for Latent Dirichlet
  Allocation
This paper presents a novel communication-efficient parallel belief
propagation (CE-PBP) algorithm for training latent Dirichlet allocation (LDA).
Based on the synchronous belief propagation (BP) algorithm, we first develop a
parallel belief propagation (PBP) algorithm on the parallel architecture.
Because the extensive communication delay often causes a low efficiency of
parallel topic modeling, we further use Zipf's law to reduce the total
communication cost in PBP. Extensive experiments on different data sets
demonstrate that CE-PBP achieves a higher topic modeling accuracy and reduces
more than 80% communication cost than the state-of-the-art parallel Gibbs
sampling (PGS) algorithm.

Clustered Bandits
We consider a multi-armed bandit setting that is inspired by real-world
applications in e-commerce. In our setting, there are a few types of users,
each with a specific response to the different arms. When a user enters the
system, his type is unknown to the decision maker. The decision maker can
either treat each user separately ignoring the previously observed users, or
can attempt to take advantage of knowing that only few types exist and cluster
the users according to their response to the arms. We devise algorithms that
combine the usual exploration-exploitation tradeoff with clustering of users
and demonstrate the value of clustering. In the process of developing
algorithms for the clustered setting, we propose and analyze simple algorithms
for the setup where a decision maker knows that a user belongs to one of few
types, but does not know which one.

Exact Soft Confidence-Weighted Learning
In this paper, we propose a new Soft Confidence-Weighted (SCW) online
learning scheme, which enables the conventional confidence-weighted learning
method to handle non-separable cases. Unlike the previous confidence-weighted
learning algorithms, the proposed soft confidence-weighted learning method
enjoys all the four salient properties: (i) large margin training, (ii)
confidence weighting, (iii) capability to handle non-separable data, and (iv)
adaptive margin. Our experimental results show that the proposed SCW algorithms
significantly outperform the original CW algorithm. When comparing with a
variety of state-of-the-art algorithms (including AROW, NAROW and NHERD), we
found that SCW generally achieves better or at least comparable predictive
accuracy, but enjoys significant advantage of computational efficiency (i.e.,
smaller number of updates and lower time cost).

Inductive Kernel Low-rank Decomposition with Priors: A Generalized
  Nystrom Method
Low-rank matrix decomposition has gained great popularity recently in scaling
up kernel methods to large amounts of data. However, some limitations could
prevent them from working effectively in certain domains. For example, many
existing approaches are intrinsically unsupervised, which does not incorporate
side information (e.g., class labels) to produce task specific decompositions;
also, they typically work "transductively", i.e., the factorization does not
generalize to new samples, so the complete factorization needs to be recomputed
when new samples become available. To solve these problems, in this paper we
propose an"inductive"-flavored method for low-rank kernel decomposition with
priors. We achieve this by generalizing the Nystr\"om method in a novel way. On
the one hand, our approach employs a highly flexible, nonparametric structure
that allows us to generalize the low-rank factors to arbitrarily new samples;
on the other hand, it has linear time and space complexities, which can be
orders of magnitudes faster than existing approaches and renders great
efficiency in learning a low-rank kernel decomposition. Empirical results
demonstrate the efficacy and efficiency of the proposed method.

Path Integral Policy Improvement with Covariance Matrix Adaptation
There has been a recent focus in reinforcement learning on addressing
continuous state and action problems by optimizing parameterized policies. PI2
is a recent example of this approach. It combines a derivation from first
principles of stochastic optimal control with tools from statistical estimation
theory. In this paper, we consider PI2 as a member of the wider family of
methods which share the concept of probability-weighted averaging to
iteratively update parameters to optimize a cost function. We compare PI2 to
other members of the same family - Cross-Entropy Methods and CMAES - at the
conceptual level and in terms of performance. The comparison suggests the
derivation of a novel algorithm which we call PI2-CMA for "Path Integral Policy
Improvement with Covariance Matrix Adaptation". PI2-CMA's main advantage is
that it determines the magnitude of the exploration noise automatically.

Optimizing F-measure: A Tale of Two Approaches
F-measures are popular performance metrics, particularly for tasks with
imbalanced data sets. Algorithms for learning to maximize F-measures follow two
approaches: the empirical utility maximization (EUM) approach learns a
classifier having optimal performance on training data, while the
decision-theoretic approach learns a probabilistic model and then predicts
labels with maximum expected F-measure. In this paper, we investigate the
theoretical justifications and connections for these two approaches, and we
study the conditions under which one approach is preferable to the other using
synthetic and real datasets. Given accurate models, our results suggest that
the two approaches are asymptotically equivalent given large training and test
sets. Nevertheless, empirically, the EUM approach appears to be more robust
against model misspecification, and given a good model, the decision-theoretic
approach appears to be better for handling rare classes and a common domain
adaptation scenario.

Multiple Kernel Learning from Noisy Labels by Stochastic Programming
We study the problem of multiple kernel learning from noisy labels. This is
in contrast to most of the previous studies on multiple kernel learning that
mainly focus on developing efficient algorithms and assume perfectly labeled
training examples. Directly applying the existing multiple kernel learning
algorithms to noisily labeled examples often leads to suboptimal performance
due to the incorrect class assignments. We address this challenge by casting
multiple kernel learning from noisy labels into a stochastic programming
problem, and presenting a minimax formulation. We develop an efficient
algorithm for solving the related convex-concave optimization problem with a
fast convergence rate of $O(1/T)$ where $T$ is the number of iterations.
Empirical studies on UCI data sets verify both the effectiveness of the
proposed framework and the efficiency of the proposed optimization algorithm.

Efficient Decomposed Learning for Structured Prediction
Structured prediction is the cornerstone of several machine learning
applications. Unfortunately, in structured prediction settings with expressive
inter-variable interactions, exact inference-based learning algorithms, e.g.
Structural SVM, are often intractable. We present a new way, Decomposed
Learning (DecL), which performs efficient learning by restricting the inference
step to a limited part of the structured spaces. We provide characterizations
based on the structure, target parameters, and gold labels, under which DecL is
equivalent to exact learning. We then show that in real world settings, where
our theoretical assumptions may not completely hold, DecL-based algorithms are
significantly more efficient and as accurate as exact learning.

Two-Manifold Problems with Applications to Nonlinear System
  Identification
Recently, there has been much interest in spectral approaches to learning
manifolds---so-called kernel eigenmap methods. These methods have had some
successes, but their applicability is limited because they are not robust to
noise. To address this limitation, we look at two-manifold problems, in which
we simultaneously reconstruct two related manifolds, each representing a
different view of the same data. By solving these interconnected learning
problems together, two-manifold algorithms are able to succeed where a
non-integrated approach would fail: each view allows us to suppress noise in
the other, reducing bias. We propose a class of algorithms for two-manifold
problems, based on spectral decomposition of cross-covariance operators in
Hilbert space, and discuss when two-manifold problems are useful. Finally, we
demonstrate that solving a two-manifold problem can aid in learning a nonlinear
dynamical system from limited data.

Modelling transition dynamics in MDPs with RKHS embeddings
We propose a new, nonparametric approach to learning and representing
transition dynamics in Markov decision processes (MDPs), which can be combined
easily with dynamic programming methods for policy optimisation and value
estimation. This approach makes use of a recently developed representation of
conditional distributions as \emph{embeddings} in a reproducing kernel Hilbert
space (RKHS). Such representations bypass the need for estimating transition
probabilities or densities, and apply to any domain on which kernels can be
defined. This avoids the need to calculate intractable integrals, since
expectations are represented as RKHS inner products whose computation has
linear complexity in the number of points used to represent the embedding. We
provide guarantees for the proposed applications in MDPs: in the context of a
value iteration algorithm, we prove convergence to either the optimal policy,
or to the closest projection of the optimal policy in our model class (an
RKHS), under reasonable assumptions. In experiments, we investigate a learning
task in a typical classical control setting (the under-actuated pendulum), and
on a navigation problem where only images from a sensor are observed. For
policy optimisation we compare with least-squares policy iteration where a
Gaussian process is used for value function estimation. For value estimation we
also compare to the NPDP method. Our approach achieves better performance in
all experiments.

Learning with Augmented Features for Heterogeneous Domain Adaptation
We propose a new learning method for heterogeneous domain adaptation (HDA),
in which the data from the source domain and the target domain are represented
by heterogeneous features with different dimensions. Using two different
projection matrices, we first transform the data from two domains into a common
subspace in order to measure the similarity between the data from two domains.
We then propose two new feature mapping functions to augment the transformed
data with their original features and zeros. The existing learning methods
(e.g., SVM and SVR) can be readily incorporated with our newly proposed
augmented feature representations to effectively utilize the data from both
domains for HDA. Using the hinge loss function in SVM as an example, we
introduce the detailed objective function in our method called Heterogeneous
Feature Augmentation (HFA) for a linear case and also describe its
kernelization in order to efficiently cope with the data with very high
dimensions. Moreover, we also develop an alternating optimization algorithm to
effectively solve the nontrivial optimization problem in our HFA method.
Comprehensive experiments on two benchmark datasets clearly demonstrate that
HFA outperforms the existing HDA methods.

Marginalized Denoising Autoencoders for Domain Adaptation
Stacked denoising autoencoders (SDAs) have been successfully used to learn
new representations for domain adaptation. Recently, they have attained record
accuracy on standard benchmark tasks of sentiment analysis across different
text domains. SDAs learn robust data representations by reconstruction,
recovering original features from data that are artificially corrupted with
noise. In this paper, we propose marginalized SDA (mSDA) that addresses two
crucial limitations of SDAs: high computational cost and lack of scalability to
high-dimensional features. In contrast to SDAs, our approach of mSDA
marginalizes noise and thus does not require stochastic gradient descent or
other optimization algorithms to learn parameters ? in fact, they are computed
in closed-form. Consequently, mSDA, which can be implemented in only 20 lines
of MATLAB^{TM}, significantly speeds up SDAs by two orders of magnitude.
Furthermore, the representations learnt by mSDA are as effective as the
traditional SDAs, attaining almost identical accuracies in benchmark tasks.

Dynamic Pricing under Finite Space Demand Uncertainty: A Multi-Armed
  Bandit with Dependent Arms
We consider a dynamic pricing problem under unknown demand models. In this
problem a seller offers prices to a stream of customers and observes either
success or failure in each sale attempt. The underlying demand model is unknown
to the seller and can take one of N possible forms. In this paper, we show that
this problem can be formulated as a multi-armed bandit with dependent arms. We
propose a dynamic pricing policy based on the likelihood ratio test. We show
that the proposed policy achieves complete learning, i.e., it offers a bounded
regret where regret is defined as the revenue loss with respect to the case
with a known demand model. This is in sharp contrast with the logarithmic
growing regret in multi-armed bandit with independent arms.

Practical recommendations for gradient-based training of deep
  architectures
Learning algorithms related to artificial neural networks and in particular
for Deep Learning may seem to involve many bells and whistles, called
hyper-parameters. This chapter is meant as a practical guide with
recommendations for some of the most commonly used hyper-parameters, in
particular in the context of learning algorithms based on back-propagated
gradient and gradient-based optimization. It also discusses how to deal with
the fact that more interesting results can be obtained when allowing one to
adjust many hyper-parameters. Overall, it describes elements of the practice
used to successfully and efficiently train and debug large-scale and often deep
multi-layer neural networks. It closes with open questions about the training
difficulties observed with deeper architectures.

Representation Learning: A Review and New Perspectives
The success of machine learning algorithms generally depends on data
representation, and we hypothesize that this is because different
representations can entangle and hide more or less the different explanatory
factors of variation behind the data. Although specific domain knowledge can be
used to help design representations, learning with generic priors can also be
used, and the quest for AI is motivating the design of more powerful
representation-learning algorithms implementing such priors. This paper reviews
recent work in the area of unsupervised feature learning and deep learning,
covering advances in probabilistic models, auto-encoders, manifold learning,
and deep networks. This motivates longer-term unanswered questions about the
appropriate objectives for learning good representations, for computing
representations (i.e., inference), and the geometrical connections between
representation learning, density estimation and manifold learning.

Graph Based Classification Methods Using Inaccurate External Classifier
  Information
In this paper we consider the problem of collectively classifying entities
where relational information is available across the entities. In practice
inaccurate class distribution for each entity is often available from another
(external) classifier. For example this distribution could come from a
classifier built using content features or a simple dictionary. Given the
relational and inaccurate external classifier information, we consider two
graph based settings in which the problem of collective classification can be
solved. In the first setting the class distribution is used to fix labels to a
subset of nodes and the labels for the remaining nodes are obtained like in a
transductive setting. In the other setting the class distributions of all nodes
are used to define the fitting function part of a graph regularized objective
function. We define a generalized objective function that handles both the
settings. Methods like harmonic Gaussian field and local-global consistency
(LGC) reported in the literature can be seen as special cases. We extend the
LGC and weighted vote relational neighbor classification (WvRN) methods to
support usage of external classifier information. We also propose an efficient
least squares regularization (LSR) based method and relate it to information
regularization methods. All the methods are evaluated on several benchmark and
real world datasets. Considering together speed, robustness and accuracy,
experimental results indicate that the LSR and WvRN-extension methods perform
better than other methods.

Learning Neighborhoods for Metric Learning
Metric learning methods have been shown to perform well on different learning
tasks. Many of them rely on target neighborhood relationships that are computed
in the original feature space and remain fixed throughout learning. As a
result, the learned metric reflects the original neighborhood relations. We
propose a novel formulation of the metric learning problem in which, in
addition to the metric, the target neighborhood relations are also learned in a
two-step iterative approach. The new formulation can be seen as a
generalization of many existing metric learning methods. The formulation
includes a target neighbor assignment rule that assigns different numbers of
neighbors to instances according to their quality; `high quality' instances get
more neighbors. We experiment with two of its instantiations that correspond to
the metric learning algorithms LMNN and MCML and compare it to other metric
learning methods on a number of datasets. The experimental results show
state-of-the-art performance and provide evidence that learning the
neighborhood relations does improve predictive performance.

On Multilabel Classification and Ranking with Partial Feedback
We present a novel multilabel/ranking algorithm working in partial
information settings. The algorithm is based on 2nd-order descent methods, and
relies on upper-confidence bounds to trade-off exploration and exploitation. We
analyze this algorithm in a partial adversarial setting, where covariates can
be adversarial, but multilabel probabilities are ruled by (generalized) linear
models. We show O(T^{1/2} log T) regret bounds, which improve in several ways
on the existing results. We test the effectiveness of our upper-confidence
scheme by contrasting against full-information baselines on real-world
multilabel datasets, often obtaining comparable performance.

Hybrid Template Update System for Unimodal Biometric Systems
Semi-supervised template update systems allow to automatically take into
account the intra-class variability of the biometric data over time. Such
systems can be inefficient by including too many impostor's samples or skipping
too many genuine's samples. In the first case, the biometric reference drifts
from the real biometric data and attracts more often impostors. In the second
case, the biometric reference does not evolve quickly enough and also
progressively drifts from the real biometric data. We propose a hybrid system
using several biometric sub-references in order to increase per- formance of
self-update systems by reducing the previously cited errors. The proposition is
validated for a keystroke- dynamics authentication system (this modality
suffers of high variability over time) on two consequent datasets from the
state of the art.

Web-Based Benchmark for Keystroke Dynamics Biometric Systems: A
  Statistical Analysis
Most keystroke dynamics studies have been evaluated using a specific kind of
dataset in which users type an imposed login and password. Moreover, these
studies are optimistics since most of them use different acquisition protocols,
private datasets, controlled environment, etc. In order to enhance the accuracy
of keystroke dynamics' performance, the main contribution of this paper is
twofold. First, we provide a new kind of dataset in which users have typed both
an imposed and a chosen pairs of logins and passwords. In addition, the
keystroke dynamics samples are collected in a web-based uncontrolled
environment (OS, keyboards, browser, etc.). Such kind of dataset is important
since it provides us more realistic results of keystroke dynamics' performance
in comparison to the literature (controlled environment, etc.). Second, we
present a statistical analysis of well known assertions such as the
relationship between performance and password size, impact of fusion schemes on
system overall performance, and others such as the relationship between
performance and entropy. We put into obviousness in this paper some new results
on keystroke dynamics in realistic conditions.

Accuracy Measures for the Comparison of Classifiers
The selection of the best classification algorithm for a given dataset is a
very widespread problem. It is also a complex one, in the sense it requires to
make several important methodological choices. Among them, in this work we
focus on the measure used to assess the classification performance and rank the
algorithms. We present the most popular measures and discuss their properties.
Despite the numerous measures proposed over the years, many of them turn out to
be equivalent in this specific case, to have interpretation problems, or to be
unsuitable for our purpose. Consequently, classic overall success rate or
marginal rates should be preferred for this specific task.

Better Mixing via Deep Representations
It has previously been hypothesized, and supported with some experimental
evidence, that deeper representations, when well trained, tend to do a better
job at disentangling the underlying factors of variation. We study the
following related conjecture: better representations, in the sense of better
disentangling, can be exploited to produce faster-mixing Markov chains.
Consequently, mixing would be more efficient at higher levels of
representation. To better understand why and how this is happening, we propose
a secondary conjecture: the higher-level samples fill more uniformly the space
they occupy and the high-density manifolds tend to unfold when represented at
higher levels. The paper discusses these hypotheses and tests them
experimentally through visualization and measurements of mixing and
interpolating between samples.

Supervised Laplacian Eigenmaps with Applications in Clinical Diagnostics
  for Pediatric Cardiology
Electronic health records contain rich textual data which possess critical
predictive information for machine-learning based diagnostic aids. However many
traditional machine learning methods fail to simultaneously integrate both
vector space data and text. We present a supervised method using Laplacian
eigenmaps to augment existing machine-learning methods with low-dimensional
representations of textual predictors which preserve the local similarities.
The proposed implementation performs alternating optimization using gradient
descent. For the evaluation we applied our method to over 2,000 patient records
from a large single-center pediatric cardiology practice to predict if patients
were diagnosed with cardiac disease. Our method was compared with latent
semantic indexing, latent Dirichlet allocation, and local Fisher discriminant
analysis. The results were assessed using AUC, MCC, specificity, and
sensitivity. Results indicate supervised Laplacian eigenmaps was the highest
performing method in our study, achieving 0.782 and 0.374 for AUC and MCC
respectively. SLE showed an increase in 8.16% in AUC and 20.6% in MCC over the
baseline which excluded textual data and a 2.69% and 5.35% increase in AUC and
MCC respectively over unsupervised Laplacian eigenmaps. This method allows many
existing machine learning predictors to effectively and efficiently utilize the
potential of textual predictors.

APRIL: Active Preference-learning based Reinforcement Learning
This paper focuses on reinforcement learning (RL) with limited prior
knowledge. In the domain of swarm robotics for instance, the expert can hardly
design a reward function or demonstrate the target behavior, forbidding the use
of both standard RL and inverse reinforcement learning. Although with a limited
expertise, the human expert is still often able to emit preferences and rank
the agent demonstrations. Earlier work has presented an iterative
preference-based RL framework: expert preferences are exploited to learn an
approximate policy return, thus enabling the agent to achieve direct policy
search. Iteratively, the agent selects a new candidate policy and demonstrates
it; the expert ranks the new demonstration comparatively to the previous best
one; the expert's ranking feedback enables the agent to refine the approximate
policy return, and the process is iterated. In this paper, preference-based
reinforcement learning is combined with active ranking in order to decrease the
number of ranking queries to the expert needed to yield a satisfactory policy.
Experiments on the mountain car and the cancer treatment testbeds witness that
a couple of dozen rankings enable to learn a competent policy.

Data Selection for Semi-Supervised Learning
The real challenge in pattern recognition task and machine learning process
is to train a discriminator using labeled data and use it to distinguish
between future data as accurate as possible. However, most of the problems in
the real world have numerous data, which labeling them is a cumbersome or even
an impossible matter. Semi-supervised learning is one approach to overcome
these types of problems. It uses only a small set of labeled with the company
of huge remain and unlabeled data to train the discriminator. In
semi-supervised learning, it is very essential that which data is labeled and
depend on position of data it effectiveness changes. In this paper, we proposed
an evolutionary approach called Artificial Immune System (AIS) to determine
which data is better to be labeled to get the high quality data. The
experimental results represent the effectiveness of this algorithm in finding
these data points.

Guess Who Rated This Movie: Identifying Users Through Subspace
  Clustering
It is often the case that, within an online recommender system, multiple
users share a common account. Can such shared accounts be identified solely on
the basis of the user- provided ratings? Once a shared account is identified,
can the different users sharing it be identified as well? Whenever such user
identification is feasible, it opens the way to possible improvements in
personalized recommendations, but also raises privacy concerns. We develop a
model for composite accounts based on unions of linear subspaces, and use
subspace clustering for carrying out the identification task. We show that a
significant fraction of such accounts is identifiable in a reliable manner, and
illustrate potential uses for personalized recommendation.

Metric Learning across Heterogeneous Domains by Respectively Aligning
  Both Priors and Posteriors
In this paper, we attempts to learn a single metric across two heterogeneous
domains where source domain is fully labeled and has many samples while target
domain has only a few labeled samples but abundant unlabeled samples. To the
best of our knowledge, this task is seldom touched. The proposed learning model
has a simple underlying motivation: all the samples in both the source and the
target domains are mapped into a common space, where both their priors
P(sample)s and their posteriors P(label|sample)s are forced to be respectively
aligned as much as possible. We show that the two mappings, from both the
source domain and the target domain to the common space, can be reparameterized
into a single positive semi-definite(PSD) matrix. Then we develop an efficient
Bregman Projection algorithm to optimize the PDS matrix over which a LogDet
function is used to regularize. Furthermore, we also show that this model can
be easily kernelized and verify its effectiveness in crosslanguage retrieval
task and cross-domain object recognition task.

Margin Distribution Controlled Boosting
Schapire's margin theory provides a theoretical explanation to the success of
boosting-type methods and manifests that a good margin distribution (MD) of
training samples is essential for generalization. However the statement that a
MD is good is vague, consequently, many recently developed algorithms try to
generate a MD in their goodness senses for boosting generalization. Unlike
their indirect control over MD, in this paper, we propose an alternative
boosting algorithm termed Margin distribution Controlled Boosting (MCBoost)
which directly controls the MD by introducing and optimizing a key adjustable
margin parameter. MCBoost's optimization implementation adopts the column
generation technique to ensure fast convergence and small number of weak
classifiers involved in the final MCBooster. We empirically demonstrate: 1)
AdaBoost is actually also a MD controlled algorithm and its iteration number
acts as a parameter controlling the distribution and 2) the generalization
performance of MCBoost evaluated on UCI benchmark datasets is validated better
than those of AdaBoost, L2Boost, LPBoost, AdaBoost-CG and MDBoost.

Inverse Reinforcement Learning with Gaussian Process
We present new algorithms for inverse reinforcement learning (IRL, or inverse
optimal control) in convex optimization settings. We argue that finite-space
IRL can be posed as a convex quadratic program under a Bayesian inference
framework with the objective of maximum a posterior estimation. To deal with
problems in large or even infinite state space, we propose a Gaussian process
model and use preference graphs to represent observations of decision
trajectories. Our method is distinguished from other approaches to IRL in that
it makes no assumptions about the form of the reward function and yet it
retains the promise of computationally manageable implementations for potential
real-world applications. In comparison with an establish algorithm on
small-scale numerical problems, our method demonstrated better accuracy in
apprenticeship learning and a more robust dependence on the number of
observations.

Efficient Active Learning of Halfspaces: an Aggressive Approach
We study pool-based active learning of half-spaces. We revisit the aggressive
approach for active learning in the realizable case, and show that it can be
made efficient and practical, while also having theoretical guarantees under
reasonable assumptions. We further show, both theoretically and experimentally,
that it can be preferable to mellow approaches. Our efficient aggressive active
learner of half-spaces has formal approximation guarantees that hold when the
pool is separable with a margin. While our analysis is focused on the
realizable setting, we show that a simple heuristic allows using the same
algorithm successfully for pools with low error as well. We further compare the
aggressive approach to the mellow approach, and prove that there are cases in
which the aggressive approach results in significantly better label complexity
compared to the mellow approach. We demonstrate experimentally that substantial
improvements in label complexity can be achieved using the aggressive approach,
for both realizable and low-error settings.

Auto-WEKA: Combined Selection and Hyperparameter Optimization of
  Classification Algorithms
Many different machine learning algorithms exist; taking into account each
algorithm's hyperparameters, there is a staggeringly large number of possible
alternatives overall. We consider the problem of simultaneously selecting a
learning algorithm and setting its hyperparameters, going beyond previous work
that addresses these issues in isolation. We show that this problem can be
addressed by a fully automated approach, leveraging recent innovations in
Bayesian optimization. Specifically, we consider a wide range of feature
selection techniques (combining 3 search and 8 evaluator methods) and all
classification approaches implemented in WEKA, spanning 2 ensemble methods, 10
meta-methods, 27 base classifiers, and hyperparameter settings for each
classifier. On each of 21 popular datasets from the UCI repository, the KDD Cup
09, variants of the MNIST dataset and CIFAR-10, we show classification
performance often much better than using standard selection/hyperparameter
optimization methods. We hope that our approach will help non-expert users to
more effectively identify machine learning algorithms and hyperparameter
settings appropriate to their applications, and hence to achieve improved
performance.

Vector Field k-Means: Clustering Trajectories by Fitting Multiple Vector
  Fields
Scientists study trajectory data to understand trends in movement patterns,
such as human mobility for traffic analysis and urban planning. There is a
pressing need for scalable and efficient techniques for analyzing this data and
discovering the underlying patterns. In this paper, we introduce a novel
technique which we call vector-field $k$-means.
  The central idea of our approach is to use vector fields to induce a
similarity notion between trajectories. Other clustering algorithms seek a
representative trajectory that best describes each cluster, much like $k$-means
identifies a representative "center" for each cluster. Vector-field $k$-means,
on the other hand, recognizes that in all but the simplest examples, no single
trajectory adequately describes a cluster. Our approach is based on the premise
that movement trends in trajectory data can be modeled as flows within multiple
vector fields, and the vector field itself is what defines each of the
clusters. We also show how vector-field $k$-means connects techniques for
scalar field design on meshes and $k$-means clustering.
  We present an algorithm that finds a locally optimal clustering of
trajectories into vector fields, and demonstrate how vector-field $k$-means can
be used to mine patterns from trajectory data. We present experimental evidence
of its effectiveness and efficiency using several datasets, including
historical hurricane data, GPS tracks of people and vehicles, and anonymous
call records from a large phone company. We compare our results to previous
trajectory clustering techniques, and find that our algorithm performs faster
in practice than the current state-of-the-art in trajectory clustering, in some
examples by a large margin.

Link Prediction via Generalized Coupled Tensor Factorisation
This study deals with the missing link prediction problem: the problem of
predicting the existence of missing connections between entities of interest.
We address link prediction using coupled analysis of relational datasets
represented as heterogeneous data, i.e., datasets in the form of matrices and
higher-order tensors. We propose to use an approach based on probabilistic
interpretation of tensor factorisation models, i.e., Generalised Coupled Tensor
Factorisation, which can simultaneously fit a large class of tensor models to
higher-order tensors/matrices with com- mon latent factors using different loss
functions. Numerical experiments demonstrate that joint analysis of data from
multiple sources via coupled factorisation improves the link prediction
performance and the selection of right loss function and tensor model is
crucial for accurately predicting missing links.

Improving the K-means algorithm using improved downhill simplex search
The k-means algorithm is one of the well-known and most popular clustering
algorithms. K-means seeks an optimal partition of the data by minimizing the
sum of squared error with an iterative optimization procedure, which belongs to
the category of hill climbing algorithms. As we know hill climbing searches are
famous for converging to local optimums. Since k-means can converge to a local
optimum, different initial points generally lead to different convergence
cancroids, which makes it important to start with a reasonable initial
partition in order to achieve high quality clustering solutions. However, in
theory, there exist no efficient and universal methods for determining such
initial partitions. In this paper we tried to find an optimum initial
partitioning for k-means algorithm. To achieve this goal we proposed a new
improved version of downhill simplex search, and then we used it in order to
find an optimal result for clustering approach and then compare this algorithm
with Genetic Algorithm base (GA), Genetic K-Means (GKM), Improved Genetic
K-Means (IGKM) and k-means algorithms.

Structuring Relevant Feature Sets with Multiple Model Learning
Feature selection is one of the most prominent learning tasks, especially in
high-dimensional datasets in which the goal is to understand the mechanisms
that underly the learning dataset. However most of them typically deliver just
a flat set of relevant features and provide no further information on what kind
of structures, e.g. feature groupings, might underly the set of relevant
features. In this paper we propose a new learning paradigm in which our goal is
to uncover the structures that underly the set of relevant features for a given
learning problem. We uncover two types of features sets, non-replaceable
features that contain important information about the target variable and
cannot be replaced by other features, and functionally similar features sets
that can be used interchangeably in learned models, given the presence of the
non-replaceable features, with no change in the predictive performance. To do
so we propose a new learning algorithm that learns a number of disjoint models
using a model disjointness regularization constraint together with a constraint
on the predictive agreement of the disjoint models. We explore the behavior of
our approach on a number of high-dimensional datasets, and show that, as
expected by their construction, these satisfy a number of properties. Namely,
model disjointness, a high predictive agreement, and a similar predictive
performance to models learned on the full set of relevant features. The ability
to structure the set of relevant features in such a manner can become a
valuable tool in different applications of scientific knowledge discovery.

An Empirical Study of MAUC in Multi-class Problems with Uncertain Cost
  Matrices
Cost-sensitive learning relies on the availability of a known and fixed cost
matrix. However, in some scenarios, the cost matrix is uncertain during
training, and re-train a classifier after the cost matrix is specified would
not be an option. For binary classification, this issue can be successfully
addressed by methods maximizing the Area Under the ROC Curve (AUC) metric.
Since the AUC can measure performance of base classifiers independent of cost
during training, and a larger AUC is more likely to lead to a smaller total
cost in testing using the threshold moving method. As an extension of AUC to
multi-class problems, MAUC has attracted lots of attentions and been widely
used. Although MAUC also measures performance of base classifiers independent
of cost, it is unclear whether a larger MAUC of classifiers is more likely to
lead to a smaller total cost. In fact, it is also unclear what kinds of
post-processing methods should be used in multi-class problems to convert base
classifiers into discrete classifiers such that the total cost is as small as
possible. In the paper, we empirically explore the relationship between MAUC
and the total cost of classifiers by applying two categories of post-processing
methods. Our results suggest that a larger MAUC is also beneficial.
Interestingly, simple calibration methods that convert the output matrix into
posterior probabilities perform better than existing sophisticated post
re-optimization methods.

Performance Evaluation of Predictive Classifiers For Knowledge Discovery
  From Engineering Materials Data Sets
In this paper, naive Bayesian and C4.5 Decision Tree Classifiers(DTC) are
successively applied on materials informatics to classify the engineering
materials into different classes for the selection of materials that suit the
input design specifications. Here, the classifiers are analyzed individually
and their performance evaluation is analyzed with confusion matrix predictive
parameters and standard measures, the classification results are analyzed on
different class of materials. Comparison of classifiers has found that naive
Bayesian classifier is more accurate and better than the C4.5 DTC. The
knowledge discovered by the naive bayesian classifier can be employed for
decision making in materials selection in manufacturing industries.

Conditional validity of inductive conformal predictors
Conformal predictors are set predictors that are automatically valid in the
sense of having coverage probability equal to or exceeding a given confidence
level. Inductive conformal predictors are a computationally efficient version
of conformal predictors satisfying the same property of validity. However,
inductive conformal predictors have been only known to control unconditional
coverage probability. This paper explores various versions of conditional
validity and various ways to achieve them using inductive conformal predictors
and their modifications.

Improving Energy Efficiency in Femtocell Networks: A Hierarchical
  Reinforcement Learning Framework
This paper investigates energy efficiency for two-tier femtocell networks
through combining game theory and stochastic learning. With the Stackelberg
game formulation, a hierarchical reinforcement learning framework is applied to
study the joint average utility maximization of macrocells and femtocells
subject to the minimum signal-to-interference-plus-noise-ratio requirements.
The macrocells behave as the leaders and the femtocells are followers during
the learning procedure. At each time step, the leaders commit to dynamic
strategies based on the best responses of the followers, while the followers
compete against each other with no further information but the leaders'
strategy information. In this paper, we propose two learning algorithms to
schedule each cell's stochastic power levels, leading by the macrocells.
Numerical experiments are presented to validate the proposed studies and show
that the two learning algorithms substantially improve the energy efficiency of
the femtocell networks.

Parametric Local Metric Learning for Nearest Neighbor Classification
We study the problem of learning local metrics for nearest neighbor
classification. Most previous works on local metric learning learn a number of
local unrelated metrics. While this "independence" approach delivers an
increased flexibility its downside is the considerable risk of overfitting. We
present a new parametric local metric learning method in which we learn a
smooth metric matrix function over the data manifold. Using an approximation
error bound of the metric matrix function we learn local metrics as linear
combinations of basis metrics defined on anchor points over different regions
of the instance space. We constrain the metric matrix function by imposing on
the linear combinations manifold regularization which makes the learned metric
matrix function vary smoothly along the geodesics of the data manifold. Our
metric learning method has excellent performance both in terms of predictive
power and scalability. We experimented with several large-scale classification
problems, tens of thousands of instances, and compared it with several state of
the art metric learning methods, both global and local, as well as to SVM with
automatic kernel selection, all of which it outperforms in a significant
manner.

Fast Randomized Model Generation for Shapelet-Based Time Series
  Classification
Time series classification is a field which has drawn much attention over the
past decade. A new approach for classification of time series uses
classification trees based on shapelets. A shapelet is a subsequence extracted
from one of the time series in the dataset. A disadvantage of this approach is
the time required for building the shapelet-based classification tree. The
search for the best shapelet requires examining all subsequences of all lengths
from all time series in the training set.
  A key goal of this work was to find an evaluation order of the shapelets
space which enables fast convergence to an accurate model. The comparative
analysis we conducted clearly indicates that a random evaluation order yields
the best results. Our empirical analysis of the distribution of high-quality
shapelets within the shapelets space provides insights into why randomized
shapelets sampling is superior to alternative evaluation orders.
  We present an algorithm for randomized model generation for shapelet-based
classification that converges extremely quickly to a model with surprisingly
high accuracy after evaluating only an exceedingly small fraction of the
shapelets space.

Towards Ultrahigh Dimensional Feature Selection for Big Data
In this paper, we present a new adaptive feature scaling scheme for
ultrahigh-dimensional feature selection on Big Data. To solve this problem
effectively, we first reformulate it as a convex semi-infinite programming
(SIP) problem and then propose an efficient \emph{feature generating paradigm}.
In contrast with traditional gradient-based approaches that conduct
optimization on all input features, the proposed method iteratively activates a
group of features and solves a sequence of multiple kernel learning (MKL)
subproblems of much reduced scale. To further speed up the training, we propose
to solve the MKL subproblems in their primal forms through a modified
accelerated proximal gradient approach. Due to such an optimization scheme,
some efficient cache techniques are also developed. The feature generating
paradigm can guarantee that the solution converges globally under mild
conditions and achieve lower feature selection bias. Moreover, the proposed
method can tackle two challenging tasks in feature selection: 1) group-based
feature selection with complex structures and 2) nonlinear feature selection
with explicit feature mappings. Comprehensive experiments on a wide range of
synthetic and real-world datasets containing tens of million data points with
$O(10^{14})$ features demonstrate the competitive performance of the proposed
method over state-of-the-art feature selection methods in terms of
generalization performance and training efficiency.

BPRS: Belief Propagation Based Iterative Recommender System
In this paper we introduce the first application of the Belief Propagation
(BP) algorithm in the design of recommender systems. We formulate the
recommendation problem as an inference problem and aim to compute the marginal
probability distributions of the variables which represent the ratings to be
predicted. However, computing these marginal probability functions is
computationally prohibitive for large-scale systems. Therefore, we utilize the
BP algorithm to efficiently compute these functions. Recommendations for each
active user are then iteratively computed by probabilistic message passing. As
opposed to the previous recommender algorithms, BPRS does not require solving
the recommendation problem for all the users if it wishes to update the
recommendations for only a single active. Further, BPRS computes the
recommendations for each user with linear complexity and without requiring a
training period. Via computer simulations (using the 100K MovieLens dataset),
we verify that BPRS iteratively reduces the error in the predicted ratings of
the users until it converges. Finally, we confirm that BPRS is comparable to
the state of art methods such as Correlation-based neighborhood model (CorNgbr)
and Singular Value Decomposition (SVD) in terms of rating and precision
accuracy. Therefore, we believe that the BP-based recommendation algorithm is a
new promising approach which offers a significant advantage on scalability
while providing competitive accuracy for the recommender systems.

More Is Better: Large Scale Partially-supervised Sentiment
  Classification - Appendix
We describe a bootstrapping algorithm to learn from partially labeled data,
and the results of an empirical study for using it to improve performance of
sentiment classification using up to 15 million unlabeled Amazon product
reviews. Our experiments cover semi-supervised learning, domain adaptation and
weakly supervised learning. In some cases our methods were able to reduce test
error by more than half using such large amount of data.
  NOTICE: This is only the supplementary material.

A Deterministic Analysis of an Online Convex Mixture of Expert
  Algorithms
We analyze an online learning algorithm that adaptively combines outputs of
two constituent algorithms (or the experts) running in parallel to model an
unknown desired signal. This online learning algorithm is shown to achieve (and
in some cases outperform) the mean-square error (MSE) performance of the best
constituent algorithm in the mixture in the steady-state. However, the MSE
analysis of this algorithm in the literature uses approximations and relies on
statistical models on the underlying signals and systems. Hence, such an
analysis may not be useful or valid for signals generated by various real life
systems that show high degrees of nonstationarity, limit cycles and, in many
cases, that are even chaotic. In this paper, we produce results in an
individual sequence manner. In particular, we relate the time-accumulated
squared estimation error of this online algorithm at any time over any interval
to the time accumulated squared estimation error of the optimal convex mixture
of the constituent algorithms directly tuned to the underlying signal in a
deterministic sense without any statistical assumptions. In this sense, our
analysis provides the transient, steady-state and tracking behavior of this
algorithm in a strong sense without any approximations in the derivations or
statistical assumptions on the underlying signals such that our results are
guaranteed to hold. We illustrate the introduced results through examples.

Memory Constraint Online Multitask Classification
We investigate online kernel algorithms which simultaneously process multiple
classification tasks while a fixed constraint is imposed on the size of their
active sets. We focus in particular on the design of algorithms that can
efficiently deal with problems where the number of tasks is extremely high and
the task data are large scale. Two new projection-based algorithms are
introduced to efficiently tackle those issues while presenting different trade
offs on how the available memory is managed with respect to the prior
information about the learning tasks. Theoretically sound budget algorithms are
devised by coupling the Randomized Budget Perceptron and the Forgetron
algorithms with the multitask kernel. We show how the two seemingly contrasting
properties of learning from multiple tasks and keeping a constant memory
footprint can be balanced, and how the sharing of the available space among
different tasks is automatically taken care of. We propose and discuss new
insights on the multitask kernel. Experiments show that online kernel multitask
algorithms running on a budget can efficiently tackle real world learning
problems involving multiple tasks.

TV-SVM: Total Variation Support Vector Machine for Semi-Supervised Data
  Classification
We introduce semi-supervised data classification algorithms based on total
variation (TV), Reproducing Kernel Hilbert Space (RKHS), support vector machine
(SVM), Cheeger cut, labeled and unlabeled data points. We design binary and
multi-class semi-supervised classification algorithms. We compare the TV-based
classification algorithms with the related Laplacian-based algorithms, and show
that TV classification perform significantly better when the number of labeled
data is small.

Fast Online EM for Big Topic Modeling
The expectation-maximization (EM) algorithm can compute the
maximum-likelihood (ML) or maximum a posterior (MAP) point estimate of the
mixture models or latent variable models such as latent Dirichlet allocation
(LDA), which has been one of the most popular probabilistic topic modeling
methods in the past decade. However, batch EM has high time and space
complexities to learn big LDA models from big data streams. In this paper, we
present a fast online EM (FOEM) algorithm that infers the topic distribution
from the previously unseen documents incrementally with constant memory
requirements. Within the stochastic approximation framework, we show that FOEM
can converge to the local stationary point of the LDA's likelihood function. By
dynamic scheduling for the fast speed and parameter streaming for the low
memory usage, FOEM is more efficient for some lifelong topic modeling tasks
than the state-of-the-art online LDA algorithms to handle both big data and big
models (aka, big topic modeling) on just a PC.

Blending Learning and Inference in Structured Prediction
In this paper we derive an efficient algorithm to learn the parameters of
structured predictors in general graphical models. This algorithm blends the
learning and inference tasks, which results in a significant speedup over
traditional approaches, such as conditional random fields and structured
support vector machines. For this purpose we utilize the structures of the
predictors to describe a low dimensional structured prediction task which
encourages local consistencies within the different structures while learning
the parameters of the model. Convexity of the learning task provides the means
to enforce the consistencies between the different parts. The
inference-learning blending algorithm that we propose is guaranteed to converge
to the optimum of the low dimensional primal and dual programs. Unlike many of
the existing approaches, the inference-learning blending allows us to learn
efficiently high-order graphical models, over regions of any size, and very
large number of parameters. We demonstrate the effectiveness of our approach,
while presenting state-of-the-art results in stereo estimation, semantic
segmentation, shape reconstruction, and indoor scene understanding.

A Direct Approach to Multi-class Boosting and Extensions
Boosting methods combine a set of moderately accurate weaklearners to form a
highly accurate predictor. Despite the practical importance of multi-class
boosting, it has received far less attention than its binary counterpart. In
this work, we propose a fully-corrective multi-class boosting formulation which
directly solves the multi-class problem without dividing it into multiple
binary classification problems. In contrast, most previous multi-class boosting
algorithms decompose a multi-boost problem into multiple binary boosting
problems. By explicitly deriving the Lagrange dual of the primal optimization
problem, we are able to construct a column generation-based fully-corrective
approach to boosting which directly optimizes multi-class classification
performance. The new approach not only updates all weak learners' coefficients
at every iteration, but does so in a manner flexible enough to accommodate
various loss functions and regularizations. For example, it enables us to
introduce structural sparsity through mixed-norm regularization to promote
group sparsity and feature sharing. Boosting with shared features is
particularly beneficial in complex prediction problems where features can be
expensive to compute. Our experiments on various data sets demonstrate that our
direct multi-class boosting generalizes as well as, or better than, a range of
competing multi-class boosting methods. The end result is a highly effective
and compact ensemble classifier which can be trained in a distributed fashion.

Bayesian Estimation for Continuous-Time Sparse Stochastic Processes
We consider continuous-time sparse stochastic processes from which we have
only a finite number of noisy/noiseless samples. Our goal is to estimate the
noiseless samples (denoising) and the signal in-between (interpolation
problem).
  By relying on tools from the theory of splines, we derive the joint a priori
distribution of the samples and show how this probability density function can
be factorized. The factorization enables us to tractably implement the maximum
a posteriori and minimum mean-square error (MMSE) criteria as two statistical
approaches for estimating the unknowns. We compare the derived statistical
methods with well-known techniques for the recovery of sparse signals, such as
the $\ell_1$ norm and Log ($\ell_1$-$\ell_0$ relaxation) regularization
methods. The simulation results show that, under certain conditions, the
performance of the regularization techniques can be very close to that of the
MMSE estimator.

Online Learning in Decentralized Multiuser Resource Sharing Problems
In this paper, we consider the general scenario of resource sharing in a
decentralized system when the resource rewards/qualities are time-varying and
unknown to the users, and using the same resource by multiple users leads to
reduced quality due to resource sharing. Firstly, we consider a
user-independent reward model with no communication between the users, where a
user gets feedback about the congestion level in the resource it uses.
Secondly, we consider user-specific rewards and allow costly communication
between the users. The users have a cooperative goal of achieving the highest
system utility. There are multiple obstacles in achieving this goal such as the
decentralized nature of the system, unknown resource qualities, communication,
computation and switching costs. We propose distributed learning algorithms
with logarithmic regret with respect to the optimal allocation. Our logarithmic
regret result holds under both i.i.d. and Markovian reward models, as well as
under communication, computation and switching costs.

A density-sensitive hierarchical clustering method
We define a hierarchical clustering method: $\alpha$-unchaining single
linkage or $SL(\alpha)$. The input of this algorithm is a finite metric space
and a certain parameter $\alpha$. This method is sensitive to the density of
the distribution and offers some solution to the so called chaining effect. We
also define a modified version, $SL^*(\alpha)$, to treat the chaining through
points or small blocks. We study the theoretical properties of these methods
and offer some theoretical background for the treatment of chaining effects.

Text Classification with Compression Algorithms
This work concerns a comparison of SVM kernel methods in text categorization
tasks. In particular I define a kernel function that estimates the similarity
between two objects computing by their compressed lengths. In fact, compression
algorithms can detect arbitrarily long dependencies within the text strings.
Data text vectorization looses information in feature extractions and is highly
sensitive by textual language. Furthermore, these methods are language
independent and require no text preprocessing. Moreover, the accuracy computed
on the datasets (Web-KB, 20ng and Reuters-21578), in some case, is greater than
Gaussian, linear and polynomial kernels. The method limits are represented by
computational time complexity of the Gram matrix and by very poor performance
on non-textual datasets.

Advances in Optimizing Recurrent Networks
After a more than decade-long period of relatively little research activity
in the area of recurrent neural networks, several new developments will be
reviewed here that have allowed substantial progress both in understanding and
in technical solutions towards more efficient training of recurrent networks.
These advances have been motivated by and related to the optimization issues
surrounding deep learning. Although recurrent networks are extremely powerful
in what they can in principle represent in terms of modelling sequences,their
training is plagued by two aspects of the same issue regarding the learning of
long-term dependencies. Experiments reported here evaluate the use of clipping
gradients, spanning longer time ranges with leaky integration, advanced
momentum techniques, using more powerful output probability models, and
encouraging sparser gradients to help symmetry breaking and credit assignment.
The experiments are performed on text and music data and show off the combined
effects of these techniques in generally improving both training and test
error.

High-dimensional sequence transduction
We investigate the problem of transforming an input sequence into a
high-dimensional output sequence in order to transcribe polyphonic audio music
into symbolic notation. We introduce a probabilistic model based on a recurrent
neural network that is able to learn realistic output distributions given the
input and we devise an efficient algorithm to search for the global mode of
that distribution. The resulting method produces musically plausible
transcriptions even under high levels of noise and drastically outperforms
previous state-of-the-art approaches on five datasets of synthesized sounds and
real recordings, approximately halving the test error rate.

Cost-Sensitive Feature Selection of Data with Errors
In data mining applications, feature selection is an essential process since
it reduces a model's complexity. The cost of obtaining the feature values must
be taken into consideration in many domains. In this paper, we study the
cost-sensitive feature selection problem on numerical data with measurement
errors, test costs and misclassification costs. The major contributions of this
paper are four-fold. First, a new data model is built to address test costs and
misclassification costs as well as error boundaries. Second, a covering-based
rough set with measurement errors is constructed. Given a confidence interval,
the neighborhood is an ellipse in a two-dimension space, or an ellipsoidal in a
three-dimension space, etc. Third, a new cost-sensitive feature selection
problem is defined on this covering-based rough set. Fourth, both backtracking
and heuristic algorithms are proposed to deal with this new problem. The
algorithms are tested on six UCI (University of California - Irvine) data sets.
Experimental results show that (1) the pruning techniques of the backtracking
algorithm help reducing the number of operations significantly, and (2) the
heuristic algorithm usually obtains optimal results. This study is a step
toward realistic applications of cost-sensitive learning.

Learning efficient sparse and low rank models
Parsimony, including sparsity and low rank, has been shown to successfully
model data in numerous machine learning and signal processing tasks.
Traditionally, such modeling approaches rely on an iterative algorithm that
minimizes an objective function with parsimony-promoting terms. The inherently
sequential structure and data-dependent complexity and latency of iterative
optimization constitute a major limitation in many applications requiring
real-time performance or involving large-scale data. Another limitation
encountered by these modeling techniques is the difficulty of their inclusion
in discriminative learning scenarios. In this work, we propose to move the
emphasis from the model to the pursuit algorithm, and develop a process-centric
view of parsimonious modeling, in which a learned deterministic
fixed-complexity pursuit process is used in lieu of iterative optimization. We
show a principled way to construct learnable pursuit process architectures for
structured sparse and robust low rank models, derived from the iteration of
proximal descent algorithms. These architectures learn to approximate the exact
parsimonious representation at a fraction of the complexity of the standard
optimization methods. We also show that appropriate training regimes allow to
naturally extend parsimonious models to discriminative settings.
State-of-the-art results are demonstrated on several challenging problems in
image and audio processing with several orders of magnitude speedup compared to
the exact optimization algorithms.

Analysis of Large-scale Traffic Dynamics using Non-negative Tensor
  Factorization
In this paper, we present our work on clustering and prediction of temporal
dynamics of global congestion configurations in large-scale road networks.
Instead of looking into temporal traffic state variation of individual links,
or of small areas, we focus on spatial congestion configurations of the whole
network. In our work, we aim at describing the typical temporal dynamic
patterns of this network-level traffic state and achieving long-term prediction
of the large-scale traffic dynamics, in a unified data-mining framework. To
this end, we formulate this joint task using Non-negative Tensor Factorization
(NTF), which has been shown to be a useful decomposition tools for multivariate
data sequences. Clustering and prediction are performed based on the compact
tensor factorization results. Experiments on large-scale simulated data
illustrate the interest of our method with promising results for long-term
forecast of traffic evolution.

Hybrid Fuzzy-ART based K-Means Clustering Methodology to Cellular
  Manufacturing Using Operational Time
This paper presents a new hybrid Fuzzy-ART based K-Means Clustering technique
to solve the part machine grouping problem in cellular manufacturing systems
considering operational time. The performance of the proposed technique is
tested with problems from open literature and the results are compared to the
existing clustering models such as simple K-means algorithm and modified ART1
algorithm using an efficient modified performance measure known as modified
grouping efficiency (MGE) as found in the literature. The results support the
better performance of the proposed algorithm. The Novelty of this study lies in
the simple and efficient methodology to produce quick solutions for shop floor
managers with least computational efforts and time.

ADADELTA: An Adaptive Learning Rate Method
We present a novel per-dimension learning rate method for gradient descent
called ADADELTA. The method dynamically adapts over time using only first order
information and has minimal computational overhead beyond vanilla stochastic
gradient descent. The method requires no manual tuning of a learning rate and
appears robust to noisy gradient information, different model architecture
choices, various data modalities and selection of hyperparameters. We show
promising results compared to other methods on the MNIST digit classification
task using a single machine and on a large scale voice dataset in a distributed
cluster environment.

Tangent Bundle Manifold Learning via Grassmann&Stiefel Eigenmaps
One of the ultimate goals of Manifold Learning (ML) is to reconstruct an
unknown nonlinear low-dimensional manifold embedded in a high-dimensional
observation space by a given set of data points from the manifold. We derive a
local lower bound for the maximum reconstruction error in a small neighborhood
of an arbitrary point. The lower bound is defined in terms of the distance
between tangent spaces to the original manifold and the estimated manifold at
the considered point and reconstructed point, respectively. We propose an
amplification of the ML, called Tangent Bundle ML, in which the proximity not
only between the original manifold and its estimator but also between their
tangent spaces is required. We present a new algorithm that solves this problem
and gives a new solution for the ML also.

A Novel Design Specification Distance(DSD) Based K-Mean Clustering
  Performace Evluation on Engineering Materials Database
Organizing data into semantically more meaningful is one of the fundamental
modes of understanding and learning. Cluster analysis is a formal study of
methods for understanding and algorithm for learning. K-mean clustering
algorithm is one of the most fundamental and simple clustering algorithms. When
there is no prior knowledge about the distribution of data sets, K-mean is the
first choice for clustering with an initial number of clusters. In this paper a
novel distance metric called Design Specification (DS) distance measure
function is integrated with K-mean clustering algorithm to improve cluster
accuracy. The K-means algorithm with proposed distance measure maximizes the
cluster accuracy to 99.98% at P = 1.525, which is determined through the
iterative procedure. The performance of Design Specification (DS) distance
measure function with K - mean algorithm is compared with the performances of
other standard distance functions such as Euclidian, squared Euclidean, City
Block, and Chebshew similarity measures deployed with K-mean algorithm.The
proposed method is evaluated on the engineering materials database. The
experiments on cluster analysis and the outlier profiling show that these is an
excellent improvement in the performance of the proposed method.

Risk-Aversion in Multi-armed Bandits
Stochastic multi-armed bandits solve the Exploration-Exploitation dilemma and
ultimately maximize the expected reward. Nonetheless, in many practical
problems, maximizing the expected reward is not the most desirable objective.
In this paper, we introduce a novel setting based on the principle of
risk-aversion where the objective is to compete against the arm with the best
risk-return trade-off. This setting proves to be intrinsically more difficult
than the standard multi-arm bandit setting due in part to an exploration risk
which introduces a regret associated to the variability of an algorithm. Using
variance as a measure of risk, we introduce two new algorithms, investigate
their theoretical guarantees, and report preliminary empirical results.

Error Correction in Learning using SVMs
This paper is concerned with learning binary classifiers under adversarial
label-noise. We introduce the problem of error-correction in learning where the
goal is to recover the original clean data from a label-manipulated version of
it, given (i) no constraints on the adversary other than an upper-bound on the
number of errors, and (ii) some regularity properties for the original data. We
present a simple and practical error-correction algorithm called SubSVMs that
learns individual SVMs on several small-size (log-size), class-balanced, random
subsets of the data and then reclassifies the training points using a majority
vote. Our analysis reveals the need for the two main ingredients of SubSVMs,
namely class-balanced sampling and subsampled bagging. Experimental results on
synthetic as well as benchmark UCI data demonstrate the effectiveness of our
approach. In addition to noise-tolerance, log-size subsampled bagging also
yields significant run-time benefits over standard SVMs.

Learning to Optimize Via Posterior Sampling
This paper considers the use of a simple posterior sampling algorithm to
balance between exploration and exploitation when learning to optimize actions
such as in multi-armed bandit problems. The algorithm, also known as Thompson
Sampling, offers significant advantages over the popular upper confidence bound
(UCB) approach, and can be applied to problems with finite or infinite action
spaces and complicated relationships among action rewards. We make two
theoretical contributions. The first establishes a connection between posterior
sampling and UCB algorithms. This result lets us convert regret bounds
developed for UCB algorithms into Bayesian regret bounds for posterior
sampling. Our second theoretical contribution is a Bayesian regret bound for
posterior sampling that applies broadly and can be specialized to many model
classes. This bound depends on a new notion we refer to as the eluder
dimension, which measures the degree of dependence among action rewards.
Compared to UCB algorithm Bayesian regret bounds for specific model classes,
our general bound matches the best available for linear models and is stronger
than the best available for generalized linear models. Further, our analysis
provides insight into performance advantages of posterior sampling, which are
highlighted through simulation results that demonstrate performance surpassing
recently proposed UCB algorithms.

Efficient Learning of Domain-invariant Image Representations
We present an algorithm that learns representations which explicitly
compensate for domain mismatch and which can be efficiently realized as linear
classifiers. Specifically, we form a linear transformation that maps features
from the target (test) domain to the source (training) domain as part of
training the classifier. We optimize both the transformation and classifier
parameters jointly, and introduce an efficient cost function based on
misclassification loss. Our method combines several features previously
unavailable in a single algorithm: multi-class adaptation through
representation learning, ability to map across heterogeneous feature spaces,
and scalability to large datasets. We present experiments on several image
datasets that demonstrate improved accuracy and computational advantages
compared to previous approaches.

Feature grouping from spatially constrained multiplicative interaction
We present a feature learning model that learns to encode relationships
between images. The model is defined as a Gated Boltzmann Machine, which is
constrained such that hidden units that are nearby in space can gate each
other's connections. We show how frequency/orientation "columns" as well as
topographic filter maps follow naturally from training the model on image
pairs. The model also helps explain why square-pooling models yield feature
groups with similar grouping properties. Experimental results on synthetic
image transformations show that spatially constrained gating is an effective
way to reduce the number of parameters and thereby to regularize a
transformation-learning model.

A Semantic Matching Energy Function for Learning with Multi-relational
  Data
Large-scale relational learning becomes crucial for handling the huge amounts
of structured data generated daily in many application domains ranging from
computational biology or information retrieval, to natural language processing.
In this paper, we present a new neural network architecture designed to embed
multi-relational graphs into a flexible continuous vector space in which the
original data is kept and enhanced. The network is trained to encode the
semantics of these graphs in order to assign high probabilities to plausible
components. We empirically show that it reaches competitive performance in link
prediction on standard datasets from the literature.

How good is the Electricity benchmark for evaluating concept drift
  adaptation
In this correspondence, we will point out a problem with testing adaptive
classifiers on autocorrelated data. In such a case random change alarms may
boost the accuracy figures. Hence, we cannot be sure if the adaptation is
working well.

Learning Features with Structure-Adapting Multi-view Exponential Family
  Harmoniums
We proposea graphical model for multi-view feature extraction that
automatically adapts its structure to achieve better representation of data
distribution. The proposed model, structure-adapting multi-view harmonium
(SA-MVH) has switch parameters that control the connection between hidden nodes
and input views, and learn the switch parameter while training. Numerical
experiments on synthetic and a real-world dataset demonstrate the useful
behavior of the SA-MVH, compared to existing multi-view feature extraction
methods.

Saturating Auto-Encoders
We introduce a simple new regularizer for auto-encoders whose hidden-unit
activation functions contain at least one zero-gradient (saturated) region.
This regularizer explicitly encourages activations in the saturated region(s)
of the corresponding activation function. We call these Saturating
Auto-Encoders (SATAE). We show that the saturation regularizer explicitly
limits the SATAE's ability to reconstruct inputs which are not near the data
manifold. Furthermore, we show that a wide variety of features can be learned
when different activation functions are used. Finally, connections are
established with the Contractive and Sparse Auto-Encoders.

Behavior Pattern Recognition using A New Representation Model
We study the use of inverse reinforcement learning (IRL) as a tool for the
recognition of agents' behavior on the basis of observation of their sequential
decision behavior interacting with the environment. We model the problem faced
by the agents as a Markov decision process (MDP) and model the observed
behavior of the agents in terms of forward planning for the MDP. We use IRL to
learn reward functions and then use these reward functions as the basis for
clustering or classification models. Experimental studies with GridWorld, a
navigation problem, and the secretary problem, an optimal stopping problem,
suggest reward vectors found from IRL can be a good basis for behavior pattern
recognition problems. Empirical comparisons of our method with several existing
IRL algorithms and with direct methods that use feature statistics observed in
state-action space suggest it may be superior for recognition problems.

Switched linear encoding with rectified linear autoencoders
Several recent results in machine learning have established formal
connections between autoencoders---artificial neural network models that
attempt to reproduce their inputs---and other coding models like sparse coding
and K-means. This paper explores in depth an autoencoder model that is
constructed using rectified linear activations on its hidden units. Our
analysis builds on recent results to further unify the world of sparse linear
coding models. We provide an intuitive interpretation of the behavior of these
coding models and demonstrate this intuition using small, artificial datasets
with known distributions.

Learning Output Kernels for Multi-Task Problems
Simultaneously solving multiple related learning tasks is beneficial under a
variety of circumstances, but the prior knowledge necessary to correctly model
task relationships is rarely available in practice. In this paper, we develop a
novel kernel-based multi-task learning technique that automatically reveals
structural inter-task relationships. Building over the framework of output
kernel learning (OKL), we introduce a method that jointly learns multiple
functions and a low-rank multi-task kernel by solving a non-convex
regularization problem. Optimization is carried out via a block coordinate
descent strategy, where each subproblem is solved using suitable conjugate
gradient (CG) type iterative methods for linear operator equations. The
effectiveness of the proposed approach is demonstrated on pharmacological and
collaborative filtering data.

See the Tree Through the Lines: The Shazoo Algorithm -- Full Version --
Predicting the nodes of a given graph is a fascinating theoretical problem
with applications in several domains. Since graph sparsification via spanning
trees retains enough information while making the task much easier, trees are
an important special case of this problem. Although it is known how to predict
the nodes of an unweighted tree in a nearly optimal way, in the weighted case a
fully satisfactory algorithm is not available yet. We fill this hole and
introduce an efficient node predictor, Shazoo, which is nearly optimal on any
weighted tree. Moreover, we show that Shazoo can be viewed as a common
nontrivial generalization of both previous approaches for unweighted trees and
weighted lines. Experiments on real-world datasets confirm that Shazoo performs
well in that it fully exploits the structure of the input tree, and gets very
close to (and sometimes better than) less scalable energy minimization methods.

Weighted Last-Step Min-Max Algorithm with Improved Sub-Logarithmic
  Regret
In online learning the performance of an algorithm is typically compared to
the performance of a fixed function from some class, with a quantity called
regret. Forster proposed a last-step min-max algorithm which was somewhat
simpler than the algorithm of Vovk, yet with the same regret. In fact the
algorithm he analyzed assumed that the choices of the adversary are bounded,
yielding artificially only the two extreme cases. We fix this problem by
weighing the examples in such a way that the min-max problem will be well
defined, and provide analysis with logarithmic regret that may have better
multiplicative factor than both bounds of Forster and Vovk. We also derive a
new bound that may be sub-logarithmic, as a recent bound of Orabona et.al, but
may have better multiplicative factor. Finally, we analyze the algorithm in a
weak-type of non-stationary setting, and show a bound that is sub-linear if the
non-stationarity is sub-linear as well.

Hierarchical Data Representation Model - Multi-layer NMF
In this paper, we propose a data representation model that demonstrates
hierarchical feature learning using nsNMF. We extend unit algorithm into
several layers. Experiments with document and image data successfully
discovered feature hierarchies. We also prove that proposed method results in
much better classification and reconstruction performance, especially for small
number of features. feature hierarchies.

Clustering-Based Matrix Factorization
Recommender systems are emerging technologies that nowadays can be found in
many applications such as Amazon, Netflix, and so on. These systems help users
to find relevant information, recommendations, and their preferred items.
Slightly improvement of the accuracy of these recommenders can highly affect
the quality of recommendations. Matrix Factorization is a popular method in
Recommendation Systems showing promising results in accuracy and complexity. In
this paper we propose an extension of matrix factorization which adds general
neighborhood information on the recommendation model. Users and items are
clustered into different categories to see how these categories share
preferences. We then employ these shared interests of categories in a fusion by
Biased Matrix Factorization to achieve more accurate recommendations. This is a
complement for the current neighborhood aware matrix factorization models which
rely on using direct neighborhood information of users and items. The proposed
model is tested on two well-known recommendation system datasets: Movielens100k
and Netflix. Our experiment shows applying the general latent features of
categories into factorized recommender models improves the accuracy of
recommendations. The current neighborhood-aware models need a great number of
neighbors to acheive good accuracies. To the best of our knowledge, the
proposed model is better than or comparable with the current neighborhood-aware
models when they consider fewer number of neighbors.

A game-theoretic framework for classifier ensembles using weighted
  majority voting with local accuracy estimates
In this paper, a novel approach for the optimal combination of binary
classifiers is proposed. The classifier combination problem is approached from
a Game Theory perspective. The proposed framework of adapted weighted majority
rules (WMR) is tested against common rank-based, Bayesian and simple majority
models, as well as two soft-output averaging rules. Experiments with ensembles
of Support Vector Machines (SVM), Ordinary Binary Tree Classifiers (OBTC) and
weighted k-nearest-neighbor (w/k-NN) models on benchmark datasets indicate that
this new adaptive WMR model, employing local accuracy estimators and the
analytically computed optimal weights outperform all the other simple
combination rules.

RandomBoost: Simplified Multi-class Boosting through Randomization
We propose a novel boosting approach to multi-class classification problems,
in which multiple classes are distinguished by a set of random projection
matrices in essence. The approach uses random projections to alleviate the
proliferation of binary classifiers typically required to perform multi-class
classification. The result is a multi-class classifier with a single
vector-valued parameter, irrespective of the number of classes involved. Two
variants of this approach are proposed. The first method randomly projects the
original data into new spaces, while the second method randomly projects the
outputs of learned weak classifiers. These methods are not only conceptually
simple but also effective and easy to implement. A series of experiments on
synthetic, machine learning and visual recognition data sets demonstrate that
our proposed methods compare favorably to existing multi-class boosting
algorithms in terms of both the convergence rate and classification accuracy.

A Comparison of Relaxations of Multiset Cannonical Correlation Analysis
  and Applications
Canonical correlation analysis is a statistical technique that is used to
find relations between two sets of variables. An important extension in pattern
analysis is to consider more than two sets of variables. This problem can be
expressed as a quadratically constrained quadratic program (QCQP), commonly
referred to Multi-set Canonical Correlation Analysis (MCCA). This is a
non-convex problem and so greedy algorithms converge to local optima without
any guarantees on global optimality. In this paper, we show that despite being
highly structured, finding the optimal solution is NP-Hard. This motivates our
relaxation of the QCQP to a semidefinite program (SDP). The SDP is convex, can
be solved reasonably efficiently and comes with both absolute and
output-sensitive approximation quality. In addition to theoretical guarantees,
we do an extensive comparison of the QCQP method and the SDP relaxation on a
variety of synthetic and real world data. Finally, we present two useful
extensions: we incorporate kernel methods and computing multiple sets of
canonical vectors.

The price of bandit information in multiclass online classification
We consider two scenarios of multiclass online learning of a hypothesis class
$H\subseteq Y^X$. In the {\em full information} scenario, the learner is
exposed to instances together with their labels. In the {\em bandit} scenario,
the true label is not exposed, but rather an indication whether the learner's
prediction is correct or not. We show that the ratio between the error rates in
the two scenarios is at most $8\cdot|Y|\cdot \log(|Y|)$ in the realizable case,
and $\tilde{O}(\sqrt{|Y|})$ in the agnostic case. The results are tight up to a
logarithmic factor and essentially answer an open question from (Daniely et.
al. - Multiclass learnability and the erm principle).
  We apply these results to the class of $\gamma$-margin multiclass linear
classifiers in $\reals^d$. We show that the bandit error rate of this class is
$\tilde{\Theta}(\frac{|Y|}{\gamma^2})$ in the realizable case and
$\tilde{\Theta}(\frac{1}{\gamma}\sqrt{|Y|T})$ in the agnostic case. This
resolves an open question from (Kakade et. al. - Efficient bandit algorithms
for online multiclass prediction).

Passive Learning with Target Risk
In this paper we consider learning in passive setting but with a slight
modification. We assume that the target expected loss, also referred to as
target risk, is provided in advance for learner as prior knowledge. Unlike most
studies in the learning theory that only incorporate the prior knowledge into
the generalization bounds, we are able to explicitly utilize the target risk in
the learning process. Our analysis reveals a surprising result on the sample
complexity of learning: by exploiting the target risk in the learning
algorithm, we show that when the loss function is both strongly convex and
smooth, the sample complexity reduces to $\O(\log (\frac{1}{\epsilon}))$, an
exponential improvement compared to the sample complexity
$\O(\frac{1}{\epsilon})$ for learning with strongly convex loss functions.
Furthermore, our proof is constructive and is based on a computationally
efficient stochastic optimization algorithm for such settings which demonstrate
that the proposed algorithm is practically useful.

Minimax Optimal Algorithms for Unconstrained Linear Optimization
We design and analyze minimax-optimal algorithms for online linear
optimization games where the player's choice is unconstrained. The player
strives to minimize regret, the difference between his loss and the loss of a
post-hoc benchmark strategy. The standard benchmark is the loss of the best
strategy chosen from a bounded comparator set. When the the comparison set and
the adversary's gradients satisfy L_infinity bounds, we give the value of the
game in closed form and prove it approaches sqrt(2T/pi) as T -> infinity.
  Interesting algorithms result when we consider soft constraints on the
comparator, rather than restricting it to a bounded set. As a warmup, we
analyze the game with a quadratic penalty. The value of this game is exactly
T/2, and this value is achieved by perhaps the simplest online algorithm of
all: unprojected gradient descent with a constant learning rate.
  We then derive a minimax-optimal algorithm for a much softer penalty
function. This algorithm achieves good bounds under the standard notion of
regret for any comparator point, without needing to specify the comparator set
in advance. The value of this game converges to sqrt{e} as T ->infinity; we
give a closed-form for the exact value as a function of T. The resulting
algorithm is natural in unconstrained investment or betting scenarios, since it
guarantees at worst constant loss, while allowing for exponential reward
against an "easy" adversary.

A Time Series Forest for Classification and Feature Extraction
We propose a tree ensemble method, referred to as time series forest (TSF),
for time series classification. TSF employs a combination of the entropy gain
and a distance measure, referred to as the Entrance (entropy and distance)
gain, for evaluating the splits. Experimental studies show that the Entrance
gain criterion improves the accuracy of TSF. TSF randomly samples features at
each tree node and has a computational complexity linear in the length of a
time series and can be built using parallel computing techniques such as
multi-core computing used here. The temporal importance curve is also proposed
to capture the important temporal characteristics useful for classification.
Experimental studies show that TSF using simple features such as mean,
deviation and slope outperforms strong competitors such as one-nearest-neighbor
classifiers with dynamic time warping, is computationally efficient, and can
provide insights into the temporal characteristics.

Extracting useful rules through improved decision tree induction using
  information entropy
Classification is widely used technique in the data mining domain, where
scalability and efficiency are the immediate problems in classification
algorithms for large databases. We suggest improvements to the existing C4.5
decision tree algorithm. In this paper attribute oriented induction (AOI) and
relevance analysis are incorporated with concept hierarchys knowledge and
HeightBalancePriority algorithm for construction of decision tree along with
Multi level mining. The assignment of priorities to attributes is done by
evaluating information entropy, at different levels of abstraction for building
decision tree using HeightBalancePriority algorithm. Modified DMQL queries are
used to understand and explore the shortcomings of the decision trees generated
by C4.5 classifier for education dataset and the results are compared with the
proposed approach.

Online Regret Bounds for Undiscounted Continuous Reinforcement Learning
We derive sublinear regret bounds for undiscounted reinforcement learning in
continuous state space. The proposed algorithm combines state aggregation with
the use of upper confidence bounds for implementing optimism in the face of
uncertainty. Beside the existence of an optimal policy which satisfies the
Poisson equation, the only assumptions made are Holder continuity of rewards
and transition probabilities.

Selecting the State-Representation in Reinforcement Learning
The problem of selecting the right state-representation in a reinforcement
learning problem is considered. Several models (functions mapping past
observations to a finite set) of the observations are given, and it is known
that for at least one of these models the resulting state dynamics are indeed
Markovian. Without knowing neither which of the models is the correct one, nor
what are the probabilistic characteristics of the resulting MDP, it is required
to obtain as much reward as the optimal policy for the correct model (or for
the best of the correct models, if there are several). We propose an algorithm
that achieves that, with a regret of order T^{2/3} where T is the horizon time.

Optimal Regret Bounds for Selecting the State Representation in
  Reinforcement Learning
We consider an agent interacting with an environment in a single stream of
actions, observations, and rewards, with no reset. This process is not assumed
to be a Markov Decision Process (MDP). Rather, the agent has several
representations (mapping histories of past interactions to a discrete state
space) of the environment with unknown dynamics, only some of which result in
an MDP. The goal is to minimize the average regret criterion against an agent
who knows an MDP representation giving the highest optimal reward, and acts
optimally in it. Recent regret bounds for this setting are of order
$O(T^{2/3})$ with an additive term constant yet exponential in some
characteristics of the optimal MDP. We propose an algorithm whose regret after
$T$ time steps is $O(\sqrt{T})$, with all constants reasonably small. This is
optimal in $T$ since $O(\sqrt{T})$ is the optimal regret in the setting of
learning in a (single discrete) MDP.

An Efficient Dual Approach to Distance Metric Learning
Distance metric learning is of fundamental interest in machine learning
because the distance metric employed can significantly affect the performance
of many learning methods. Quadratic Mahalanobis metric learning is a popular
approach to the problem, but typically requires solving a semidefinite
programming (SDP) problem, which is computationally expensive. Standard
interior-point SDP solvers typically have a complexity of $O(D^{6.5})$ (with
$D$ the dimension of input data), and can thus only practically solve problems
exhibiting less than a few thousand variables. Since the number of variables is
$D (D+1) / 2 $, this implies a limit upon the size of problem that can
practically be solved of around a few hundred dimensions. The complexity of the
popular quadratic Mahalanobis metric learning approach thus limits the size of
problem to which metric learning can be applied. Here we propose a
significantly more efficient approach to the metric learning problem based on
the Lagrange dual formulation of the problem. The proposed formulation is much
simpler to implement, and therefore allows much larger Mahalanobis metric
learning problems to be solved. The time complexity of the proposed method is
$O (D ^ 3) $, which is significantly lower than that of the SDP approach.
Experiments on a variety of datasets demonstrate that the proposed method
achieves an accuracy comparable to the state-of-the-art, but is applicable to
significantly larger problems. We also show that the proposed method can be
applied to solve more general Frobenius-norm regularized SDP problems
approximately.

Adaptive Crowdsourcing Algorithms for the Bandit Survey Problem
Very recently crowdsourcing has become the de facto platform for distributing
and collecting human computation for a wide range of tasks and applications
such as information retrieval, natural language processing and machine
learning. Current crowdsourcing platforms have some limitations in the area of
quality control. Most of the effort to ensure good quality has to be done by
the experimenter who has to manage the number of workers needed to reach good
results.
  We propose a simple model for adaptive quality control in crowdsourced
multiple-choice tasks which we call the \emph{bandit survey problem}. This
model is related to, but technically different from the well-known multi-armed
bandit problem. We present several algorithms for this problem, and support
them with analysis and simulations. Our approach is based in our experience
conducting relevance evaluation for a large commercial search engine.

StructBoost: Boosting Methods for Predicting Structured Output Variables
Boosting is a method for learning a single accurate predictor by linearly
combining a set of less accurate weak learners. Recently, structured learning
has found many applications in computer vision. Inspired by structured support
vector machines (SSVM), here we propose a new boosting algorithm for structured
output prediction, which we refer to as StructBoost. StructBoost supports
nonlinear structured learning by combining a set of weak structured learners.
As SSVM generalizes SVM, our StructBoost generalizes standard boosting
approaches such as AdaBoost, or LPBoost to structured learning. The resulting
optimization problem of StructBoost is more challenging than SSVM in the sense
that it may involve exponentially many variables and constraints. In contrast,
for SSVM one usually has an exponential number of constraints and a
cutting-plane method is used. In order to efficiently solve StructBoost, we
formulate an equivalent $ 1 $-slack formulation and solve it using a
combination of cutting planes and column generation. We show the versatility
and usefulness of StructBoost on a range of problems such as optimizing the
tree loss for hierarchical multi-class classification, optimizing the Pascal
overlap criterion for robust visual tracking and learning conditional random
field parameters for image segmentation.

Thompson Sampling in Switching Environments with Bayesian Online Change
  Point Detection
Thompson Sampling has recently been shown to be optimal in the Bernoulli
Multi-Armed Bandit setting[Kaufmann et al., 2012]. This bandit problem assumes
stationary distributions for the rewards. It is often unrealistic to model the
real world as a stationary distribution. In this paper we derive and evaluate
algorithms using Thompson Sampling for a Switching Multi-Armed Bandit Problem.
We propose a Thompson Sampling strategy equipped with a Bayesian change point
mechanism to tackle this problem. We develop algorithms for a variety of cases
with constant switching rate: when switching occurs all arms change (Global
Switching), switching occurs independently for each arm (Per-Arm Switching),
when the switching rate is known and when it must be inferred from data. This
leads to a family of algorithms we collectively term Change-Point Thompson
Sampling (CTS). We show empirical results of the algorithm in 4 artificial
environments, and 2 derived from real world data; news click-through[Yahoo!,
2011] and foreign exchange data[Dukascopy, 2012], comparing them to some other
bandit algorithms. In real world data CTS is the most effective.

Graph-based Generalization Bounds for Learning Binary Relations
We investigate the generalizability of learned binary relations: functions
that map pairs of instances to a logical indicator. This problem has
application in numerous areas of machine learning, such as ranking, entity
resolution and link prediction. Our learning framework incorporates an example
labeler that, given a sequence $X$ of $n$ instances and a desired training size
$m$, subsamples $m$ pairs from $X \times X$ without replacement. The challenge
in analyzing this learning scenario is that pairwise combinations of random
variables are inherently dependent, which prevents us from using traditional
learning-theoretic arguments. We present a unified, graph-based analysis, which
allows us to analyze this dependence using well-known graph identities. We are
then able to bound the generalization error of learned binary relations using
Rademacher complexity and algorithmic stability. The rate of uniform
convergence is partially determined by the labeler's subsampling process. We
thus examine how various assumptions about subsampling affect generalization;
under a natural random subsampling process, our bounds guarantee
$\tilde{O}(1/\sqrt{n})$ uniform convergence.

The Importance of Clipping in Neurocontrol by Direct Gradient Descent on
  the Cost-to-Go Function and in Adaptive Dynamic Programming
In adaptive dynamic programming, neurocontrol and reinforcement learning, the
objective is for an agent to learn to choose actions so as to minimise a total
cost function. In this paper we show that when discretized time is used to
model the motion of the agent, it can be very important to do "clipping" on the
motion of the agent in the final time step of the trajectory. By clipping we
mean that the final time step of the trajectory is to be truncated such that
the agent stops exactly at the first terminal state reached, and no distance
further. We demonstrate that when clipping is omitted, learning performance can
fail to reach the optimum; and when clipping is done properly, learning
performance can improve significantly.
  The clipping problem we describe affects algorithms which use explicit
derivatives of the model functions of the environment to calculate a learning
gradient. These include Backpropagation Through Time for Control, and methods
based on Dual Heuristic Dynamic Programming. However the clipping problem does
not significantly affect methods based on Heuristic Dynamic Programming,
Temporal Differences or Policy Gradient Learning algorithms. Similarly, the
clipping problem does not affect fixed-length finite-horizon problems.

Prediction by Random-Walk Perturbation
We propose a version of the follow-the-perturbed-leader online prediction
algorithm in which the cumulative losses are perturbed by independent symmetric
random walks. The forecaster is shown to achieve an expected regret of the
optimal order O(sqrt(n log N)) where n is the time horizon and N is the number
of experts. More importantly, it is shown that the forecaster changes its
prediction at most O(sqrt(n log N)) times, in expectation. We also extend the
analysis to online combinatorial optimization and show that even in this more
general setting, the forecaster rarely switches between experts while having a
regret of near-optimal order.

Sparse Frequency Analysis with Sparse-Derivative Instantaneous Amplitude
  and Phase Functions
This paper addresses the problem of expressing a signal as a sum of frequency
components (sinusoids) wherein each sinusoid may exhibit abrupt changes in its
amplitude and/or phase. The Fourier transform of a narrow-band signal, with a
discontinuous amplitude and/or phase function, exhibits spectral and temporal
spreading. The proposed method aims to avoid such spreading by explicitly
modeling the signal of interest as a sum of sinusoids with time-varying
amplitudes. So as to accommodate abrupt changes, it is further assumed that the
amplitude/phase functions are approximately piecewise constant (i.e., their
time-derivatives are sparse). The proposed method is based on a convex
variational (optimization) approach wherein the total variation (TV) of the
amplitude functions are regularized subject to a perfect (or approximate)
reconstruction constraint. A computationally efficient algorithm is derived
based on convex optimization techniques. The proposed technique can be used to
perform band-pass filtering that is relatively insensitive to narrow-band
amplitude/phase jumps present in data, which normally pose a challenge (due to
transients, leakage, etc.). The method is illustrated using both synthetic
signals and human EEG data for the purpose of band-pass filtering and the
estimation of phase synchrony indexes.

Online Learning for Time Series Prediction
In this paper we address the problem of predicting a time series using the
ARMA (autoregressive moving average) model, under minimal assumptions on the
noise terms. Using regret minimization techniques, we develop effective online
learning algorithms for the prediction problem, without assuming that the noise
terms are Gaussian, identically distributed or even independent. Furthermore,
we show that our algorithm's performances asymptotically approaches the
performance of the best ARMA model in hindsight.

Online Convex Optimization Against Adversaries with Memory and
  Application to Statistical Arbitrage
The framework of online learning with memory naturally captures learning
problems with temporal constraints, and was previously studied for the experts
setting. In this work we extend the notion of learning with memory to the
general Online Convex Optimization (OCO) framework, and present two algorithms
that attain low regret. The first algorithm applies to Lipschitz continuous
loss functions, obtaining optimal regret bounds for both convex and strongly
convex losses. The second algorithm attains the optimal regret bounds and
applies more broadly to convex losses without requiring Lipschitz continuity,
yet is more complicated to implement. We complement our theoretic results with
an application to statistical arbitrage in finance: we devise algorithms for
constructing mean-reverting portfolios.

Online Similarity Prediction of Networked Data from Known and Unknown
  Graphs
We consider online similarity prediction problems over networked data. We
begin by relating this task to the more standard class prediction problem,
showing that, given an arbitrary algorithm for class prediction, we can
construct an algorithm for similarity prediction with "nearly" the same mistake
bound, and vice versa. After noticing that this general construction is
computationally infeasible, we target our study to {\em feasible} similarity
prediction algorithms on networked data. We initially assume that the network
structure is {\em known} to the learner. Here we observe that Matrix Winnow
\cite{w07} has a near-optimal mistake guarantee, at the price of cubic
prediction time per round. This motivates our effort for an efficient
implementation of a Perceptron algorithm with a weaker mistake guarantee but
with only poly-logarithmic prediction time. Our focus then turns to the
challenging case of networks whose structure is initially {\em unknown} to the
learner. In this novel setting, where the network structure is only
incrementally revealed, we obtain a mistake-bounded algorithm with a quadratic
prediction time per round.

Learning Hash Functions Using Column Generation
Fast nearest neighbor searching is becoming an increasingly important tool in
solving many large-scale problems. Recently a number of approaches to learning
data-dependent hash functions have been developed. In this work, we propose a
column generation based method for learning data-dependent hash functions on
the basis of proximity comparison information. Given a set of triplets that
encode the pairwise proximity comparison information, our method learns hash
functions that preserve the relative comparison relationships in the data as
well as possible within the large-margin learning framework. The learning
procedure is implemented using column generation and hence is named CGHash. At
each iteration of the column generation procedure, the best hash function is
selected. Unlike most other hashing methods, our method generalizes to new data
points naturally; and has a training objective which is convex, thus ensuring
that the global optimum can be identified. Experiments demonstrate that the
proposed method learns compact binary codes and that its retrieval performance
compares favorably with state-of-the-art methods when tested on a few benchmark
datasets.

Inductive Sparse Subspace Clustering
Sparse Subspace Clustering (SSC) has achieved state-of-the-art clustering
quality by performing spectral clustering over a $\ell^{1}$-norm based
similarity graph. However, SSC is a transductive method which does not handle
with the data not used to construct the graph (out-of-sample data). For each
new datum, SSC requires solving $n$ optimization problems in O(n) variables for
performing the algorithm over the whole data set, where $n$ is the number of
data points. Therefore, it is inefficient to apply SSC in fast online
clustering and scalable graphing. In this letter, we propose an inductive
spectral clustering algorithm, called inductive Sparse Subspace Clustering
(iSSC), which makes SSC feasible to cluster out-of-sample data. iSSC adopts the
assumption that high-dimensional data actually lie on the low-dimensional
manifold such that out-of-sample data could be grouped in the embedding space
learned from in-sample data. Experimental results show that iSSC is promising
in clustering out-of-sample data.

Convex and Scalable Weakly Labeled SVMs
In this paper, we study the problem of learning from weakly labeled data,
where labels of the training examples are incomplete. This includes, for
example, (i) semi-supervised learning where labels are partially known; (ii)
multi-instance learning where labels are implicitly known; and (iii) clustering
where labels are completely unknown. Unlike supervised learning, learning with
weak labels involves a difficult Mixed-Integer Programming (MIP) problem.
Therefore, it can suffer from poor scalability and may also get stuck in local
minimum. In this paper, we focus on SVMs and propose the WellSVM via a novel
label generation strategy. This leads to a convex relaxation of the original
MIP, which is at least as tight as existing convex Semi-Definite Programming
(SDP) relaxations. Moreover, the WellSVM can be solved via a sequence of SVM
subproblems that are much more scalable than previous convex SDP relaxations.
Experiments on three weakly labeled learning tasks, namely, (i) semi-supervised
learning; (ii) multi-instance learning for locating regions of interest in
content-based information retrieval; and (iii) clustering, clearly demonstrate
improved performance, and WellSVM is also readily applicable on large data
sets.

Multi-relational Learning Using Weighted Tensor Decomposition with
  Modular Loss
We propose a modular framework for multi-relational learning via tensor
decomposition. In our learning setting, the training data contains multiple
types of relationships among a set of objects, which we represent by a sparse
three-mode tensor. The goal is to predict the values of the missing entries. To
do so, we model each relationship as a function of a linear combination of
latent factors. We learn this latent representation by computing a low-rank
tensor decomposition, using quasi-Newton optimization of a weighted objective
function. Sparsity in the observed data is captured by the weighted objective,
leading to improved accuracy when training data is limited. Exploiting sparsity
also improves efficiency, potentially up to an order of magnitude over
unweighted approaches. In addition, our framework accommodates arbitrary
combinations of smooth, task-specific loss functions, making it better suited
for learning different types of relations. For the typical cases of real-valued
functions and binary relations, we propose several loss functions and derive
the associated parameter gradients. We evaluate our method on synthetic and
real data, showing significant improvements in both accuracy and scalability
over related factorization techniques.

Transfer Learning for Voice Activity Detection: A Denoising Deep Neural
  Network Perspective
Mismatching problem between the source and target noisy corpora severely
hinder the practical use of the machine-learning-based voice activity detection
(VAD). In this paper, we try to address this problem in the transfer learning
prospective. Transfer learning tries to find a common learning machine or a
common feature subspace that is shared by both the source corpus and the target
corpus. The denoising deep neural network is used as the learning machine.
Three transfer techniques, which aim to learn common feature representations,
are used for analysis. Experimental results demonstrate the effectiveness of
the transfer learning schemes on the mismatch problem.

Convex Discriminative Multitask Clustering
Multitask clustering tries to improve the clustering performance of multiple
tasks simultaneously by taking their relationship into account. Most existing
multitask clustering algorithms fall into the type of generative clustering,
and none are formulated as convex optimization problems. In this paper, we
propose two convex Discriminative Multitask Clustering (DMTC) algorithms to
address the problems. Specifically, we first propose a Bayesian DMTC framework.
Then, we propose two convex DMTC objectives within the framework. The first
one, which can be seen as a technical combination of the convex multitask
feature learning and the convex Multiclass Maximum Margin Clustering (M3C),
aims to learn a shared feature representation. The second one, which can be
seen as a combination of the convex multitask relationship learning and M3C,
aims to learn the task relationship. The two objectives are solved in a uniform
procedure by the efficient cutting-plane algorithm. Experimental results on a
toy problem and two benchmark datasets demonstrate the effectiveness of the
proposed algorithms.

Heuristic Ternary Error-Correcting Output Codes Via Weight Optimization
  and Layered Clustering-Based Approach
One important classifier ensemble for multiclass classification problems is
Error-Correcting Output Codes (ECOCs). It bridges multiclass problems and
binary-class classifiers by decomposing multiclass problems to a serial
binary-class problems. In this paper, we present a heuristic ternary code,
named Weight Optimization and Layered Clustering-based ECOC (WOLC-ECOC). It
starts with an arbitrary valid ECOC and iterates the following two steps until
the training risk converges. The first step, named Layered Clustering based
ECOC (LC-ECOC), constructs multiple strong classifiers on the most confusing
binary-class problem. The second step adds the new classifiers to ECOC by a
novel Optimized Weighted (OW) decoding algorithm, where the optimization
problem of the decoding is solved by the cutting plane algorithm. Technically,
LC-ECOC makes the heuristic training process not blocked by some difficult
binary-class problem. OW decoding guarantees the non-increase of the training
risk for ensuring a small code length. Results on 14 UCI datasets and a music
genre classification problem demonstrate the effectiveness of WOLC-ECOC.

A Last-Step Regression Algorithm for Non-Stationary Online Learning
The goal of a learner in standard online learning is to maintain an average
loss close to the loss of the best-performing single function in some class. In
many real-world problems, such as rating or ranking items, there is no single
best target function during the runtime of the algorithm, instead the best
(local) target function is drifting over time. We develop a novel last-step
minmax optimal algorithm in context of a drift. We analyze the algorithm in the
worst-case regret framework and show that it maintains an average loss close to
that of the best slowly changing sequence of linear functions, as long as the
total of drift is sublinear. In some situations, our bound improves over
existing bounds, and additionally the algorithm suffers logarithmic regret when
there is no drift. We also build on the H_infinity filter and its bound, and
develop and analyze a second algorithm for drifting setting. Synthetic
simulations demonstrate the advantages of our algorithms in a worst-case
constant drift setting.

A Quorum Sensing Inspired Algorithm for Dynamic Clustering
Quorum sensing is a decentralized biological process, through which a
community of cells with no global awareness coordinate their functional
behaviors based solely on cell-medium interactions and local decisions. This
paper draws inspirations from quorum sensing and colony competition to derive a
new algorithm for data clustering. The algorithm treats each data as a single
cell, and uses knowledge of local connectivity to cluster cells into multiple
colonies simultaneously. It simulates auto-inducers secretion in quorum sensing
to tune the influence radius for each cell. At the same time, sparsely
distributed core cells spread their influences to form colonies, and
interactions between colonies eventually determine each cell's identity. The
algorithm has the flexibility to analyze not only static but also time-varying
data, which surpasses the capacity of many existing algorithms. Its stability
and convergence properties are established. The algorithm is tested on several
applications, including both synthetic and real benchmarks data sets, alleles
clustering, community detection, image segmentation. In particular, the
algorithm's distinctive capability to deal with time-varying data allows us to
experiment it on novel applications such as robotic swarms grouping and
switching model identification. We believe that the algorithm's promising
performance would stimulate many more exciting applications.

On multi-class learning through the minimization of the confusion matrix
  norm
In imbalanced multi-class classification problems, the misclassification rate
as an error measure may not be a relevant choice. Several methods have been
developed where the performance measure retained richer information than the
mere misclassification rate: misclassification costs, ROC-based information,
etc. Following this idea of dealing with alternate measures of performance, we
propose to address imbalanced classification problems by using a new measure to
be optimized: the norm of the confusion matrix. Indeed, recent results show
that using the norm of the confusion matrix as an error measure can be quite
interesting due to the fine-grain informations contained in the matrix,
especially in the case of imbalanced classes. Our first contribution then
consists in showing that optimizing criterion based on the confusion matrix
gives rise to a common background for cost-sensitive methods aimed at dealing
with imbalanced classes learning problems. As our second contribution, we
propose an extension of a recent multi-class boosting method --- namely
AdaBoost.MM --- to the imbalanced class problem, by greedily minimizing the
empirical norm of the confusion matrix. A theoretical analysis of the
properties of the proposed method is presented, while experimental results
illustrate the behavior of the algorithm and show the relevancy of the approach
compared to other methods.

Markov Chain Monte Carlo for Arrangement of Hyperplanes in
  Locality-Sensitive Hashing
Since Hamming distances can be calculated by bitwise computations, they can
be calculated with less computational load than L2 distances. Similarity
searches can therefore be performed faster in Hamming distance space. The
elements of Hamming distance space are bit strings. On the other hand, the
arrangement of hyperplanes induce the transformation from the feature vectors
into feature bit strings. This transformation method is a type of
locality-sensitive hashing that has been attracting attention as a way of
performing approximate similarity searches at high speed. Supervised learning
of hyperplane arrangements allows us to obtain a method that transforms them
into feature bit strings reflecting the information of labels applied to
higher-dimensional feature vectors. In this p aper, we propose a supervised
learning method for hyperplane arrangements in feature space that uses a Markov
chain Monte Carlo (MCMC) method. We consider the probability density functions
used during learning, and evaluate their performance. We also consider the
sampling method for learning data pairs needed in learning, and we evaluate its
performance. We confirm that the accuracy of this learning method when using a
suitable probability density function and sampling method is greater than the
accuracy of existing learning methods.

Large-Scale Learning with Less RAM via Randomization
We reduce the memory footprint of popular large-scale online learning methods
by projecting our weight vector onto a coarse discrete set using randomized
rounding. Compared to standard 32-bit float encodings, this reduces RAM usage
by more than 50% during training and by up to 95% when making predictions from
a fixed model, with almost no loss in accuracy. We also show that randomized
counting can be used to implement per-coordinate learning rates, improving
model quality with little additional RAM. We prove these memory-saving methods
achieve regret guarantees similar to their exact variants. Empirical evaluation
confirms excellent performance, dominating standard approaches across memory
versus accuracy tradeoffs.

A Note on k-support Norm Regularized Risk Minimization
The k-support norm has been recently introduced to perform correlated
sparsity regularization. Although Argyriou et al. only reported experiments
using squared loss, here we apply it to several other commonly used settings
resulting in novel machine learning algorithms with interesting and familiar
limit cases. Source code for the algorithms described here is available.

Inductive Hashing on Manifolds
Learning based hashing methods have attracted considerable attention due to
their ability to greatly increase the scale at which existing algorithms may
operate. Most of these methods are designed to generate binary codes that
preserve the Euclidean distance in the original space. Manifold learning
techniques, in contrast, are better able to model the intrinsic structure
embedded in the original high-dimensional data. The complexity of these models,
and the problems with out-of-sample data, have previously rendered them
unsuitable for application to large-scale embedding, however. In this work, we
consider how to learn compact binary embeddings on their intrinsic manifolds.
In order to address the above-mentioned difficulties, we describe an efficient,
inductive solution to the out-of-sample data problem, and a process by which
non-parametric manifold learning may be used as the basis of a hashing method.
Our proposed approach thus allows the development of a range of new hashing
techniques exploiting the flexibility of the wide variety of manifold learning
approaches available. We particularly show that hashing on the basis of t-SNE .

O(logT) Projections for Stochastic Optimization of Smooth and Strongly
  Convex Functions
Traditional algorithms for stochastic optimization require projecting the
solution at each iteration into a given domain to ensure its feasibility. When
facing complex domains, such as positive semi-definite cones, the projection
operation can be expensive, leading to a high computational cost per iteration.
In this paper, we present a novel algorithm that aims to reduce the number of
projections for stochastic optimization. The proposed algorithm combines the
strength of several recent developments in stochastic optimization, including
mini-batch, extra-gradient, and epoch gradient descent, in order to effectively
explore the smoothness and strong convexity. We show, both in expectation and
with a high probability, that when the objective function is both smooth and
strongly convex, the proposed algorithm achieves the optimal $O(1/T)$ rate of
convergence with only $O(\log T)$ projections. Our empirical study verifies the
theoretical result.

Efficient Distance Metric Learning by Adaptive Sampling and Mini-Batch
  Stochastic Gradient Descent (SGD)
Distance metric learning (DML) is an important task that has found
applications in many domains. The high computational cost of DML arises from
the large number of variables to be determined and the constraint that a
distance metric has to be a positive semi-definite (PSD) matrix. Although
stochastic gradient descent (SGD) has been successfully applied to improve the
efficiency of DML, it can still be computationally expensive because in order
to ensure that the solution is a PSD matrix, it has to, at every iteration,
project the updated distance metric onto the PSD cone, an expensive operation.
We address this challenge by developing two strategies within SGD, i.e.
mini-batch and adaptive sampling, to effectively reduce the number of updates
(i.e., projections onto the PSD cone) in SGD. We also develop hybrid approaches
that combine the strength of adaptive sampling with that of mini-batch online
learning techniques to further improve the computational efficiency of SGD for
DML. We prove the theoretical guarantees for both adaptive sampling and
mini-batch based approaches for DML. We also conduct an extensive empirical
study to verify the effectiveness of the proposed algorithms for DML.

Fast SVM training using approximate extreme points
Applications of non-linear kernel Support Vector Machines (SVMs) to large
datasets is seriously hampered by its excessive training time. We propose a
modification, called the approximate extreme points support vector machine
(AESVM), that is aimed at overcoming this burden. Our approach relies on
conducting the SVM optimization over a carefully selected subset, called the
representative set, of the training dataset. We present analytical results that
indicate the similarity of AESVM and SVM solutions. A linear time algorithm
based on convex hulls and extreme points is used to compute the representative
set in kernel space. Extensive computational experiments on nine datasets
compared AESVM to LIBSVM \citep{LIBSVM}, CVM \citep{Tsang05}, BVM
\citep{Tsang07}, LASVM \citep{Bordes05}, $\text{SVM}^{\text{perf}}$
\citep{Joachims09}, and the random features method \citep{rahimi07}. Our AESVM
implementation was found to train much faster than the other methods, while its
classification accuracy was similar to that of LIBSVM in all cases. In
particular, for a seizure detection dataset, AESVM training was almost $10^3$
times faster than LIBSVM and LASVM and more than forty times faster than CVM
and BVM. Additionally, AESVM also gave competitively fast classification times.

A Generalized Online Mirror Descent with Applications to Classification
  and Regression
Online learning algorithms are fast, memory-efficient, easy to implement, and
applicable to many prediction problems, including classification, regression,
and ranking. Several online algorithms were proposed in the past few decades,
some based on additive updates, like the Perceptron, and some on multiplicative
updates, like Winnow. A unifying perspective on the design and the analysis of
online algorithms is provided by online mirror descent, a general prediction
strategy from which most first-order algorithms can be obtained as special
cases. We generalize online mirror descent to time-varying regularizers with
generic updates. Unlike standard mirror descent, our more general formulation
also captures second order algorithms, algorithms for composite losses and
algorithms for adaptive filtering. Moreover, we recover, and sometimes improve,
known regret bounds as special cases of our analysis using specific
regularizers. Finally, we show the power of our approach by deriving a new
second order algorithm with a regret bound invariant with respect to arbitrary
rescalings of individual features.

A New Homogeneity Inter-Clusters Measure in SemiSupervised Clustering
Many studies in data mining have proposed a new learning called
semi-Supervised. Such type of learning combines unlabeled and labeled data
which are hard to obtain. However, in unsupervised methods, the only unlabeled
data are used. The problem of significance and the effectiveness of
semi-supervised clustering results is becoming of main importance. This paper
pursues the thesis that muchgreater accuracy can be achieved in such clustering
by improving the similarity computing. Hence, we introduce a new approach of
semisupervised clustering using an innovative new homogeneity measure of
generated clusters. Our experimental results demonstrate significantly improved
accuracy as a result.

A Survey on Multi-view Learning
In recent years, a great many methods of learning from multi-view data by
considering the diversity of different views have been proposed. These views
may be obtained from multiple sources or different feature subsets. In trying
to organize and highlight similarities and differences between the variety of
multi-view learning approaches, we review a number of representative multi-view
learning algorithms in different areas and classify them into three groups: 1)
co-training, 2) multiple kernel learning, and 3) subspace learning. Notably,
co-training style algorithms train alternately to maximize the mutual agreement
on two distinct views of the data; multiple kernel learning algorithms exploit
kernels that naturally correspond to different views and combine kernels either
linearly or non-linearly to improve learning performance; and subspace learning
algorithms aim to obtain a latent subspace shared by multiple views by assuming
that the input views are generated from this latent subspace. Though there is
significant variance in the approaches to integrating multiple views to improve
learning performance, they mainly exploit either the consensus principle or the
complementary principle to ensure the success of multi-view learning. Since
accessing multiple views is the fundament of multi-view learning, with the
exception of study on learning a model from multiple views, it is also valuable
to study how to construct multiple views and how to evaluate these views.
Overall, by exploring the consistency and complementary properties of different
views, multi-view learning is rendered more effective, more promising, and has
better generalization ability than single-view learning.

Continuum armed bandit problem of few variables in high dimensions
We consider the stochastic and adversarial settings of continuum armed
bandits where the arms are indexed by [0,1]^d. The reward functions r:[0,1]^d
-> R are assumed to intrinsically depend on at most k coordinate variables
implying r(x_1,..,x_d) = g(x_{i_1},..,x_{i_k}) for distinct and unknown
i_1,..,i_k from {1,..,d} and some locally Holder continuous g:[0,1]^k -> R with
exponent 0 < alpha <= 1. Firstly, assuming (i_1,..,i_k) to be fixed across
time, we propose a simple modification of the CAB1 algorithm where we construct
the discrete set of sampling points to obtain a bound of
O(n^((alpha+k)/(2*alpha+k)) (log n)^((alpha)/(2*alpha+k)) C(k,d)) on the
regret, with C(k,d) depending at most polynomially in k and sub-logarithmically
in d. The construction is based on creating partitions of {1,..,d} into k
disjoint subsets and is probabilistic, hence our result holds with high
probability. Secondly we extend our results to also handle the more general
case where (i_1,...,i_k) can change over time and derive regret bounds for the
same.

Irreflexive and Hierarchical Relations as Translations
We consider the problem of embedding entities and relations of knowledge
bases in low-dimensional vector spaces. Unlike most existing approaches, which
are primarily efficient for modeling equivalence relations, our approach is
designed to explicitly model irreflexive relations, such as hierarchies, by
interpreting them as translations operating on the low-dimensional embeddings
of the entities. Preliminary experiments show that, despite its simplicity and
a smaller number of parameters than previous approaches, our approach achieves
state-of-the-art performance according to standard evaluation protocols on data
from WordNet and Freebase.

Fractal structures in Adversarial Prediction
Fractals are self-similar recursive structures that have been used in
modeling several real world processes. In this work we study how "fractal-like"
processes arise in a prediction game where an adversary is generating a
sequence of bits and an algorithm is trying to predict them. We will see that
under a certain formalization of the predictive payoff for the algorithm it is
most optimal for the adversary to produce a fractal-like sequence to minimize
the algorithm's ability to predict. Indeed it has been suggested before that
financial markets exhibit a fractal-like behavior. We prove that a fractal-like
distribution arises naturally out of an optimization from the adversary's
perspective.
  In addition, we give optimal trade-offs between predictability and expected
deviation (i.e. sum of bits) for our formalization of predictive payoff. This
result is motivated by the observation that several time series data exhibit
higher deviations than expected for a completely random walk.

Clustering Unclustered Data: Unsupervised Binary Labeling of Two
  Datasets Having Different Class Balances
We consider the unsupervised learning problem of assigning labels to
unlabeled data. A naive approach is to use clustering methods, but this works
well only when data is properly clustered and each cluster corresponds to an
underlying class. In this paper, we first show that this unsupervised labeling
problem in balanced binary cases can be solved if two unlabeled datasets having
different class balances are available. More specifically, estimation of the
sign of the difference between probability densities of two unlabeled datasets
gives the solution. We then introduce a new method to directly estimate the
sign of the density difference without density estimation. Finally, we
demonstrate the usefulness of the proposed method against several clustering
methods on various toy problems and real-world datasets.

Perceptron Mistake Bounds
We present a brief survey of existing mistake bounds and introduce novel
bounds for the Perceptron or the kernel Perceptron algorithm. Our novel bounds
generalize beyond standard margin-loss type bounds, allow for any convex and
Lipschitz loss function, and admit a very simple proof.

Deep Learning of Representations: Looking Forward
Deep learning research aims at discovering learning algorithms that discover
multiple levels of distributed representations, with higher levels representing
more abstract concepts. Although the study of deep learning has already led to
impressive theoretical results, learning algorithms and breakthrough
experiments, several challenges lie ahead. This paper proposes to examine some
of these challenges, centering on the questions of scaling deep learning
algorithms to much larger models and datasets, reducing optimization
difficulties due to ill-conditioning or local minima, designing more efficient
and powerful inference and sampling procedures, and learning to disentangle the
factors of variation underlying the observed data. It also proposes a few
forward-looking research directions aimed at overcoming these challenges.

Spectral Classification Using Restricted Boltzmann Machine
In this study, a novel machine learning algorithm, restricted Boltzmann
machine (RBM), is introduced. The algorithm is applied for the spectral
classification in astronomy. RBM is a bipartite generative graphical model with
two separate layers (one visible layer and one hidden layer), which can extract
higher level features to represent the original data. Despite generative, RBM
can be used for classification when modified with a free energy and a soft-max
function. Before spectral classification, the original data is binarized
according to some rule. Then we resort to the binary RBM to classify
cataclysmic variables (CVs) and non-CVs (one half of all the given data for
training and the other half for testing). The experiment result shows
state-of-the-art accuracy of 100%, which indicates the efficiency of the binary
RBM algorithm.

Learning from Imprecise and Fuzzy Observations: Data Disambiguation
  through Generalized Loss Minimization
Methods for analyzing or learning from "fuzzy data" have attracted increasing
attention in recent years. In many cases, however, existing methods (for
precise, non-fuzzy data) are extended to the fuzzy case in an ad-hoc manner,
and without carefully considering the interpretation of a fuzzy set when being
used for modeling data. Distinguishing between an ontic and an epistemic
interpretation of fuzzy set-valued data, and focusing on the latter, we argue
that a "fuzzification" of learning algorithms based on an application of the
generic extension principle is not appropriate. In fact, the extension
principle fails to properly exploit the inductive bias underlying statistical
and machine learning methods, although this bias, at least in principle, offers
a means for "disambiguating" the fuzzy data. Alternatively, we therefore
propose a method which is based on the generalization of loss functions in
empirical risk minimization, and which performs model identification and data
disambiguation simultaneously. Elaborating on the fuzzification of specific
types of losses, we establish connections to well-known loss functions in
regression and classification. We compare our approach with related methods and
illustrate its use in logistic regression for binary classification.

Simple Deep Random Model Ensemble
Representation learning and unsupervised learning are two central topics of
machine learning and signal processing. Deep learning is one of the most
effective unsupervised representation learning approach. The main contributions
of this paper to the topics are as follows. (i) We propose to view the
representative deep learning approaches as special cases of the knowledge reuse
framework of clustering ensemble. (ii) We propose to view sparse coding when
used as a feature encoder as the consensus function of clustering ensemble, and
view dictionary learning as the training process of the base clusterings of
clustering ensemble. (ii) Based on the above two views, we propose a very
simple deep learning algorithm, named deep random model ensemble (DRME). It is
a stack of random model ensembles. Each random model ensemble is a special
k-means ensemble that discards the expectation-maximization optimization of
each base k-means but only preserves the default initialization method of the
base k-means. (iv) We propose to select the most powerful representation among
the layers by applying DRME to clustering where the single-linkage is used as
the clustering algorithm. Moreover, the DRME based clustering can also detect
the number of the natural clusters accurately. Extensive experimental
comparisons with 5 representation learning methods on 19 benchmark data sets
demonstrate the effectiveness of DRME.

A Differential Equations Approach to Optimizing Regret Trade-offs
We consider the classical question of predicting binary sequences and study
the {\em optimal} algorithms for obtaining the best possible regret and payoff
functions for this problem. The question turns out to be also equivalent to the
problem of optimal trade-offs between the regrets of two experts in an "experts
problem", studied before by \cite{kearns-regret}. While, say, a regret of
$\Theta(\sqrt{T})$ is known, we argue that it important to ask what is the
provably optimal algorithm for this problem --- both because it leads to
natural algorithms, as well as because regret is in fact often comparable in
magnitude to the final payoffs and hence is a non-negligible term.
  In the basic setting, the result essentially follows from a classical result
of Cover from '65. Here instead, we focus on another standard setting, of
time-discounted payoffs, where the final "stopping time" is not specified. We
exhibit an explicit characterization of the optimal regret for this setting.
  To obtain our main result, we show that the optimal payoff functions have to
satisfy the Hermite differential equation, and hence are given by the solutions
to this equation. It turns out that characterization of the payoff function is
qualitatively different from the classical (non-discounted) setting, and,
namely, there's essentially a unique optimal solution.

One-Pass AUC Optimization
AUC is an important performance measure and many algorithms have been devoted
to AUC optimization, mostly by minimizing a surrogate convex loss on a training
data set. In this work, we focus on one-pass AUC optimization that requires
only going through the training data once without storing the entire training
dataset, where conventional online learning algorithms cannot be applied
directly because AUC is measured by a sum of losses defined over pairs of
instances from different classes. We develop a regression-based algorithm which
only needs to maintain the first and second order statistics of training data
in memory, resulting a storage requirement independent from the size of
training data. To efficiently handle high dimensional data, we develop a
randomized algorithm that approximates the covariance matrices by low rank
matrices. We verify, both theoretically and empirically, the effectiveness of
the proposed algorithm.

Class Imbalance Problem in Data Mining Review
In last few years there are major changes and evolution has been done on
classification of data. As the application area of technology is increases the
size of data also increases. Classification of data becomes difficult because
of unbounded size and imbalance nature of data. Class imbalance problem become
greatest issue in data mining. Imbalance problem occur where one of the two
classes having more sample than other classes. The most of algorithm are more
focusing on classification of major sample while ignoring or misclassifying
minority sample. The minority samples are those that rarely occur but very
important. There are different methods available for classification of
imbalance data set which is divided into three main categories, the algorithmic
approach, data-preprocessing approach and feature selection approach. Each of
this technique has their own advantages and disadvantages. In this paper
systematic study of each approach is define which gives the right direction for
research in class imbalance problem.

Stochastic Collapsed Variational Bayesian Inference for Latent Dirichlet
  Allocation
In the internet era there has been an explosion in the amount of digital text
information available, leading to difficulties of scale for traditional
inference algorithms for topic models. Recent advances in stochastic
variational inference algorithms for latent Dirichlet allocation (LDA) have
made it feasible to learn topic models on large-scale corpora, but these
methods do not currently take full advantage of the collapsed representation of
the model. We propose a stochastic algorithm for collapsed variational Bayesian
inference for LDA, which is simpler and more efficient than the state of the
art method. We show connections between collapsed variational Bayesian
inference and MAP estimation for LDA, and leverage these connections to prove
convergence properties of the proposed algorithm. In experiments on large-scale
text corpora, the algorithm was found to converge faster and often to a better
solution than the previous method. Human-subject experiments also demonstrated
that the method can learn coherent topics in seconds on small corpora,
facilitating the use of topic models in interactive document analysis software.

An efficient algorithm for learning with semi-bandit feedback
We consider the problem of online combinatorial optimization under
semi-bandit feedback. The goal of the learner is to sequentially select its
actions from a combinatorial decision set so as to minimize its cumulative
loss. We propose a learning algorithm for this problem based on combining the
Follow-the-Perturbed-Leader (FPL) prediction method with a novel loss
estimation procedure called Geometric Resampling (GR). Contrary to previous
solutions, the resulting algorithm can be efficiently implemented for any
decision set where efficient offline combinatorial optimization is possible at
all. Assuming that the elements of the decision set can be described with
d-dimensional binary vectors with at most m non-zero entries, we show that the
expected regret of our algorithm after T rounds is O(m sqrt(dT log d)). As a
side result, we also improve the best known regret bounds for FPL in the full
information setting to O(m^(3/2) sqrt(T log d)), gaining a factor of sqrt(d/m)
over previous bounds for this algorithm.

