# Setup.py Documentation

## Overview
Setup.py is an automated setup and configuration script for the OASST1 Word Transformer Training system. It performs comprehensive environment validation, dependency management, and guided setup for the entire training pipeline.

## Key Features
- **Environment Validation**: Python version and system compatibility checking
- **Dependency Management**: Automatic installation of required packages
- **File Validation**: Ensures all required project files are present
- **Hardware Detection**: Identifies optimal training hardware (CUDA/MPS/CPU)
- **Dataset Management**: Automated dataset download and validation
- **Training Guidance**: Provides setup completion and next steps

## Main Functions

### 1. Environment Validation

#### `check_python_version()`
- **Purpose**: Validates Python interpreter compatibility
- **Requirements**: Python 3.8 or higher
- **Returns**: Boolean success status
- **Output**: Version information and compatibility status

```python
def check_python_version():
    """Check if Python version is compatible."""
    if sys.version_info < (3, 8):
        print("âŒ Python 3.8 or higher is required!")
        print(f"Current version: {sys.version}")
        return False
    print(f"âœ… Python version: {sys.version.split()[0]}")
    return True
```

### 2. Package Management

#### `check_and_install_packages()`
- **Purpose**: Validates and installs required Python packages
- **Dependencies Managed**:
  - `torch>=2.0.0`: PyTorch deep learning framework
  - `datasets>=2.14.0`: HuggingFace datasets library
  - `huggingface_hub`: Hub API access
  - `numpy`: Numerical computations
  - `tqdm`: Progress bars

**Installation Process:**
1. Checks each package availability using `importlib.import_module()`
2. Identifies missing packages
3. Executes `pip install --upgrade` for missing dependencies
4. Validates successful installation

### 3. Project File Validation

#### `check_required_files()`
- **Purpose**: Ensures all core project files are present
- **Required Files**:
  - `model_manager.py`: Model management system
  - `word_transformer.py`: Transformer architecture
  - `Train.py`: Main training script
  - `Dataset_download.py`: Dataset preparation script

**Validation Process:**
```python
required_files = [
    "model_manager.py",
    "word_transformer.py", 
    "Train.py",
    "Dataset_download.py"
]

for file_name in required_files:
    if Path(file_name).exists():
        print(f"âœ… {file_name}")
    else:
        print(f"âŒ {file_name} is missing")
```

### 4. Hardware Detection and Optimization

#### `check_torch_device()`
- **Purpose**: Identifies optimal training hardware
- **Detection Priority**:
  1. **CUDA**: NVIDIA GPU acceleration
  2. **MPS**: Apple Silicon optimization
  3. **CPU**: Fallback for compatibility

**Hardware Analysis:**
```python
if torch.cuda.is_available():
    device_name = torch.cuda.get_device_name()
    memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
    return "cuda", f"CUDA: {device_name} ({memory_gb:.1f} GB)"
elif torch.backends.mps.is_available():
    return "mps", "Apple Silicon (MPS)"
else:
    return "cpu", "CPU mode"
```

### 5. Dataset Management

#### `download_dataset()`
- **Purpose**: Automated OASST1 dataset preparation
- **Process**:
  1. Checks for existing dataset files
  2. Executes `Dataset_download.py` if needed
  3. Validates download success
  4. Reports dataset statistics

**File Validation:**
- `oasst1_data/oasst1_train.jsonl`: Training data
- `oasst1_data/oasst1_validation.jsonl`: Validation data

### 6. Training Time Estimation

#### `estimate_training_time(device_type)`
- **Purpose**: Provides realistic training time expectations
- **Estimates by Hardware**:
  - **CUDA**: 2-6 hours (GPU dependent)
  - **MPS**: 4-8 hours (Apple Silicon)
  - **CPU**: 12-24 hours (not recommended)

## Usage Examples

### Standard Setup
```bash
python Setup.py
```

### Complete Setup Output
```
==============================================================
ðŸ¤– OASST1 Word Transformer Training Setup
==============================================================
âœ… Python version: 3.11.5
ðŸ” Checking required packages...
âœ… torch is installed
âœ… datasets is installed
âœ… huggingface_hub is installed
âœ… numpy is installed
âœ… tqdm is installed
ðŸ“ Checking required files...
âœ… model_manager.py
âœ… word_transformer.py
âœ… Train.py
âœ… Dataset_download.py
ðŸ–¥ï¸  Checking available devices...
âœ… CUDA available: NVIDIA GeForce RTX 4080
   Memory: 16.0 GB
â±ï¸  Estimated training time: 2-6 hours (depending on GPU)
ðŸ“ Dataset files already exist!
âœ… Existing files are valid!
==============================================================
âœ… Setup completed successfully!
==============================================================

ðŸš€ Start training now? (y/n): y
```

### Automated Training Start
```bash
ðŸš€ Starting training...
Note: You can interrupt training with Ctrl+C
The best model will be saved automatically.
--------------------------------------------------
ðŸš€ Starting Memory-Optimized OASST1 Word-Level Transformer Training
======================================================================
ðŸ“š Loading OASST1 dataset (memory-limited)...
```

## Advanced Configuration

### 1. Environment Customization

#### Python Version Requirements
- **Minimum**: Python 3.8
- **Recommended**: Python 3.9+
- **Tested**: Python 3.11.5

#### Package Version Management
```python
required_packages = [
    ("torch", "torch>=2.0.0"),      # Deep learning framework
    ("datasets", "datasets>=2.14.0"), # HuggingFace datasets
    ("huggingface_hub", "huggingface_hub"), # Model hub access
    ("numpy", "numpy"),             # Numerical computing
    ("tqdm", "tqdm"),              # Progress indicators
]
```

### 2. Hardware Optimization

#### CUDA Configuration
- Automatic GPU detection and memory reporting
- Optimal batch size recommendations based on VRAM
- Multi-GPU support detection

#### Apple Silicon (MPS) Support
- Native Apple Silicon acceleration
- Memory-efficient settings for unified memory
- Performance optimization for M1/M2/M3 chips

#### CPU Fallback
- Multi-threading optimization
- Memory usage warnings
- Performance expectations management

### 3. Dataset Validation

#### File Integrity Checks
```python
def validate_dataset_files(output_dir):
    """Comprehensive dataset validation."""
    checks = [
        "File existence validation",
        "File size verification", 
        "JSON format validation",
        "Required field checking",
        "Content sampling test"
    ]
```

#### Storage Requirements
- **Training Data**: ~50-150 MB
- **Validation Data**: ~5-15 MB  
- **Total Required**: ~200 MB free space
- **Recommended**: 1 GB free space for model storage

## Error Handling and Troubleshooting

### Common Setup Issues

#### 1. Python Version Incompatibility
**Error**: `Python 3.8 or higher is required!`
**Solution**: Upgrade Python or use virtual environment
```bash
# Using pyenv
pyenv install 3.11.5
pyenv local 3.11.5

# Using conda
conda create -n wordtransformer python=3.11
conda activate wordtransformer
```

#### 2. Package Installation Failures
**Error**: `Failed to install packages: subprocess.CalledProcessError`
**Solutions**:
```bash
# Update pip first
python -m pip install --upgrade pip

# Install with user flag
python -m pip install --user torch datasets huggingface_hub numpy tqdm

# Use conda instead
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
conda install -c huggingface datasets transformers
```

#### 3. Missing Project Files
**Error**: `âŒ model_manager.py is missing`
**Solution**: Ensure all project files are in the same directory
```bash
# Verify project structure
ls -la *.py
# Expected files:
# ChatAI.py, Dataset_download.py, Setup.py, Train.py
# fine_tune.py, model_manager.py, word_transformer.py
```

#### 4. Hardware Detection Issues
**Error**: No CUDA/MPS detected despite having compatible hardware
**Solutions**:
```bash
# CUDA troubleshooting
nvidia-smi  # Check GPU availability
python -c "import torch; print(torch.cuda.is_available())"

# MPS troubleshooting (Mac)
python -c "import torch; print(torch.backends.mps.is_available())"
```

#### 5. Dataset Download Problems
**Error**: `Dataset download failed`
**Solutions**:
```bash
# Login to HuggingFace Hub
huggingface-cli login

# Manual dataset download
python Dataset_download.py

# Check internet connectivity
ping huggingface.co
```

### Debug Mode
Enable detailed logging for troubleshooting:
```python
# Modify Setup.py temporarily
import logging
logging.basicConfig(level=logging.DEBUG)
```

## Integration with Training Pipeline

### 1. Seamless Workflow
```bash
# Complete setup and training in one go
python Setup.py
# Automatically starts Train.py if user confirms
```

### 2. Manual Control
```bash
# Setup only
python Setup.py
# Answer 'n' when prompted to start training
# Then run training manually later:
python Train.py
```

### 3. Validation Pipeline
1. **Environment Check**: Python, packages, files
2. **Hardware Detection**: Optimal device selection
3. **Dataset Preparation**: Download and validation
4. **Training Readiness**: All prerequisites confirmed
5. **Optional Start**: User-controlled training initiation

## Best Practices

### 1. Pre-Setup Preparation
- Ensure stable internet connection for dataset download
- Have sufficient disk space (1GB+ recommended)
- Close unnecessary applications to free memory
- Update system drivers (especially GPU drivers)

### 2. Virtual Environment Usage
```bash
# Recommended: Use virtual environment
python -m venv wordtransformer_env
source wordtransformer_env/bin/activate  # Linux/Mac
# or
wordtransformer_env\Scripts\activate     # Windows

# Then run setup
python Setup.py
```

### 3. Resource Planning
- **CUDA Systems**: Ensure adequate VRAM (8GB+ recommended)
- **MPS Systems**: Consider unified memory limitations
- **CPU Systems**: Plan for extended training times

### 4. Monitoring Setup
```bash
# Monitor system resources during setup
htop           # Linux/Mac
Task Manager   # Windows

# Monitor GPU usage (NVIDIA)
nvidia-smi -l 1
```

## Advanced Features

### 1. Custom Installation Paths
The script can be modified to support custom installation directories:
```python
def setup_output_directory(project_root: Optional[str] = None):
    """Custom project root support."""
    if project_root is None:
        project_root = Path.cwd()
    # ... setup logic
```

### 2. Dependency Version Management
Advanced users can customize package versions:
```python
# Modify required_packages for specific versions
required_packages = [
    ("torch", "torch==2.1.0"),  # Specific version
    ("datasets", "datasets>=2.14.0,<3.0.0"),  # Version range
]
```

### 3. Hardware-Specific Optimizations
```python
def optimize_for_hardware(device_type):
    """Apply hardware-specific optimizations."""
    if device_type == "cuda":
        # CUDA optimizations
        os.environ["CUDA_LAUNCH_BLOCKING"] = "1"
    elif device_type == "mps":
        # MPS optimizations  
        os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
```

### 4. Automated Configuration Generation
The setup script can generate configuration files:
```python
def generate_config_file(hardware_info):
    """Generate optimized configuration."""
    config = {
        "device": hardware_info["device"],
        "batch_size": hardware_info["recommended_batch_size"],
        "memory_limit": hardware_info["memory_gb"]
    }
    # Save configuration for training scripts
```

## Security Considerations

### 1. Package Installation Security
- Uses official PyPI repositories
- Upgrades packages to latest secure versions
- No arbitrary code execution during setup

### 2. Dataset Security
- Downloads from official HuggingFace repositories
- Validates file integrity after download
- No execution of downloaded content

### 3. File Access Permissions
- Only accesses project directory files
- No system-wide modifications
- Respects user permissions

This setup script provides a comprehensive, user-friendly way to prepare the entire word-level transformer training environment with minimal manual intervention and maximum reliability.